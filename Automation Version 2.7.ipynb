{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation Version 2.7\n",
    "\n",
    "3/10/19 update - CLASSIFICATION SOLIDIFIED AND FINISHED. Essential goal: analyzes the SPLASH spectra using a variety of different \"score calculation\" methods in order to classify the stars into three groups: carbon stars, weak CN stars, and other/normal stars.\n",
    "\n",
    "started 3/22/19 - ATTEMPT AT CLEANING AND COMBINING 2.6.1 AND 2.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools needed for data analysis throughout the code\n",
    "import os \n",
    "import numpy as np\n",
    "import random\n",
    "import array as arr\n",
    "import math as m\n",
    "import statistics as st\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import path\n",
    "import seaborn as sns #used for plotting kernel density plots\n",
    "import pandas as pd #used for turning data into dataframes(tables)\n",
    "from astropy.convolution import convolve, Box1DKernel, Gaussian1DKernel \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the folder that necessary program information is stored in\n",
    "#this should be the only thing that needs to change between computers\n",
    "#keep the r at the front, and outside of the string, when pasting in a new pathname\n",
    "pathname = r'/Users/rachelraikar/Desktop/SIP/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads the data from the SPLASH fits file\n",
    "hdu = fits.open(os.path.join(pathname, 'subMasterSPLASH2.fits'))\n",
    "#for the SPLASH survey, all data is contained in a single hdu entry, so the variable data contains all the data\n",
    "data = hdu[1].data\n",
    "\n",
    "#reads the data from the keckPHAT fits file\n",
    "hdu2 = fits.open(os.path.join(pathname, 'keckphat_catalog_replaced.fits'))\n",
    "#for the keckPHAT survey, all data is contained in a single hdu entry, so the variable data contains all the data\n",
    "keckPHATdata = hdu2[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters stars based on their ZQUAL scores and keeps only those where ZQUAL = 1, 3, or 4\n",
    "#produces a list of the SPLASH indices of \"valid\" stars (those who meet the ZQUAL condition above)\n",
    "#also produces a list of \"invalid\" star indices (those who have a ZQUAL that is not 1, 3, or 4)\n",
    "validZQUAL = [1, 3, 4]\n",
    "invalidStars = []\n",
    "validStars = []\n",
    "for star in range(data.size):\n",
    "    if data[\"ZQUAL\"][star] in validZQUAL:\n",
    "        validStars.append(star)\n",
    "    else:\n",
    "        invalidStars.append(star)\n",
    "        \n",
    "#converts the lists into arrays for easier manipulation later on if needed\n",
    "allinvalidstars = np.array(invalidStars)\n",
    "allvalidstars = np.array(validStars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates arrays that contain the indices of stars visually identified to be in the categories listed\n",
    "#note that these indices only include stars that were found to be \"valid\" in the previous step\n",
    "others = np.load(os.path.join(pathname, 'validindices', 'nonCarbonOrCNIndices.npy')) #other stars (normal stars)\n",
    "\n",
    "allcarbon = np.load(os.path.join(pathname, 'validindices', 'allCarbonIndices.npy')) #all carbon stars (not CN) \n",
    "wNm = np.load(os.path.join(pathname, 'validindices', 'weakCNIndices.npy')) #weak and marginal CN stars\n",
    "\n",
    "extremes = np.load(os.path.join(pathname, 'validindices', 'extremeCarbonIndices.npy')) #different individual subsets of carbon stars (extremes, strongs, and mediums together make up allcarbon above)\n",
    "strongs = np.load(os.path.join(pathname, 'validindices', 'strongCarbonIndices.npy'))\n",
    "mediums = np.load(os.path.join(pathname, 'validindices', 'mediumCarbonIndices.npy'))\n",
    "\n",
    "weaks = np.load(os.path.join(pathname, 'validindices', 'weakCarbonIndices.npy')) #stars suspected to be CN (weaks and marginals together make up wNm above)\n",
    "marginals = np.load(os.path.join(pathname, 'validindices', 'marginalCarbonIndices.npy'))\n",
    "\n",
    "#creates an array that accomodates for all of the other star indices in SPLASH that were not visually identified/sorted\n",
    "outsiders_list = [i for i in range(data.size) if i not in others and i not in wNm and i not in allcarbon and i not in invalidStars]\n",
    "outsiders = np.array(outsiders_list)\n",
    "\n",
    "#creates sets of different types of stars that can later be used to more quickly test for membership\n",
    "allcarbon_set, wNm_set, others_set = set(), set(), set()\n",
    "allcarbon_set.update(allcarbon); wNm_set.update(wNm); others_set.update(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raja thinks these stars were flagged on the basis of Raja's more careful inspection of zspec notes \n",
    "#Confirm with Alex and Arya\n",
    "flaggedStars = {\"allcarbon\":[19905], \"weaks\":[21466], \"marginals\":[22159, 23248, 24545], \"outsiders\":[23368, 23390]}\n",
    "flaggedStars_list = [19905, 21466, 22159, 23248, 23368, 23390, 24545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new sample of other/normal stars that is based only on those that have PHAT data\n",
    "#also creates a new sample of stars containing all of the \"other\" stars that have no PHAT data\n",
    "photoOthers, nonphotoOthers, allPhotoStars = [], [], []\n",
    "allPhotoStars_set, photoOthers_set = set(), set() #sets created for easier membership testing\n",
    "\n",
    "filter336, filter475, filter814, filter110, filter160 = data[\"F336W\"].tolist(), data[\"F475W\"].tolist(), data[\"F814W\"].tolist(), data[\"F110W\"].tolist(), data[\"F160W\"].tolist()\n",
    "for star in allvalidstars:\n",
    "    #checks for PHAT data: checking for data in the following filters\n",
    "    identifiedFlag = False #a flag that checks whether the current star is an identified one, used later in creation of nonphotoOthers list\n",
    "    if (not np.isnan(filter336[star]) and filter336[star] < 99) or (not np.isnan(filter475[star]) and filter475[star] < 99) or (not np.isnan(filter814[star]) and filter814[star] < 99) or (not np.isnan(filter110[star]) and filter110[star] < 99) or (not np.isnan(filter160[star]) and filter160[star] < 99):\n",
    "        if star in others_set or star in wNm_set or star in allcarbon_set:\n",
    "            allPhotoStars.append(star)\n",
    "        if star in others_set:\n",
    "            photoOthers.append(star)\n",
    "            identifiedFlag = True\n",
    "    if star in others_set and not identifiedFlag: #if this star is in \"others\" but was not just added to the photoOthers list\n",
    "        nonphotoOthers.append(star)\n",
    "        \n",
    "allPhotoStars_set.update(allPhotoStars)\n",
    "photoOthers_set.update(photoOthers)\n",
    "print(\"Total number of weakCN,carbon,and other stars with photometric data:\", len(allPhotoStars_set))\n",
    "print(\"Individual counts (wNm and allcarbon not limited by photometry, photoOthers limited):\", len(wNm_set), len(allcarbon_set), len(photoOthers_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a list that consists of bright stars from the photoOthers list\n",
    "bright = [i for i in photoOthers if data['F814W'][i] < 22 and data['F475W'][i] < 24]\n",
    "print(len(bright))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates (mask,slit,objID):index dictionaries to speed up process of finding keckPHAT data for each star\n",
    "keckIndex_dict = {}\n",
    "for i in range(len(keckPHATdata['KOBJNAME'])):\n",
    "    #first pad KSLITNAME with as many 0s as required\n",
    "    slitName = keckPHATdata['KSLITNAME'][i]\n",
    "    slitName = '0'*(3-len(str(slitName))) + str(slitName)\n",
    "    keckIndex_dict[(keckPHATdata['KMASK'][i], slitName, keckPHATdata['KOBJNAME'][i])] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the new photoOthers sample based on data from the keckPHAT catalog\n",
    "keckPhotoOthers, nonKeckPhotoOthers = [], []\n",
    "keckPhotoOthers_set, indSet = set(), set()\n",
    "ctr = 0\n",
    "for star in photoOthers:\n",
    "    keckInd = keckIndex_dict[(data['MASK'][star], data['SLITNAME'][star], data['OBJNAME'][star])]\n",
    "    if keckInd in indSet:\n",
    "        print(str(keckInd) + ': duplicate')\n",
    "    indSet.add(keckInd)\n",
    "    if keckPHATdata['BRIGHTFLAG'][keckInd] == 0 and keckPHATdata['CONTFRAC'][keckInd] < 0.5:\n",
    "        keckPhotoOthers.append(star)\n",
    "    else:\n",
    "        nonKeckPhotoOthers.append(star)\n",
    "    ctr += 1\n",
    "    if ctr % 500 == 0:\n",
    "        print(str(ctr) + \" stars completed.\") \n",
    "\n",
    "keckPhotoOthers_set.update(keckPhotoOthers)\n",
    "print(str(len(photoOthers)) + ' stars in photoOthers became ' + str(len(keckPhotoOthers)) + ' stars in keckPhotoOthers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines variables that will be used for clipping spectra to the right wavelength window\n",
    "#goal: isolate the 'W' shaped feature shared by carbon and weak CN stars\n",
    "lowerThresh = 5840         #represents 7796.0 angstroms in data[\"LBIN\"]\n",
    "upperThresh = 6550         #represents 8257.5 angstroms in data[\"LBIN\"]\n",
    "middleThresh = 6184        #represents 8019.6 angstroms in data[\"LBIN\"]; point between the two 'U's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines different \"lower\" and \"upper\" threshold values to be used for normalization and coaddition \n",
    "#with these, the operations will be performed over the entire spectrum instead of just around the 7800-8200 angstrom range\n",
    "fullSpec_low = 0\n",
    "fullSpec_high = len(data[\"LBIN\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing a NaN cut on the stars to eliminate any whose spectra are more than 10% NaNs on the 'W' range\n",
    "NANvalidstars_list = allvalidstars[:].tolist()\n",
    "for star in allvalidstars:\n",
    "    NANcount = 0\n",
    "    for flux in data[\"SPEC\"][star][lowerThresh:upperThresh]:\n",
    "        if np.isnan(flux):\n",
    "            NANcount += 1\n",
    "    if NANcount > 0.1*len(data[\"SPEC\"][star][lowerThresh:upperThresh]):\n",
    "        NANvalidstars_list.remove(star)\n",
    "NANvalidstars = np.array(NANvalidstars_list)\n",
    "\n",
    "#metadata: showing how many stars were cut out of the data due to the NaN limits\n",
    "print(str(len(allvalidstars)) + ' stars became ' + str(len(NANvalidstars)) + ' after the NaN cut.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Spectra\n",
    "Includes spectrum slicing for the raw data, normalization based on median flux, and graphing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that will slice any spectrum to desired wavelengths\n",
    "def sliceSpec(star, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    star: the index of a particular star (with corresponding spectrum) in SPLASH\n",
    "    lower: the lower boundary of the slice, in terms of wavelength\n",
    "    upper: the upper boundary of the slice, in terms of wavelength\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    \n",
    "    Returns newWv, a Numpy array containing every wavelength value between lower and upper for which data exists for a certain star \n",
    "    Also returns newFlux, a Numpy array containing the flux values that (for a certain star) correspond to each of the wavelength values in newSpec\n",
    "    Also returns newIvar, a Numpy array containing the ivar values that (for a certain star) corresopnd to each of the wavelength values in newSpec\n",
    "    '''\n",
    "    newWv = data[\"LBIN\"][star][lower:upper]\n",
    "    newFlux = data[\"SPEC\"][star][lower:upper]\n",
    "    newIvar = data[\"IVAR\"][star][lower:upper]\n",
    "    return newWv, newFlux, newIvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that can be used to normalize the spectrum of a star on a certain wavelength range\n",
    "def normSpec(star = None, spectrum = None, ivars = None, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    star: the index of a particular star (with corresponding spectrum) in SPLASH\n",
    "    spectrum: a Numpy array containing the data that represents the flux values for a spectrum\n",
    "    ivars: a Numpy array containing the data that represents the ivar values for the same spectrum as above\n",
    "    lower: the lower boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    upper: the upper boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    star, spectrum, and ivars all default to None so that either a star index or raw spectral/ivar data can be fed into the function with the same result. Depending on what your data looks like, use the corresponding star or spectrum/ivar inputs and leave the other(s) as None\n",
    "    Only employ one or the other of these inputs when calling this function; do not define both star and spectrum/ivars at the same time \n",
    "    \n",
    "    If the spectrum is found to consist only of NaN values on the range defined by lower and upper:\n",
    "    Returns np.array(wvSlice), a Numpy array containing every wavelength value between lower and upper\n",
    "    Also returns np.array(fluxSlice_list), a Numpy array containing only NaN values that is the same length as np.array(wvSlice)\n",
    "    Also returns np.array(ivarSlice_list), a Numpy array containing only 0's that is the same length as np.array(wvSlice)\n",
    "    Also returns False, which is intended to be used as an argument in other functions to determine spectrum validity.\n",
    "    Note that if this happens, the spectrum will not be normalized and therefore cannot be graphed.\n",
    "    \n",
    "    Otherwise:\n",
    "    Returns wvSlice_np, a Numpy array containing every wavelength value between lower and upper\n",
    "    Also returns normedFlux_np, a Numpy array containing the normalized flux values for a certain star at every wavelength between lower and upper\n",
    "    Also returns normedIvar_np, a Numpy array containing the changed ivar values that correspond to each of the normalized flux values for a certain star in normedSpec_np\n",
    "    Also returns True, which is intended to be used as an argument in other functions to determine spectrum validity.\n",
    "    Note that for normedFlux_np, values within 5 pixels of a nan value that fall outside of 5 standard deviations from the mean flux have been replaced with nan values as well\n",
    "    '''\n",
    "    #converting arrays to list for easy iteration and modification\n",
    "    if star is None and (spectrum is None or ivars is None):\n",
    "        print(\"InputError: missing one or more of the necessary arguments.\")\n",
    "        return np.array(wvSlice), np.array(fluxSlice_list), np.array(ivarSlice_list), False\n",
    "    if star is not None: #if a star index was inputted, get data directly from SPLASH\n",
    "        wvSlice, fluxSlice, ivarSlice = sliceSpec(star, lower, upper)\n",
    "    elif np.all(spectrum is not None) and np.all(ivars is not None): #if a spectrum was inputted, use that as the data\n",
    "        wvSlice, fluxSlice, ivarSlice = data[\"LBIN\"][0][lower:upper], spectrum, ivars\n",
    "    wvSlice_list = wvSlice.tolist()\n",
    "    fluxSlice_list = fluxSlice.tolist()\n",
    "    ivarSlice_list = ivarSlice.tolist()\n",
    "    \n",
    "    #creating a version of the spectrum without any NaNs for performing median/standard deviation calculations\n",
    "    #if the spectrum is all NaNs on the range specified in the function call, will return an error\n",
    "    #if the spectrum is all 0s on the range specified in the function call, will replace the 0s with NaNs and returm am error\n",
    "    newFluxSlice = []\n",
    "    for wv in range(len(fluxSlice_list)):\n",
    "        #in the case of NaN ivars, exactly 0 ivars, or exactly 0 flux values, flux values should be converted into NaN and ivar values to 0 so that the data is not graphed\n",
    "        if fluxSlice_list[wv] == 0 or ivarSlice_list[wv] == 0: \n",
    "            fluxSlice_list[wv] = np.nan\n",
    "            ivarSlice_list[wv] = 0 #seems repetitive due to check in if statement, but necessary for any cases where flux = 0 but ivar does not and needs to be set to 0\n",
    "        elif np.isnan(ivarSlice_list[wv]) or np.isnan(fluxSlice_list[wv]):\n",
    "            ivarSlice_list[wv] = 0\n",
    "        else: #add to \"non-zero, non-NaN\" data\n",
    "            newFluxSlice.append(fluxSlice_list[wv])\n",
    "    if newFluxSlice == []:\n",
    "        print(\"NormalizationError: The spectrum for star \" + str(star) + \" contains only NaN values on the specified range. It cannot be normalized.\")\n",
    "        return np.array(wvSlice), np.array(fluxSlice_list), np.array(ivarSlice_list), False\n",
    "    medianFlux = st.median(newFluxSlice)\n",
    "    spec_mean = st.mean(newFluxSlice)\n",
    "    spec_stdev = st.stdev(newFluxSlice)\n",
    "    upperLim = spec_mean + 5*spec_stdev #limits calculated to clip out values around nan\n",
    "    lowerLim = spec_mean - 5*spec_stdev\n",
    "    \n",
    "    #replaces with np.nan values that are within 5 pixels of a nan value and outside of 5 standard deviations from the mean flux \n",
    "    #accomodates for nan values being located on the edges of the spectrum (in positions where 5 pixels out in either direction would be out of range)\n",
    "    nanIndices = []\n",
    "    for index in range(len(fluxSlice_list)):\n",
    "        if np.isnan(fluxSlice_list[index]): \n",
    "            if 5 < index < len(wvSlice_list) - 5:\n",
    "                for i in range(index-5,index+5):\n",
    "                    if lowerLim > fluxSlice_list[i] or upperLim < fluxSlice_list[i]:\n",
    "                        fluxSlice_list[i] = np.nan\n",
    "            elif 5 > index:\n",
    "                for i in range(0,index+5):\n",
    "                    if lowerLim > fluxSlice_list[i] or upperLim < fluxSlice_list[i]:\n",
    "                        fluxSlice_list[i] = np.nan\n",
    "            elif index > len(wvSlice_list) - 5:\n",
    "                for i in range(index-5, len(wvSlice)): #this should go upto len(specSlice)-1 due to 0-indexing\n",
    "                    if lowerLim > fluxSlice_list[i] or upperLim < fluxSlice_list[i]:\n",
    "                        fluxSlice_list[i] = np.nan\n",
    "\n",
    "    #at each pixel, normalizes the star's spectrum and modifies the corresponding ivar value\n",
    "    normedFlux = []\n",
    "    normedIvar = []\n",
    "    for wv in range(len(wvSlice_list)):\n",
    "        normedFlux.append(fluxSlice_list[wv]/medianFlux)\n",
    "        normedIvar.append(ivarSlice_list[wv]*(medianFlux**2))\n",
    "    \n",
    "    #converts the final products back to arrays for easy manipulation later in the code\n",
    "    normedFlux_np = np.array(normedFlux)\n",
    "    normedIvar_np = np.array(normedIvar)\n",
    "    wvSlice_np = np.array(wvSlice)\n",
    "    \n",
    "    return wvSlice_np, normedFlux_np, normedIvar_np, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates splashSpecs_dict, a dictionary of the normalized spectra for every valid star in SPLASH, and splashIvars_dict, a dictionary of the normalized ivar values for those same stars\n",
    "#keys are the indices of stars, paired values are arrays representing the flux/ivar values of those stars at every wavelength in the range identified\n",
    "#note that NormalizationError messages may appear if stars that cannot be normalized; in these cases, star index keys are paired with arrays of NaN values in splashSpecs_dict and arrays of 0s in splashIvars_dict (because ivar = 0 for every NaN)\n",
    "splashSpecs_dict, splashIvars_dict, splashSuccess_dict = {}, {}, {}\n",
    "\n",
    "#creates a list of stars with high median ivars to later test against their brightnesses\n",
    "highIvarStars = []\n",
    "\n",
    "#create lists of median ivars for every star (without including NaN or 0 medians)\n",
    "#also sets up dictionaries of star:medianIvar for later use in ivar trimming, etc\n",
    "#note that if a star's spectrum could not be normalized, it will be excluded from these dictionaries (rather than paired with NaNs as was done earlier)\n",
    "wNm_ivarMeds, carbon_ivarMeds, kphOthers_ivarMeds = [], [], []\n",
    "wNm_ivarMeds_dict, carbon_ivarMeds_dict, kphOthers_ivarMeds_dict = {}, {}, {}\n",
    "\n",
    "IVAR_LIMIT = 1000 #an arbitrary constant that acts as the defining limit for what counts as a high-ivar star\n",
    "count = 0 #progress tracker\n",
    "\n",
    "for star in allvalidstars:\n",
    "    #the following lines are done for all stars, as a part of the base dictionary creation\n",
    "    spSlice, normSp, normIv, success = normSpec(star = star, lower = lowerThresh, upper = upperThresh)\n",
    "    splashSpecs_dict[star], splashIvars_dict[star], splashSuccess_dict[star] = normSp, normIv, success\n",
    "    \n",
    "    #now, based on star type (wNm, carbon, other, highIvar), normIv is added to its corresponding list to be used in subsequent ivar trimming and graphs\n",
    "    if success: #if the star could not be normalized, then won't be needed in trimming/statistical analyses\n",
    "        if star in wNm:\n",
    "            med = np.nanmedian(normIv)\n",
    "            if med != 0:\n",
    "                wNm_ivarMeds.append(med); wNm_ivarMeds_dict[star] = med\n",
    "        if star in allcarbon:\n",
    "            med = np.nanmedian(normIv)\n",
    "            if med != 0:\n",
    "                carbon_ivarMeds.append(med); carbon_ivarMeds_dict[star] = med\n",
    "        if star in keckPhotoOthers:\n",
    "            med = np.nanmedian(normIv)\n",
    "            if med != 0:\n",
    "                kphOthers_ivarMeds.append(med); kphOthers_ivarMeds_dict[star] = med\n",
    "        if np.nanmedian(normIv) > IVAR_LIMIT:\n",
    "            highIvarStars.append(star)\n",
    "    \n",
    "    count += 1\n",
    "    if count%1000 == 0:\n",
    "        print(str(count) + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphs the normalized spectrum of any star in SPLASH\n",
    "#inclues the option to graph an already-made template spectrum alongside the normalized spectrum\n",
    "def graphNormSpec(star = None, spectrum = None, lower = lowerThresh, upper = upperThresh, template = False, templateSpec = None, fileName = None):\n",
    "    '''\n",
    "    star: the index of a particular star (with corresponding spectrum) in SPLASH\n",
    "    spectrum: a Numpy array consisting of the data values that represent the flux values of a spectrum to be graphed\n",
    "    lower: the lower boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    upper: the upper boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    template: a Boolean variable that, if True, will graph the normalized spectrum and the template spectrum on the same graph. If False, only the normalized spectrum will be graphed\n",
    "    templateSpec: a Numpy array representing the flux values of the spectrum to be used as the template if template is True\n",
    "    fileName: an optional argument that can be used to save the created graph as a png with the file name designated\n",
    "    \n",
    "    Note that in order to use the template, the functions below that are devoted to template creation must be initialized\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    template will default to False, and templateSpec will default to Ctemplate (the carbon coadd)\n",
    "    star and spectrum will default to None so that either a star index or raw spectral data can be used in the function. Use the inputs that you need based on your data type and leave the other as None\n",
    "    fileName will default to None, meaning the graph will not be saved as a png\n",
    "    \n",
    "    Does not return a particular value, but will produce a graph of wavelength versus flux that represents the normalized spectrum of star\n",
    "    Note that gaps may be present in the spectral graph where NaN values are present in the flux measurements of a certain star\n",
    "    '''\n",
    "    #assigning the data to be graphed\n",
    "    if star is None and np.all(spectrum is None):\n",
    "        print(\"InputError: One of 'star' and 'spectrum' must not be None.\")\n",
    "        return None\n",
    "    if star is not None:\n",
    "        wvrange, spectrum, ivar = normSpec(star = star, lower = lower, upper = upper)[:3]\n",
    "    elif np.all(spectrum is not None):\n",
    "        wvrange, spectrum = data[\"LBIN\"][0][lower:upper], spectrum\n",
    "    x = wvrange.tolist()\n",
    "    y = spectrum.tolist()\n",
    "    \n",
    "    #this if statement separates out the graphing data that is assigned if template is True\n",
    "    if template:\n",
    "        y2 = templateSpec\n",
    "        plt.plot(x, y, color = \"b\", label = \"Normalized Spectrum\")\n",
    "        plt.plot(x, y2, color = \"r\", label = \"Template Spectrum\")\n",
    "        plt.legend(fontsize = 20)\n",
    "    else:\n",
    "        plt.plot(x,y)\n",
    "    \n",
    "    #formatting the graph so that it is easily readable and executing its creation\n",
    "    plt.rcParams['figure.figsize'] = 30,11 \n",
    "    plt.title(\"Normalized Spectrum of Star #\" + str(star), size = 30) \n",
    "    plt.ylabel(\"Flux (normalized)\", size = 20)\n",
    "    plt.xlabel(\"Wavelength\", size = 20) \n",
    "    if fileName is not None:\n",
    "        plt.savefig(fileName)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "#test execution of the function\n",
    "graphNormSpec(star = 10147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a histogram-making function that condenses parameters and has constant defaults that are used in most of our histograms\n",
    "#note: some features of this function are final/set-in-stone, thus only compatible where these features work\n",
    "\n",
    "#version note: defaultHist has not been implemented/used in v2.4.0, go to 2.5.1 to see usage\n",
    "def defaultHist(data, binList, colors, labels, graphLabels, xLim = None, yLim = None, dens=False,alphas = None, step = 0, fileName = None):\n",
    "    '''\n",
    "    main note on this function: everything should be passed in as a tuple - even if a single value, put [ ] around\n",
    "   \n",
    "    data: a tuple containing all the lists of data to plot on the same histogram\n",
    "    binList: the Numpy array to use as bins (used for ALL data populations)\n",
    "    colors: a tuple containing all the colors, corresponding to each sample in data\n",
    "    labels: a tuple containing all the labels, corresponding to each sample in data\n",
    "    graphLabels: a tuple of length 3 containing data for the graph: (1) title, (2) x-label, (3) y-label\n",
    "    dens: a boolean that, if True, will make the histogram a density histogram - default is False\n",
    "    xLim, yLim: if not None, the limits to put on the viewing rectangle of the graph\n",
    "    alphas: a tuple of alpha values (transparency amounts) - default is None (no transparency)\n",
    "    step: if greater than 0, implies a step histogram should be used. value is the line width for the histogram\n",
    "    fileName: if not None, means this plot should be saved as a figure with this file name.\n",
    "    '''\n",
    "    \n",
    "    for index in range(len(data)):\n",
    "        a = 1\n",
    "        if not alphas is None:\n",
    "            a = alphas[index]\n",
    "        if step > 0:\n",
    "            plt.hist(data[index], bins = binList, color = colors[index], label = labels[index], histtype='step', linewidth = step, density = dens, alpha = a)\n",
    "        else:\n",
    "            plt.hist(data[index], bins = binList, color = colors[index], label = labels[index], density = dens, alpha = a)\n",
    "    plt.rcParams['figure.figsize'] = 30,11 \n",
    "    plt.title(graphLabels[0], size = 50) \n",
    "    plt.xlabel(graphLabels[1], size = 40)\n",
    "    plt.ylabel(graphLabels[2], size = 40)\n",
    "    plt.legend(fontsize = 35)\n",
    "\n",
    "    if xLim is not None:\n",
    "        plt.xlim(xLim)\n",
    "    if yLim is not None:\n",
    "        plt.ylim(yLim)\n",
    "    \n",
    "    if fileName is not None:\n",
    "        plt.savefig(fileName)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coadding Spectra\n",
    "Includes sigma clipping for normalized spectral data, coaddition, and graphing functions. Also includes a Gaussian function to smooth spectral graphs. Creates three template spectra to be used in later score calculation methods; these include both a clipped and full-range carbon star template as well as a weak CN star template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that clips out outlier data points in a set of spectra \n",
    "#outliers are defined as points that lie outside of a certain number of standard deviations away from the median flux value at each wavelength\n",
    "def sigmaClip(spectra, ivars, nsigma = 3.5):\n",
    "    '''\n",
    "    spectra: a list of the spectra of each star that is being clipped\n",
    "    ivars: a list of the sets of ivars for each star that is being coadded\n",
    "    nsigma: an integer or float representing the number of standard deviations away from the median to be used in clipping\n",
    "    \n",
    "    nsigma will default to 3.5 unless otherwise specified\n",
    "    spectra and ivar values must be normalized and corresponding for best results\n",
    "    \n",
    "    Returns spectra, a list of the spectra of each star in terms of flux\n",
    "    Also returns ivars, a list of the set of ivars of each star with values corresponding to the invalid values in spectra (those that lie more than nsigma standard deviations away from the median) replaced by 0s\n",
    "    '''\n",
    "    sortedSpecList = []\n",
    "    for value in range(len(spectra[1])): #note that the use of spectra[1] is arbitrary as all of the lists in spectra have the same length\n",
    "        listToAdd = []\n",
    "        for spectrum in range(len(spectra)):\n",
    "            if not np.isnan(spectra[spectrum][value]):\n",
    "                listToAdd.append(spectra[spectrum][value])\n",
    "        sortedSpecList.append(listToAdd)\n",
    "    medians = []\n",
    "    for eachlist in range(len(sortedSpecList)):\n",
    "        if len(sortedSpecList[eachlist]) != 0:\n",
    "            medians.append(st.median(sortedSpecList[eachlist]))\n",
    "        else: \n",
    "            medians.append(np.nan)\n",
    "        if eachlist%100 == 0 and eachlist != 0:\n",
    "            print(str(eachlist) + \" medians calculated.\")\n",
    "    for spectrum in range(len(spectra)):\n",
    "        for flux in range(len(spectra[1])): #see above comment\n",
    "            if np.isnan(medians[flux]):\n",
    "                continue\n",
    "            elif ivars[spectrum][flux] != 0 and not np.isnan(spectra[spectrum][flux]):\n",
    "                testFlux = ((spectra[spectrum][flux] - medians[flux])**2)*ivars[spectrum][flux] \n",
    "                if testFlux > nsigma**2:\n",
    "                    spectra[spectrum][flux] = np.nan\n",
    "                    ivars[spectrum][flux] = 0          \n",
    "    return spectra, ivars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that will coadd normalized spectra based on provided lists of spectra and ivar weights\n",
    "def coadd(spectra, ivars, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    spectra: a list of the spectra of each star that is being coadded\n",
    "    ivars: a list of the sets of ivars for each star that is being coadded\n",
    "    lower: the lower boundary of the range the spectrum have been normalized on, in terms of wavelength\n",
    "    upper: the upper boundary of the range the spectrum have been normalized on, in terms of wavelength\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    spectra and ivar values must be normalized and corresponding for best results\n",
    "    \n",
    "    Returns wvValues_np, a Numpy array containing every wavelength value for which spectral data exists between lower and upper\n",
    "    Also returns coaddedFlux_np, a Numpy array containing the flux values of the coadded spectrum corresponding to each wavelength in wvValues_np \n",
    "    Also returns coaddedIvar_np, a Numpy array containing the ivar values of the coadded spectrum corresponding to each wavelength in  wvValues_np\n",
    "    '''\n",
    "    wvValues = data[\"LBIN\"][0][lower:upper].tolist()\n",
    "    coaddedFlux = []\n",
    "    coaddedIvar = []\n",
    "    for wv in range(len(wvValues)):\n",
    "        fluxSum = 0\n",
    "        ivarSum = 0\n",
    "        for star in range(len(spectra)):\n",
    "            if not np.isnan(spectra[star][wv]): \n",
    "                fluxSum += spectra[star][wv] * ivars[star][wv] #multiplying by ivar as a weight, as per formula\n",
    "                ivarSum += ivars[star][wv]\n",
    "        if ivarSum == 0:\n",
    "            coaddedFlux.append(np.nan)\n",
    "            coaddedIvar.append(0)\n",
    "        else:\n",
    "            newFlux = fluxSum/ivarSum #normalizing the weights, as per formula\n",
    "            coaddedFlux.append(newFlux) #coaddedSpec now contains a coadded spectrum value at each LBIN value\n",
    "            coaddedIvar.append(ivarSum) #coadded ivar is simply the sum of all ivars for a certain bin, across all stars (based on a mathematical proof)\n",
    "    for flux in range(len(coaddedFlux)):\n",
    "        if coaddedFlux[flux] == 0:\n",
    "            coaddedFlux[flux] = np.nan\n",
    "    coaddedFlux_np = np.array(coaddedFlux)\n",
    "    wvValues_np = np.array(wvValues)\n",
    "    coaddedIvar_np = np.array(coaddedIvar)\n",
    "    return wvValues_np, coaddedFlux_np, coaddedIvar_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that applys a smoothing function to a spectrum to improve the quality of the spectrum's graph\n",
    "#used in this program largely for smoothing the graphs of template spectra\n",
    "def applyGauss(spectrum, gauss = 2):\n",
    "    '''\n",
    "    spectrum: a Numpy array containing the flux values of a pre-clipped and normalized (if applicable) star spectrum that will be smoothed\n",
    "    gauss: an optional numerical argument to be used as the standard deviation of the Gaussian kernel\n",
    "    \n",
    "    gauss will default to 2 if no other value is provided (this value was determined based on previous work by A. Kamath)\n",
    "    \n",
    "    Returns smoothSpec, a Numpy array containing the modified/smoothed flux values of the original spectrum\n",
    "    '''\n",
    "    kernel = Gaussian1DKernel(gauss)\n",
    "    smoothSpec = convolve(spectrum, kernel)\n",
    "    return smoothSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that creates a coadded template spectrum by combining several spectra normalized over a certain range\n",
    "def getTempSpec(starIndices, lower = lowerThresh, upper = upperThresh, nsigma = 3.5):\n",
    "    '''\n",
    "    starIndices: an array or list of the indices of the stars to be coadded (which correspond to spectra in SPLASH)\n",
    "    lower: the lower boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    upper: the upper boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    nsigma: a numerical value representing the number of standard deviations away from the flux medians that data for the coaddition will be trimmed to\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    nsigma will default to 3.5 unless another value is provided\n",
    "    \n",
    "    Returns coadd_wv, the set of all wavelength values for which data exists in the final coadded spectrum\n",
    "    Also returns coadd_spec, the set of all flux values that correspond to the wavelength values in coadd_wv for the final coadded spectrum\n",
    "    Also returns coadd_ivar, the number representing the ivar for every wavelength value on the final coadded spectrum\n",
    "    Note that the final spectrum has been created from nsigma clipped data\n",
    "    '''\n",
    "    #creating lists of normalized spectra and ivars for each star to be coadded\n",
    "    spectra = []\n",
    "    ivars = []\n",
    "    for star in starIndices:\n",
    "        if lower == lowerThresh and upper == upperThresh:\n",
    "            spectra.append(splashSpecs_dict[star].tolist())\n",
    "            ivars.append(splashIvars_dict[star].tolist())\n",
    "        else:\n",
    "            starSpec, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "            spectra.append(starSpec.tolist())\n",
    "            ivars.append(starIvar.tolist())\n",
    "    print(\"Step 1 of 3 complete. Normalized spectra and inverse variances loaded.\")\n",
    "\n",
    "    #takes the original data and replaces with NaN values any data points that are greater than nsigma standard deviations from the median\n",
    "    #the median is defined as the median flux at each wavelength when the flux values for every spectrum at that wavelength are considered\n",
    "    spectra_new, ivars_new = sigmaClip(spectra, ivars, nsigma)\n",
    "    print(\"Step 2 of 3 complete. Spectral and ivar data clipped to \" + str(nsigma) + \" sigmas.\")\n",
    "\n",
    "    #performs the coaddition with the edited data from the last step\n",
    "    coadd_wv, coadd_spec, coadd_ivar = coadd(spectra_new, ivars_new, lower, upper)\n",
    "    print(\"Step 3 of 3 complete. Coaddition of spectra and ivars performed and template created.\")\n",
    "    \n",
    "    return coadd_wv, coadd_spec, coadd_ivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctemplate_wv, Ctemplate, Ctemplate_ivar = getTempSpec(allcarbon)\n",
    "Ctemplate_wv_full, Ctemplate_full, Ctemplate_ivar_full = getTempSpec(allcarbon, lower = fullSpec_low, upper = fullSpec_high)\n",
    "Wtemplate_wv, Wtemplate, Wtemplate_ivar = getTempSpec(wNm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphs the limited-range carbon template spectrum created from the above function\n",
    "x = Ctemplate_wv.tolist()\n",
    "y = Ctemplate.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Carbon Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ivar Analysis (Plotting & Trimming)\n",
    "Focuses on analyzing ivars of different stars in other to further process and analyze spectral data. First, creates plots of ivar vs brightness to look for correlation between high ivar and high brightness (as a measure of affirmation that high ivar values are not unfounded). Then, trims the PHAT keckPhotoOthers sample set to match weak CN and carbon in terms of normalized distribution of ivars.\n",
    "End result is two samples of others stars, others1 and others2, which match the weak CN and carbon ivar distributions, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1: Ivar v. Brightness Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a histogram of the F814W data, to get a general sense of the distribution\n",
    "plt.hist(data[\"F814W\"], bins = np.arange(1, 25, 1), range = (1, 25), color = \"b\", alpha = 0.5, label = \"F814W data\")\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"F814W Data\", size = 30) \n",
    "plt.ylabel(\"Frequency\", size = 20)\n",
    "plt.xlabel(\"Magnitude\", size = 20)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the data needed to make a scatter plot of IVAR v MAGNITUDE \n",
    "#goal: check if extremely high ivar is really correct\n",
    "#implementation note: can't use the ivarMeds lists because need to know the star itself (to determine the brightness)\n",
    "x, y, wNm_x, wNm_y, carb_x, carb_y, kphO_x, kphO_y = [], [], [], [], [], [], [], [] #creating lists that will be filled with the coordinates for each star\n",
    "highIvarNaN = wNmIvarNaN = carbIvarNaN = kphOIvarNaN  = 0 #defining counters that will be used to keep track of how many stars have NaN values in the F814W dataset\n",
    "SAMPLE_OTHERS = False #this boolean represents a flag of whether to plot the full photo others (False), or only a 10% sample (True)\n",
    "REMOVE_OVERLAP = True #this boolean represents a flag of whether to remove the high star data from the control data (since that is where they originate from, really)\n",
    "                      #if REMOVE_OVERLAP is true, then the stars in the wNm, carbon, and kphOthers control groups will NOT have the highIvarStars data in them\n",
    "\n",
    "print(\"Flag states:\", \"SAMPLE_OTHERS =\", SAMPLE_OTHERS, 'and', \"REMOVE_OVERLAP =\", REMOVE_OVERLAP)\n",
    "#create the x and y data for the high ivar stars: x = median of ivars, y = F814W magnitude\n",
    "for star in highIvarStars:\n",
    "    x.append(np.nanmedian(splashIvars_dict[star])) #these stars MUST have non-0, non-NaN ivars, due to their construction as \"high ivar stars\"\n",
    "    y.append(data[\"F814W\"][star])\n",
    "    if np.isnan(data[\"F814W\"][star]): #gathering metadata on cardinality of brightness-NaN-subset of highIvar\n",
    "        highIvarNaN += 1\n",
    "        \n",
    "print('The following stars overlap in wNm and highIvarStars.') \n",
    "wNmOverlap = 0\n",
    "for star in wNm: #control group 1: weak CN stars\n",
    "    if star not in wNm_ivarMeds_dict: #ensures that stars whose spectra could not be normalized are skipped over\n",
    "        continue\n",
    "    if not REMOVE_OVERLAP or (REMOVE_OVERLAP and star not in highIvarStars):\n",
    "        med = wNm_ivarMeds_dict[star]\n",
    "        wNm_x.append(med) #if REMOVE_OVERLAP is False, this will be the same as wNm_ivarMeds; otherwise, it is no-highIvarStar clipped version\n",
    "        wNm_y.append(data[\"F814W\"][star])\n",
    "    if star in highIvarStars: #gathering metadata on the stats of high-IVAR stars and their distribution in SPLASH\n",
    "        print(star, \"median ivar =\", med)\n",
    "        wNmOverlap += 1\n",
    "    if np.isnan(data[\"F814W\"][star]): #gathering metadata on cardinality of brightness-NaN-subset of wNm\n",
    "        wNmIvarNaN += 1\n",
    "if wNmOverlap == 0:\n",
    "    print(\"NONE\")\n",
    "        \n",
    "\n",
    "print('The following stars overlap in carbon and highIvarStars.')\n",
    "cOverlap = 0\n",
    "for star in allcarbon: #control group 2: carbon stars\n",
    "    if star not in carbon_ivarMeds_dict: #ensures that stars whose spectra could not be normalized are skipped over\n",
    "        continue\n",
    "    if not REMOVE_OVERLAP or (REMOVE_OVERLAP and star not in highIvarStars):\n",
    "        med = carbon_ivarMeds_dict[star]\n",
    "        carb_x.append(med) #if REMOVE_OVERLAP is False, this will be the same as carbon_ivarMeds; otherwise, it is no-highIvarStar clipped version\n",
    "        carb_y.append(data[\"F814W\"][star])\n",
    "    if star in highIvarStars: #gathering metadata on the stats of high-IVAR stars and their distribution in SPLASH\n",
    "        cOverlap += 1\n",
    "        print(star, \"median ivar =\", med)\n",
    "    if np.isnan(data[\"F814W\"][star]): #gathering metadata on cardinality of brightness-NaN-subset of carbon\n",
    "        carbIvarNaN += 1\n",
    "if cOverlap == 0:\n",
    "    print(\"NONE\")\n",
    "\n",
    "print('The following stars overlap in the control group of PHAT-others and highIvarStars.')\n",
    "oOverlap = 0\n",
    "if SAMPLE_OTHERS:\n",
    "    picker = 0\n",
    "    print('SAMPLE_OTHERS = TRUE, so this is not ALL of the stars in highIvarStars from keckPhotoOthers; since this is a 10% sample, it is likely 10% the actual, larger number.')\n",
    "for star in keckPhotoOthers: #control group 3: keckPhotoOthers (with possibility of randomized 10% subset)\n",
    "    if SAMPLE_OTHERS:\n",
    "        picker += 1\n",
    "        if not picker % 10 == randrange(0, 9, 1): #generates a random number to use, will pick ~1/10 the subset\n",
    "            continue\n",
    "    if star not in kphOthers_ivarMeds_dict: #ensures that stars whose spectra could not be normalized are skipped over\n",
    "        continue\n",
    "    currentMed = kphOthers_ivarMeds_dict[star]\n",
    "    if not REMOVE_OVERLAP or (REMOVE_OVERLAP and star not in highIvarStars):\n",
    "        kphO_x.append(currentMed)\n",
    "        kphO_y.append(data[\"F814W\"][star])\n",
    "    if star in highIvarStars: #gathering metadata on the stats of high-IVAR stars and their distribution in SPLASH\n",
    "        print(star, \"median ivar =\", currentMed)\n",
    "        oOverlap += 1\n",
    "    if np.isnan(data[\"F814W\"][star]):\n",
    "        kphOIvarNaN += 1 #this will likely be 0 (although not certain, due to \"OR\" condition in keckPhotoOthers construction)\n",
    "if oOverlap == 0:\n",
    "    print(\"NONE\")\n",
    "    \n",
    "#printing out metadata for debugging/testing uses        \n",
    "print(\"Brightness NaN counts (highIvar, wNm, carbon, kphO):\", highIvarNaN, wNmIvarNaN, carbIvarNaN, kphOIvarNaN) #check to see how many of each type don't have data in F814W \n",
    "print(\"Total Stars (highIvar, wNm, carbon, kphO):\", len(x), len(wNm_y), len(carb_y), len(kphO_y))\n",
    "print(\"Overlaps (wNm, carbon, kphO):\", wNmOverlap, cOverlap, oOverlap)\n",
    "print(\"Maximum Ivar Found:\", np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the scatter plots of the star ivars vs brightness\n",
    "#note that the dataset is split into the highIvarStars, and wNm and carbon as controls\n",
    "plt.scatter(np.log(x), y, color = 'b', label = \"High-IVAR Stars (varying types)\")\n",
    "plt.scatter(np.log(wNm_x), wNm_y, color = 'orange', alpha = 0.7, label = \"wNm Control Group\")\n",
    "plt.scatter(np.log(carb_x), carb_y, color = 'g', alpha = 0.7, label = \"Carbon Control Group\")\n",
    "plt.scatter(np.log(kphO_x), kphO_y, color = 'r', alpha = 0.3, label = \"PHAT Others Control Group\")\n",
    "\n",
    "#formatting the graph to make it easier to read\n",
    "plt.xlim(-5, 12) #after 17000, just a few outliers (some ~20000, 2 ~ 50000, 1 ~ 180000, 1 ~ 225000), with magnitudes ~16, 15, 13\n",
    "plt.ylim(25, 14)\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"Brightness vs Ivar\", size = 30) \n",
    "plt.ylabel(\"Brightness (Magnitude)\", size = 20)\n",
    "plt.xlabel(\"Natural Log (Median Ivar)\", size = 20)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Ivar Histograms (observing distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a histogram of ivars for different types of stars to provide insight into distribution of uncertainty for wNm, carbon, and other stars\n",
    "binList = np.arange(0, 500, 5)\n",
    "plt.hist(wNm_ivarMeds, bins = binList, color = \"b\", alpha = 0.5, label = \"Weak CN Ivars\")\n",
    "plt.hist(kphOthers_ivarMeds, bins = binList, color = \"g\", alpha = 0.5, label = \"PHAT Other Ivars\")\n",
    "plt.hist(carbon_ivarMeds, bins = binList, color = \"r\", alpha = 0.5, label = \"Carbon Ivars\")\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"Ivar Distribution\", size = 30) \n",
    "plt.ylabel(\"Frequency\", size = 20)\n",
    "plt.xlabel(\"Ivar\", size = 20)\n",
    "\n",
    "#optional y-lim: leave commented out for full version, use for zoomed-in version\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a density histogram of the ivars for different types of stars\n",
    "binList = np.arange(0, 500, 10)\n",
    "plt.hist(wNm_ivarMeds, bins = binList, color = \"b\", alpha = 0.5, label = \"Weak CN Ivars\", density=True)\n",
    "plt.hist(kphOthers_ivarMeds, bins = binList, color = \"g\", alpha = 0.5, label = \"PHAT Other Ivars\", density=True)\n",
    "plt.hist(carbon_ivarMeds, bins = binList, color = \"r\", alpha = 0.5, label = \"Carbon Ivars\", density=True)\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"Ivar Density Distribution\", size = 30) \n",
    "plt.ylabel(\"Density/Probability\", size = 20)\n",
    "plt.xlabel(\"Ivar\", size = 20)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 3: Trimming Based on Ivars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method of ivar trimming: take a ratio based on high-ivar ratio\n",
    "#step 1: create histogram based on log (ivar), step sizes of 1.5\n",
    "binList = np.arange(-6, 6, 0.25) #largest value ~160000\n",
    "wNm_logHighData = plt.hist(np.log(wNm_ivarMeds)/np.log(10), bins = binList, color = \"b\", alpha = 0.5, label = \"Weak CN Ivars\")\n",
    "kphO_logHighData = plt.hist(np.log(kphOthers_ivarMeds)/np.log(10), bins = binList, color = \"g\", alpha = 0.5, label = \"PHAT Other Ivars\")\n",
    "carb_logHighData = plt.hist(np.log(carbon_ivarMeds)/np.log(10), bins = binList, color = \"r\", alpha = 0.5, label = \"Carbon Ivars\")\n",
    "plt.legend(fontsize = 20)\n",
    "plt.title(\"Log(Ivar) Histogram\", fontsize = 30)\n",
    "plt.xlabel(\"Log(Ivar)\", fontsize = 20)\n",
    "plt.ylabel(\"Frequency\", fontsize = 20)\n",
    "plt.ylim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2: find ratios of other stars to wNm and carbon stars at high ivars, which will be applied to lower ivars to clip the sample\n",
    "#finding ratio for others1 (high kphOthers:high wNm)\n",
    "#note: bucket with high-ivar values (log IVAR_LIMIT = log 1000 = 3) is index 36\n",
    "highKphOSum = highwNmSum = 0\n",
    "for i in range(36, len(kphO_logHighData[0])):\n",
    "    highKphOSum += kphO_logHighData[0][i]\n",
    "    highwNmSum += wNm_logHighData[0][i]\n",
    "others1R = highKphOSum/highwNmSum\n",
    "\n",
    "#finding ratio for others2 (kphOthers:carbon) after 10^2.5 (~316)\n",
    "#note: bucket with high-ivar values (log IVAR_LIMIT = log 10^2.5 = 2.5) is index 34\n",
    "highKphOSum = highCarbSum = 0\n",
    "for i in range(34, len(kphO_logHighData[0])):\n",
    "    if not carb_logHighData[0][i] == 0: #stops the ratio from going beyond 700-ish, as the carbon stars are limited by that value but the other stars are not\n",
    "        highKphOSum += kphO_logHighData[0][i]\n",
    "        highCarbSum += carb_logHighData[0][i]\n",
    "others2R = highKphOSum/highCarbSum\n",
    "\n",
    "print('others1:', others1R, '|', 'others2:', others2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for trimStars\n",
    "#defines a function which will give a fraction (probability) to run through trimStars, based on bin-based-ratio\n",
    "def ratioLim(sampleData, medIvar, ratio, modelData):   \n",
    "    '''\n",
    "    algorithm\n",
    "    a. find bin which this ivar falls under\n",
    "    b. multiply the count of weakCN/carbon (model population) by the constant ratio previously created for that bin\n",
    "    c. divide the result of (b) by the total number of stars in the current bin from the kphOthers population (the one to trim)\n",
    "    \n",
    "    sampleData: the dataset that you wish to clip/modify based on ivar\n",
    "    medIvar: the ivar to operate with\n",
    "    ratio: a numerical value representing the ratio of other stars population to model carbon/weak CN population previously found \n",
    "    modelData: the dataset that you are trying to match the sampleData to through ivar clipping\n",
    "    buckets: the buckets with which to operate - if the log-ivar histogram bins are changed, then this must be changed as well\n",
    "    \n",
    "    Note that buckets will default to an array from 0 to 6 with a step size of 0.25 unless otherwise assigned\n",
    "    \n",
    "    Returns a numerical value representing a probability that will be used to choose a certain number of stars from the sample population\n",
    "    '''\n",
    "    buckets = sampleData[1]\n",
    "    logIv = np.log(medIvar)/np.log(10)\n",
    "    step = buckets[1] - buckets[0]\n",
    "    index = int((logIv - buckets[0])/step)\n",
    "    goalCount = ratio*modelData[0][index]\n",
    "    return goalCount/sampleData[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that takes in a sample of stars and trims that sample according to the ivars of those stars\n",
    "def trimStars(starSample, medIvDict, modelData, ratio, sampleData):\n",
    "    '''\n",
    "    starSample: the sample of stars that you wish to trim based on ivar\n",
    "    medIvDict: a dictionary of the median ivars for the stars in starSample; keys are the indices of the stars and values are the median ivars\n",
    "    modelData: the model histogram data for bin-based ratio calculation (wNm_logHighData or carb_logHighData)\n",
    "    ratio: the ratio of other:model to use for trimming the starSample dataset\n",
    "    sampleData: the sample histogram data for bin-based ratio calculation (kphO_logHighData); a 2D array representing the histogram frequencies/bins that were used to find the ratio\n",
    "    \n",
    "    Returns pickStar, an array of Boolean values corresponding to the stars in starSample. True indicates that the star should be selected and False indicates that it should not be selected\n",
    "    Also returns trimmed_ivarMeds, an array containing the median ivar values for each of the stars in the new trimmed sample. In other words, these median ivars correspond to the \"True\"s in the pickStar array\n",
    "    '''\n",
    "    pickStar = np.zeros(len(starSample), dtype = bool)\n",
    "    trimmed_ivarMeds = []\n",
    "    index = 0\n",
    "    for star in starSample: #set to choose from is keckPhotoOthers (not the entire others set)\n",
    "        if star not in medIvDict:\n",
    "            index += 1 #must actually skip this index in pickStar, on top of just moving to next star\n",
    "            continue\n",
    "        starMedIvar = medIvDict[star]\n",
    "        \n",
    "        #find the fraction to pick, and thus probability of picking, based on the function: limFunc(starMedIvar)\n",
    "        pickFraction = ratioLim(sampleData, starMedIvar, ratio, modelData)\n",
    "        if random.random() < pickFraction: #random.random() generates a floating point number from [0.0, 1.0)\n",
    "            pickStar[index] = True #this star will be picked for the new sample\n",
    "            trimmed_ivarMeds.append(starMedIvar) #add this star's median ivar to a list, to plot in the new normalized histogram\n",
    "        index += 1\n",
    "    return pickStar, trimmed_ivarMeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating trimmed others1 and others2 samples based on the ivar-trimming functions above\n",
    "chosenStars1, kphTrimmedOthers1_ivarMeds = trimStars(keckPhotoOthers, kphOthers_ivarMeds_dict, wNm_logHighData, others1R, kphO_logHighData)\n",
    "kphTrimmedOthers1 = np.array(keckPhotoOthers)[chosenStars1]\n",
    "chosenStars2, kphTrimmedOthers2_ivarMeds = trimStars(keckPhotoOthers, kphOthers_ivarMeds_dict, carb_logHighData, others2R, kphO_logHighData)\n",
    "kphTrimmedOthers2 = np.array(keckPhotoOthers)[chosenStars2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: New Ivar Histograms & Analysis of Trimmed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
