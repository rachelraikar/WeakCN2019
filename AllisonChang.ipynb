{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation Version 2.7\n",
    "\n",
    "3/10/19 update - CLASSIFICATION SOLIDIFIED AND FINISHED. Essential goal: analyzes the SPLASH spectra using a variety of different \"score calculation\" methods in order to classify the stars into three groups: carbon stars, weak CN stars, and other/normal stars.\n",
    "\n",
    "    started 3/22/19 - ATTEMPT AT CREATING WCN TEMPLATE BY Rachel and Antara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools needed for data analysis throughout the code\n",
    "import os \n",
    "import numpy as np\n",
    "import random\n",
    "import array as arr\n",
    "import math as m\n",
    "import statistics as st\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import path\n",
    "import seaborn as sns #used for plotting kernel density plots\n",
    "import pandas as pd #used for turning data into dataframes(tables)\n",
    "from astropy.convolution import convolve, Box1DKernel, Gaussian1DKernel \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the folder that necessary program information is stored in\n",
    "#this should be the only thing that needs to change between computers\n",
    "#keep the r at the front, and outside of the string, when pasting in a new pathname\n",
    "pathname = r'/Users/allison/Desktop/SIP/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads the data from the SPLASH fits file\n",
    "hdu = fits.open(os.path.join(pathname, 'subMasterSPLASH2.fits'))\n",
    "#for the SPLASH survey, all data is contained in a single hdu entry, so the variable data contains all the data\n",
    "data = hdu[1].data\n",
    "\n",
    "#reads the data from the keckPHAT fits file\n",
    "hdu2 = fits.open(os.path.join(pathname, 'keckphat_catalog_replaced.fits'))\n",
    "#for the keckPHAT survey, all data is contained in a single hdu entry, so the variable data contains all the data\n",
    "keckPHATdata = hdu2[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters stars based on their ZQUAL scores and keeps only those where ZQUAL = 1, 3, or 4\n",
    "#produces a list of the SPLASH indices of \"valid\" stars (those who meet the ZQUAL condition above)\n",
    "#also produces a list of \"invalid\" star indices (those who have a ZQUAL that is not 1, 3, or 4)\n",
    "validZQUAL = [1, 3, 4]\n",
    "invalidStars = []\n",
    "validStars = []\n",
    "\n",
    "for star in range(data.size):\n",
    "    if data[\"ZQUAL\"][star] in validZQUAL:\n",
    "        validStars.append(star)\n",
    "    else:\n",
    "        invalidStars.append(star)\n",
    "        \n",
    "#converts the lists into arrays for easier manipulation later on if needed\n",
    "allinvalidstars = np.array(invalidStars)\n",
    "allvalidstars = np.array(validStars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates arrays that contain the indices of stars visually identified to be in the categories listed\n",
    "#note that these indices only include stars that were found to be \"valid\" in the previous step\n",
    "others = np.load(os.path.join(pathname, 'validindices', 'nonCarbonOrCNIndices.npy')) #other stars (normal stars)\n",
    "\n",
    "allcarbon = np.load(os.path.join(pathname, 'validindices', 'allCarbonIndices.npy')) #all carbon stars (not CN) \n",
    "wNm = np.load(os.path.join(pathname, 'validindices', 'weakCNIndices.npy')) #weak and marginal CN stars\n",
    "\n",
    "extremes = np.load(os.path.join(pathname, 'validindices', 'extremeCarbonIndices.npy')) #different individual subsets of carbon stars (extremes, strongs, and mediums together make up allcarbon above)\n",
    "strongs = np.load(os.path.join(pathname, 'validindices', 'strongCarbonIndices.npy'))\n",
    "mediums = np.load(os.path.join(pathname, 'validindices', 'mediumCarbonIndices.npy'))\n",
    "\n",
    "weaks = np.load(os.path.join(pathname, 'validindices', 'weakCarbonIndices.npy')) #stars suspected to be CN (weaks and marginals together make up wNm above)\n",
    "marginals = np.load(os.path.join(pathname, 'validindices', 'marginalCarbonIndices.npy'))\n",
    "\n",
    "#creates an array that accomodates for all of the other star indices in SPLASH that were not visually identified/sorted\n",
    "outsiders_list = [i for i in range(data.size) if i not in others and i not in wNm and i not in allcarbon and i not in invalidStars]\n",
    "outsiders = np.array(outsiders_list)\n",
    "\n",
    "#creates sets of different types of stars that can later be used to more quickly test for membership\n",
    "allcarbon_set, wNm_set, others_set = set(), set(), set()\n",
    "allcarbon_set.update(allcarbon); wNm_set.update(wNm); others_set.update(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raja thinks these stars were flagged on the basis of Raja's more careful inspection of zspec notes \n",
    "#Confirm with Alex and Arya\n",
    "flaggedStars = {\"allcarbon\":[19905], \"weaks\":[21466], \"marginals\":[22159, 23248, 24545], \"outsiders\":[23368, 23390]}\n",
    "flaggedStars_list = [19905, 21466, 22159, 23248, 23368, 23390, 24545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of weakCN,carbon,and other stars with photometric data: 8011\n",
      "Individual counts (wNm and allcarbon not limited by photometry, photoOthers limited): 158 98 7760\n"
     ]
    }
   ],
   "source": [
    "#creates a new sample of other/normal stars that is based only on those that have PHAT data\n",
    "#also creates a new sample of stars containing all of the \"other\" stars that have no PHAT data\n",
    "photoOthers, nonphotoOthers, allPhotoStars = [], [], []\n",
    "allPhotoStars_set, photoOthers_set = set(), set() #sets created for easier membership testing\n",
    "\n",
    "filter336, filter475, filter814, filter110, filter160 = data[\"F336W\"].tolist(), data[\"F475W\"].tolist(), data[\"F814W\"].tolist(), data[\"F110W\"].tolist(), data[\"F160W\"].tolist()\n",
    "for star in allvalidstars:\n",
    "    #checks for PHAT data: checking for data in the following filters\n",
    "    identifiedFlag = False #a flag that checks whether the current star is an identified one, used later in creation of nonphotoOthers list\n",
    "    if (not np.isnan(filter336[star]) and filter336[star] < 99) or (not np.isnan(filter475[star]) and filter475[star] < 99) or (not np.isnan(filter814[star]) and filter814[star] < 99) or (not np.isnan(filter110[star]) and filter110[star] < 99) or (not np.isnan(filter160[star]) and filter160[star] < 99):\n",
    "        if star in others_set or star in wNm_set or star in allcarbon_set:\n",
    "            allPhotoStars.append(star)\n",
    "        if star in others_set:\n",
    "            photoOthers.append(star)\n",
    "            identifiedFlag = True\n",
    "    if star in others_set and not identifiedFlag: #if this star is in \"others\" but was not just added to the photoOthers list\n",
    "        nonphotoOthers.append(star)\n",
    "        \n",
    "allPhotoStars_set.update(allPhotoStars)\n",
    "photoOthers_set.update(photoOthers)\n",
    "print(\"Total number of weakCN,carbon,and other stars with photometric data:\", len(allPhotoStars_set))\n",
    "print(\"Individual counts (wNm and allcarbon not limited by photometry, photoOthers limited):\", len(wNm_set), len(allcarbon_set), len(photoOthers_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2858\n"
     ]
    }
   ],
   "source": [
    "#defining a list that consists of bright stars from the photoOthers list\n",
    "bright = [i for i in photoOthers if data['F814W'][i] < 22 and data['F475W'][i] < 24]\n",
    "print(len(bright))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates (mask,slit,objID):index dictionaries to speed up process of finding keckPHAT data for each star\n",
    "keckIndex_dict = {}\n",
    "for i in range(len(keckPHATdata['KOBJNAME'])):\n",
    "    #first pad KSLITNAME with as many 0s as required\n",
    "    slitName = keckPHATdata['KSLITNAME'][i]\n",
    "    slitName = '0'*(3-len(str(slitName))) + str(slitName)\n",
    "    keckIndex_dict[(keckPHATdata['KMASK'][i], slitName, keckPHATdata['KOBJNAME'][i])] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 stars completed.\n",
      "1000 stars completed.\n",
      "1500 stars completed.\n",
      "2000 stars completed.\n",
      "2500 stars completed.\n",
      "3000 stars completed.\n",
      "3500 stars completed.\n",
      "4000 stars completed.\n",
      "4500 stars completed.\n",
      "5000 stars completed.\n",
      "5500 stars completed.\n",
      "6000 stars completed.\n",
      "6500 stars completed.\n",
      "7000 stars completed.\n",
      "7500 stars completed.\n",
      "7760 stars in photoOthers became 5586 stars in keckPhotoOthers.\n"
     ]
    }
   ],
   "source": [
    "#creates the new photoOthers sample based on data from the keckPHAT catalog\n",
    "keckPhotoOthers, nonKeckPhotoOthers = [], []\n",
    "keckPhotoOthers_set, indSet = set(), set()\n",
    "ctr = 0\n",
    "for star in photoOthers:\n",
    "    keckInd = keckIndex_dict[(data['MASK'][star], data['SLITNAME'][star], data['OBJNAME'][star])]\n",
    "    if keckInd in indSet:\n",
    "        print(str(keckInd) + ': duplicate')\n",
    "    indSet.add(keckInd)\n",
    "    if keckPHATdata['BRIGHTFLAG'][keckInd] == 0 and keckPHATdata['CONTFRAC'][keckInd] < 0.5:\n",
    "        keckPhotoOthers.append(star)\n",
    "    else:\n",
    "        nonKeckPhotoOthers.append(star)\n",
    "    ctr += 1\n",
    "    if ctr % 500 == 0:\n",
    "        print(str(ctr) + \" stars completed.\") \n",
    "\n",
    "keckPhotoOthers_set.update(keckPhotoOthers)\n",
    "print(str(len(photoOthers)) + ' stars in photoOthers became ' + str(len(keckPhotoOthers)) + ' stars in keckPhotoOthers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines variables that will be used for clipping spectra to the right wavelength window\n",
    "#goal: isolate the 'W' shaped feature shared by carbon and weak CN stars\n",
    "lowerThresh = 5840         #represents 7796.0 angstroms in data[\"LBIN\"]\n",
    "upperThresh = 6550         #represents 8257.5 angstroms in data[\"LBIN\"]\n",
    "middleThresh = 6184        #represents 8019.6 angstroms in data[\"LBIN\"]; point between the two 'U's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines different \"lower\" and \"upper\" threshold values to be used for normalization and coaddition \n",
    "#with these, the operations will be performed over the entire spectrum instead of just around the 7800-8200 angstrom range\n",
    "fullSpec_low = 0\n",
    "fullSpec_high = len(data[\"LBIN\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing a NaN cut on the stars to eliminate any whose spectra are more than 10% NaNs on the 'W' range\n",
    "NANvalidstars_list = allvalidstars[:].tolist()\n",
    "for star in allvalidstars:\n",
    "    NANcount = 0\n",
    "    for flux in data[\"SPEC\"][star][lowerThresh:upperThresh]:\n",
    "        if np.isnan(flux):\n",
    "            NANcount += 1\n",
    "    if NANcount > 0.1*len(data[\"SPEC\"][star][lowerThresh:upperThresh]):\n",
    "        NANvalidstars_list.remove(star)\n",
    "NANvalidstars = np.array(NANvalidstars_list)\n",
    "\n",
    "#metadata: showing how many stars were cut out of the data due to the NaN limits\n",
    "print(str(len(allvalidstars)) + ' stars became ' + str(len(NANvalidstars)) + ' after the NaN cut.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Spectra\n",
    "Includes spectrum slicing for the raw data, normalization based on median flux, and graphing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that will slice any spectrum to desired wavelengths\n",
    "def sliceSpec(star, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    star: the index of a particular star (with corresponding spectrum) in SPLASH\n",
    "    lower: the lower boundary of the slice, in terms of wavelength\n",
    "    upper: the upper boundary of the slice, in terms of wavelength\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    \n",
    "    Returns newWv, a Numpy array containing every wavelength value between lower and upper for which data exists for a certain star \n",
    "    Also returns newFlux, a Numpy array containing the flux values that (for a certain star) correspond to each of the wavelength values in newSpec\n",
    "    Also returns newIvar, a Numpy array containing the ivar values that (for a certain star) corresopnd to each of the wavelength values in newSpec\n",
    "    '''\n",
    "    newWv = data[\"LBIN\"][star][lower:upper]\n",
    "    newFlux = data[\"SPEC\"][star][lower:upper]\n",
    "    newIvar = data[\"IVAR\"][star][lower:upper]\n",
    "    return newWv, newFlux, newIvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that can be used to normalize the spectrum of a star on a certain wavelength range\n",
    "def normSpec(star = None, spectrum = None, ivars = None, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    star: the index of a particular star (with corresponding spectrum) in SPLASH\n",
    "    spectrum: a Numpy array containing the data that represents the flux values for a spectrum\n",
    "    ivars: a Numpy array containing the data that represents the ivar values for the same spectrum as above\n",
    "    lower: the lower boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    upper: the upper boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    star, spectrum, and ivars all default to None so that either a star index or raw spectral/ivar data can be fed into the function with the same result. Depending on what your data looks like, use the corresponding star or spectrum/ivar inputs and leave the other(s) as None\n",
    "    Only employ one or the other of these inputs when calling this function; do not define both star and spectrum/ivars at the same time \n",
    "    \n",
    "    If the spectrum is found to consist only of NaN values on the range defined by lower and upper:\n",
    "    Returns np.array(wvSlice), a Numpy array containing every wavelength value between lower and upper\n",
    "    Also returns np.array(fluxSlice_list), a Numpy array containing only NaN values that is the same length as np.array(wvSlice)\n",
    "    Also returns np.array(ivarSlice_list), a Numpy array containing only 0's that is the same length as np.array(wvSlice)\n",
    "    Also returns False, which is intended to be used as an argument in other functions to determine spectrum validity.\n",
    "    Note that if this happens, the spectrum will not be normalized and therefore cannot be graphed.\n",
    "    \n",
    "    Otherwise:\n",
    "    Returns wvSlice_np, a Numpy array containing every wavelength value between lower and upper\n",
    "    Also returns normedFlux_np, a Numpy array containing the normalized flux values for a certain star at every wavelength between lower and upper\n",
    "    Also returns normedIvar_np, a Numpy array containing the changed ivar values that correspond to each of the normalized flux values for a certain star in normedSpec_np\n",
    "    Also returns True, which is intended to be used as an argument in other functions to determine spectrum validity.\n",
    "    Note that for normedFlux_np, values within 5 pixels of a nan value that fall outside of 5 standard deviations from the mean flux have been replaced with nan values as well\n",
    "    '''\n",
    "    #converting arrays to list for easy iteration and modification\n",
    "    if star is None and (spectrum is None or ivars is None):\n",
    "        print(\"InputError: missing one or more of the necessary arguments.\")\n",
    "        return np.array(wvSlice), np.array(fluxSlice_list), np.array(ivarSlice_list), False\n",
    "    if star is not None: #if a star index was inputted, get data directly from SPLASH\n",
    "        wvSlice, fluxSlice, ivarSlice = sliceSpec(star, lower, upper)\n",
    "    elif np.all(spectrum is not None) and np.all(ivars is not None): #if a spectrum was inputted, use that as the data\n",
    "        wvSlice, fluxSlice, ivarSlice = data[\"LBIN\"][0][lower:upper], spectrum, ivars\n",
    "    wvSlice_list = wvSlice.tolist()\n",
    "    fluxSlice_list = fluxSlice.tolist()\n",
    "    ivarSlice_list = ivarSlice.tolist()\n",
    "    \n",
    "    #creating a version of the spectrum without any NaNs for performing median/standard deviation calculations\n",
    "    #if the spectrum is all NaNs on the range specified in the function call, will return an error\n",
    "    #if the spectrum is all 0s on the range specified in the function call, will replace the 0s with NaNs and returm am error\n",
    "    newFluxSlice = []\n",
    "    for wv in range(len(fluxSlice_list)):\n",
    "        #in the case of NaN ivars, exactly 0 ivars, or exactly 0 flux values, flux values should be converted into NaN and ivar values to 0 so that the data is not graphed\n",
    "        if fluxSlice_list[wv] == 0 or ivarSlice_list[wv] == 0: \n",
    "            fluxSlice_list[wv] = np.nan\n",
    "            ivarSlice_list[wv] = 0 #seems repetitive due to check in if statement, but necessary for any cases where flux = 0 but ivar does not and needs to be set to 0\n",
    "        elif np.isnan(ivarSlice_list[wv]) or np.isnan(fluxSlice_list[wv]):\n",
    "            ivarSlice_list[wv] = 0\n",
    "        else: #add to \"non-zero, non-NaN\" data\n",
    "            newFluxSlice.append(fluxSlice_list[wv])\n",
    "    if newFluxSlice == []:\n",
    "        print(\"NormalizationError: The spectrum for star \" + str(star) + \" contains only NaN values on the specified range. It cannot be normalized.\")\n",
    "        return np.array(wvSlice), np.array(fluxSlice_list), np.array(ivarSlice_list), False\n",
    "    medianFlux = st.median(newFluxSlice)\n",
    "    spec_mean = st.mean(newFluxSlice)\n",
    "    spec_stdev = st.stdev(newFluxSlice)\n",
    "    upperLim = spec_mean + 5*spec_stdev #limits calculated to clip out values around nan\n",
    "    lowerLim = spec_mean - 5*spec_stdev\n",
    "    \n",
    "    #replaces with np.nan values that are within 5 pixels of a nan value and outside of 5 standard deviations from the mean flux \n",
    "    #accomodates for nan values being located on the edges of the spectrum (in positions where 5 pixels out in either direction would be out of range)\n",
    "    nanIndices = []\n",
    "    for index in range(len(fluxSlice_list)):\n",
    "        if np.isnan(fluxSlice_list[index]): \n",
    "            if 5 < index < len(wvSlice_list) - 5:\n",
    "                for i in range(index-5,index+5):\n",
    "                    if lowerLim > fluxSlice_list[i] or upperLim < fluxSlice_list[i]:\n",
    "                        fluxSlice_list[i] = np.nan\n",
    "            elif 5 > index:\n",
    "                for i in range(0,index+5):\n",
    "                    if lowerLim > fluxSlice_list[i] or upperLim < fluxSlice_list[i]:\n",
    "                        fluxSlice_list[i] = np.nan\n",
    "            elif index > len(wvSlice_list) - 5:\n",
    "                for i in range(index-5, len(wvSlice)): #this should go upto len(specSlice)-1 due to 0-indexing\n",
    "                    if lowerLim > fluxSlice_list[i] or upperLim < fluxSlice_list[i]:\n",
    "                        fluxSlice_list[i] = np.nan\n",
    "\n",
    "    #at each pixel, normalizes the star's spectrum and modifies the corresponding ivar value\n",
    "    normedFlux = []\n",
    "    normedIvar = []\n",
    "    for wv in range(len(wvSlice_list)):\n",
    "        normedFlux.append(fluxSlice_list[wv]/medianFlux)\n",
    "        normedIvar.append(ivarSlice_list[wv]*(medianFlux**2))\n",
    "    \n",
    "    #converts the final products back to arrays for easy manipulation later in the code\n",
    "    normedFlux_np = np.array(normedFlux)\n",
    "    normedIvar_np = np.array(normedIvar)\n",
    "    wvSlice_np = np.array(wvSlice)\n",
    "    \n",
    "    return wvSlice_np, normedFlux_np, normedIvar_np, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creates splashSpecs_dict, a dictionary of the normalized spectra for every valid star in SPLASH, and splashIvars_dict, a dictionary of the normalized ivar values for those same stars\n",
    "#keys are the indices of stars, paired values are arrays representing the flux/ivar values of those stars at every wavelength in the range identified\n",
    "#note that NormalizationError messages may appear if stars that cannot be normalized; in these cases, star index keys are paired with arrays of NaN values in splashSpecs_dict and arrays of 0s in splashIvars_dict (because ivar = 0 for every NaN)\n",
    "splashSpecs_dict, splashIvars_dict, splashSuccess_dict = {}, {}, {}\n",
    "\n",
    "#creates a list of stars with high median ivars to later test against their brightnesses\n",
    "highIvarStars = []\n",
    "\n",
    "#create lists of median ivars for every star (without including NaN or 0 medians)\n",
    "#also sets up dictionaries of star:medianIvar for later use in ivar trimming, etc\n",
    "#note that if a star's spectrum could not be normalized, it will be excluded from these dictionaries (rather than paired with NaNs as was done earlier)\n",
    "wNm_ivarMeds, carbon_ivarMeds, kphOthers_ivarMeds = [], [], []\n",
    "wNm_ivarMeds_dict, carbon_ivarMeds_dict, kphOthers_ivarMeds_dict = {}, {}, {}\n",
    "\n",
    "IVAR_LIMIT = 1000 #an arbitrary constant that acts as the defining limit for what counts as a high-ivar star\n",
    "count = 0 #progress tracker\n",
    "\n",
    "for star in allvalidstars:\n",
    "    #the following lines are done for all stars, as a part of the base dictionary creation\n",
    "    spSlice, normSp, normIv, success = normSpec(star = star, lower = lowerThresh, upper = upperThresh)\n",
    "    splashSpecs_dict[star], splashIvars_dict[star], splashSuccess_dict[star] = normSp, normIv, success\n",
    "    \n",
    "    #now, based on star type (wNm, carbon, other, highIvar), normIv is added to its corresponding list to be used in subsequent ivar trimming and graphs\n",
    "    if success: #if the star could not be normalized, then won't be needed in trimming/statistical analyses\n",
    "        if star in wNm:\n",
    "            med = np.nanmedian(normIv)\n",
    "            if med != 0:\n",
    "                wNm_ivarMeds.append(med); wNm_ivarMeds_dict[star] = med\n",
    "        if star in allcarbon:\n",
    "            med = np.nanmedian(normIv)\n",
    "            if med != 0:\n",
    "                carbon_ivarMeds.append(med); carbon_ivarMeds_dict[star] = med\n",
    "        if star in keckPhotoOthers:\n",
    "            med = np.nanmedian(normIv)\n",
    "            if med != 0:\n",
    "                kphOthers_ivarMeds.append(med); kphOthers_ivarMeds_dict[star] = med\n",
    "        if np.nanmedian(normIv) > IVAR_LIMIT:\n",
    "            highIvarStars.append(star)\n",
    "    \n",
    "    count += 1\n",
    "    if count%1000 == 0:\n",
    "        print(str(count) + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphs the normalized spectrum of any star in SPLASH\n",
    "#inclues the option to graph an already-made template spectrum alongside the normalized spectrum\n",
    "def graphNormSpec(star = None, spectrum = None, lower = lowerThresh, upper = upperThresh, template = False, templateSpec = None, fileName = None):\n",
    "    '''\n",
    "    star: the index of a particular star (with corresponding spectrum) in SPLASH\n",
    "    spectrum: a Numpy array consisting of the data values that represent the flux values of a spectrum to be graphed\n",
    "    lower: the lower boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    upper: the upper boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    template: a Boolean variable that, if True, will graph the normalized spectrum and the template spectrum on the same graph. If False, only the normalized spectrum will be graphed\n",
    "    templateSpec: a Numpy array representing the flux values of the spectrum to be used as the template if template is True\n",
    "    fileName: an optional argument that can be used to save the created graph as a png with the file name designated\n",
    "    \n",
    "    Note that in order to use the template, the functions below that are devoted to template creation must be initialized\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    template will default to False, and templateSpec will default to Ctemplate (the carbon coadd)\n",
    "    star and spectrum will default to None so that either a star index or raw spectral data can be used in the function. Use the inputs that you need based on your data type and leave the other as None\n",
    "    fileName will default to None, meaning the graph will not be saved as a png\n",
    "   \n",
    "    \n",
    "    Does not return a particular value, but will produce a graph of wavelength versus flux that represents the normalized spectrum of star\n",
    "    Note that gaps may be present in the spectral graph where NaN values are present in the flux measurements of a certain star\n",
    "    '''\n",
    "    #assigning the data to be graphed\n",
    "    if star is None and np.all(spectrum is None):\n",
    "        print(\"InputError: One of 'star' and 'spectrum' must not be None.\")\n",
    "        return None\n",
    "    if star is not None:\n",
    "        wvrange, spectrum, ivar = normSpec(star = star, lower = lower, upper = upper)[:3]\n",
    "    elif np.all(spectrum is not None):\n",
    "        wvrange, spectrum = data[\"LBIN\"][0][lower:upper], spectrum\n",
    "    x = wvrange.tolist()\n",
    "    y = spectrum.tolist()\n",
    "    \n",
    "    #this if statement separates out the graphing data that is assigned if template is True\n",
    "    if template is True:  #Antara - changed the default template to Wtemplate (weak CN coadd)\n",
    "        y2 = templateSpec\n",
    "        plt.plot(x, y, color = \"b\", label = \"Normalized Spectrum\")\n",
    "        plt.plot(x, y2, color = \"r\", label = \"Template Spectrum\")\n",
    "        plt.legend(fontsize = 20)\n",
    "    else:\n",
    "        plt.plot(x,y)\n",
    "    \n",
    "    #formatting the graph so that it is easily readable and executing its creation\n",
    "    plt.rcParams['figure.figsize'] = 30,11 \n",
    "    plt.title(\"Normalized Spectrum of Star #\" + str(star), size = 30) \n",
    "    plt.ylabel(\"Flux (normalized)\", size = 20)\n",
    "    plt.xlabel(\"Wavelength\", size = 20) \n",
    "    if fileName is not None:\n",
    "        plt.savefig(fileName)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "#test execution of the function\n",
    "graphNormSpec(star = 10147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a histogram-making function that condenses parameters and has constant defaults that are used in most of our histograms\n",
    "#note: some features of this function are final/set-in-stone, thus only compatible where these features work\n",
    "\n",
    "#version note: defaultHist has not been implemented/used in v2.4.0, go to 2.5.1 to see usage\n",
    "def defaultHist(data, binList, colors, labels, graphLabels, xLim = None, yLim = None, dens=False,alphas = None, step = 0, fileName = None):\n",
    "    '''\n",
    "    main note on this function: everything should be passed in as a tuple - even if a single value, put [ ] around\n",
    "   \n",
    "    data: a tuple containing all the lists of data to plot on the same histogram\n",
    "    binList: the Numpy array to use as bins (used for ALL data populations)\n",
    "    colors: a tuple containing all the colors, corresponding to each sample in data\n",
    "    labels: a tuple containing all the labels, corresponding to each sample in data\n",
    "    graphLabels: a tuple of length 3 containing data for the graph: (1) title, (2) x-label, (3) y-label\n",
    "    dens: a boolean that, if True, will make the histogram a density histogram - default is False\n",
    "    xLim, yLim: if not None, the limits to put on the viewing rectangle of the graph\n",
    "    alphas: a tuple of alpha values (transparency amounts) - default is None (no transparency)\n",
    "    step: if greater than 0, implies a step histogram should be used. value is the line width for the histogram\n",
    "    fileName: if not None, means this plot should be saved as a figure with this file name.\n",
    "    '''\n",
    "    \n",
    "    for index in range(len(data)):\n",
    "        a = 1\n",
    "        if not alphas is None:\n",
    "            a = alphas[index]\n",
    "        if step > 0:\n",
    "            plt.hist(data[index], bins = binList, color = colors[index], label = labels[index], histtype='step', linewidth = step, density = dens, alpha = a)\n",
    "        else:\n",
    "            plt.hist(data[index], bins = binList, color = colors[index], label = labels[index], density = dens, alpha = a)\n",
    "    plt.rcParams['figure.figsize'] = 30,11 \n",
    "    plt.title(graphLabels[0], size = 50) \n",
    "    plt.xlabel(graphLabels[1], size = 40)\n",
    "    plt.ylabel(graphLabels[2], size = 40)\n",
    "    plt.legend(fontsize = 35)\n",
    "\n",
    "    if xLim is not None:\n",
    "        plt.xlim(xLim)\n",
    "    if yLim is not None:\n",
    "        plt.ylim(yLim)\n",
    "    \n",
    "    if fileName is not None:\n",
    "        plt.savefig(fileName)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coadding Spectra\n",
    "Includes sigma clipping for normalized spectral data, coaddition, and graphing functions. Also includes a Gaussian function to smooth spectral graphs. Creates three template spectra to be used in later score calculation methods; these include both a clipped and full-range carbon star template as well as a weak CN star template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that clips out outlier data points in a set of spectra \n",
    "#outliers are defined as points that lie outside of a certain number of standard deviations away from the median flux value at each wavelength\n",
    "def sigmaClip(spectra, ivars, nsigma = 3.5):\n",
    "    '''\n",
    "    spectra: a list of the spectra of each star that is being clipped\n",
    "    ivars: a list of the sets of ivars for each star that is being coadded\n",
    "    nsigma: an integer or float representing the number of standard deviations away from the median to be used in clipping\n",
    "    \n",
    "    nsigma will default to 3.5 unless otherwise specified\n",
    "    spectra and ivar values must be normalized and corresponding for best results\n",
    "    \n",
    "    Returns spectra, a list of the spectra of each star in terms of flux\n",
    "    Also returns ivars, a list of the set of ivars of each star with values corresponding to the invalid values in spectra (those that lie more than nsigma standard deviations away from the median) replaced by 0s\n",
    "    '''\n",
    "    sortedSpecList = []\n",
    "    for value in range(len(spectra[1])): #note that the use of spectra[1] is arbitrary as all of the lists in spectra have the same length\n",
    "        listToAdd = []\n",
    "        for spectrum in range(len(spectra)):\n",
    "            if not np.isnan(spectra[spectrum][value]):\n",
    "                listToAdd.append(spectra[spectrum][value])\n",
    "        sortedSpecList.append(listToAdd)\n",
    "    medians = []\n",
    "    for eachlist in range(len(sortedSpecList)):\n",
    "        if len(sortedSpecList[eachlist]) != 0:\n",
    "            medians.append(st.median(sortedSpecList[eachlist]))\n",
    "        else: \n",
    "            medians.append(np.nan)\n",
    "        if eachlist%100 == 0 and eachlist != 0:\n",
    "            print(str(eachlist) + \" medians calculated.\")\n",
    "    for spectrum in range(len(spectra)):\n",
    "        for flux in range(len(spectra[1])): #see above comment\n",
    "            if np.isnan(medians[flux]):\n",
    "                continue\n",
    "            elif ivars[spectrum][flux] != 0 and not np.isnan(spectra[spectrum][flux]):\n",
    "                testFlux = ((spectra[spectrum][flux] - medians[flux])**2)*ivars[spectrum][flux] \n",
    "                if testFlux > nsigma**2:\n",
    "                    spectra[spectrum][flux] = np.nan\n",
    "                    ivars[spectrum][flux] = 0          \n",
    "    return spectra, ivars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that will coadd normalized spectra based on provided lists of spectra and ivar weights\n",
    "def coadd(spectra, ivars, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    spectra: a list of the spectra of each star that is being coadded\n",
    "    ivars: a list of the sets of ivars for each star that is being coadded\n",
    "    lower: the lower boundary of the range the spectrum have been normalized on, in terms of wavelength\n",
    "    upper: the upper boundary of the range the spectrum have been normalized on, in terms of wavelength\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    spectra and ivar values must be normalized and corresponding for best results\n",
    "    \n",
    "    Returns wvValues_np, a Numpy array containing every wavelength value for which spectral data exists between lower and upper\n",
    "    Also returns coaddedFlux_np, a Numpy array containing the flux values of the coadded spectrum corresponding to each wavelength in wvValues_np \n",
    "    Also returns coaddedIvar_np, a Numpy array containing the ivar values of the coadded spectrum corresponding to each wavelength in  wvValues_np\n",
    "    '''\n",
    "    wvValues = data[\"LBIN\"][0][lower:upper].tolist()\n",
    "    coaddedFlux = []\n",
    "    coaddedIvar = []\n",
    "    for wv in range(len(wvValues)):\n",
    "        fluxSum = 0\n",
    "        ivarSum = 0\n",
    "        for star in range(len(spectra)):\n",
    "            if not np.isnan(spectra[star][wv]): \n",
    "                fluxSum += spectra[star][wv] * ivars[star][wv] #multiplying by ivar as a weight, as per formula\n",
    "                ivarSum += ivars[star][wv]\n",
    "        if ivarSum == 0:\n",
    "            coaddedFlux.append(np.nan)\n",
    "            coaddedIvar.append(0)\n",
    "        else:\n",
    "            newFlux = fluxSum/ivarSum #normalizing the weights, as per formula\n",
    "            coaddedFlux.append(newFlux) #coaddedSpec now contains a coadded spectrum value at each LBIN value\n",
    "            coaddedIvar.append(ivarSum) #coadded ivar is simply the sum of all ivars for a certain bin, across all stars (based on a mathematical proof)\n",
    "    for flux in range(len(coaddedFlux)):\n",
    "        if coaddedFlux[flux] == 0:\n",
    "            coaddedFlux[flux] = np.nan\n",
    "    coaddedFlux_np = np.array(coaddedFlux)\n",
    "    wvValues_np = np.array(wvValues)\n",
    "    coaddedIvar_np = np.array(coaddedIvar)\n",
    "    return wvValues_np, coaddedFlux_np, coaddedIvar_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that applys a smoothing function to a spectrum to improve the quality of the spectrum's graph\n",
    "#used in this program largely for smoothing the graphs of template spectra\n",
    "def applyGauss(spectrum, gauss = 2):\n",
    "    '''\n",
    "    spectrum: a Numpy array containing the flux values of a pre-clipped and normalized (if applicable) star spectrum that will be smoothed\n",
    "    gauss: an optional numerical argument to be used as the standard deviation of the Gaussian kernel\n",
    "    \n",
    "    gauss will default to 2 if no other value is provided (this value was determined based on previous work by A. Kamath)\n",
    "    \n",
    "    Returns smoothSpec, a Numpy array containing the modified/smoothed flux values of the original spectrum\n",
    "    '''\n",
    "    kernel = Gaussian1DKernel(gauss)\n",
    "    smoothSpec = convolve(spectrum, kernel)\n",
    "    return smoothSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that creates a coadded template spectrum by combining several spectra normalized over a certain range\n",
    "def getTempSpec(starIndices, lower = lowerThresh, upper = upperThresh, nsigma = 3.5):\n",
    "    '''\n",
    "    starIndices: an array or list of the indices of the stars to be coadded (which correspond to spectra in SPLASH)\n",
    "    lower: the lower boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    upper: the upper boundary of the range the spectrum will be normalized on, in terms of wavelength\n",
    "    nsigma: a numerical value representing the number of standard deviations away from the flux medians that data for the coaddition will be trimmed to\n",
    "    \n",
    "    lower and upper will default to the lowerThresh and upperThresh values defined above, respectively\n",
    "    nsigma will default to 3.5 unless another value is provided\n",
    "    \n",
    "    Returns coadd_wv, the set of all wavelength values for which data exists in the final coadded spectrum\n",
    "    Also returns coadd_spec, the set of all flux values that correspond to the wavelength values in coadd_wv for the final coadded spectrum\n",
    "    Also returns coadd_ivar, the number representing the ivar for every wavelength value on the final coadded spectrum\n",
    "    Note that the final spectrum has been created from nsigma clipped data\n",
    "    '''\n",
    "    #creating lists of normalized spectra and ivars for each star to be coadded\n",
    "    spectra = []\n",
    "    ivars = []\n",
    "    for star in starIndices:\n",
    "        if lower == lowerThresh and upper == upperThresh:\n",
    "            spectra.append(splashSpecs_dict[star].tolist())\n",
    "            ivars.append(splashIvars_dict[star].tolist())\n",
    "        else:\n",
    "            starSpec, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "            spectra.append(starSpec.tolist())\n",
    "            ivars.append(starIvar.tolist())\n",
    "    print(\"Step 1 of 3 complete. Normalized spectra and inverse variances loaded.\")\n",
    "\n",
    "    #takes the original data and replaces with NaN values any data points that are greater than nsigma standard deviations from the median\n",
    "    #the median is defined as the median flux at each wavelength when the flux values for every spectrum at that wavelength are considered\n",
    "    spectra_new, ivars_new = sigmaClip(spectra, ivars, nsigma)\n",
    "    print(\"Step 2 of 3 complete. Spectral and ivar data clipped to \" + str(nsigma) + \" sigmas.\")\n",
    "\n",
    "    #performs the coaddition with the edited data from the last step\n",
    "    coadd_wv, coadd_spec, coadd_ivar = coadd(spectra_new, ivars_new, lower, upper)\n",
    "    print(\"Step 3 of 3 complete. Coaddition of spectra and ivars performed and template created.\")\n",
    "    \n",
    "    return coadd_wv, coadd_spec, coadd_ivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ctemplate_wv, Ctemplate, Ctemplate_ivar = getTempSpec(allcarbon)\n",
    "Ctemplate_wv_full, Ctemplate_full, Ctemplate_ivar_full = getTempSpec(allcarbon, lower = fullSpec_low, upper = fullSpec_high)\n",
    "Wtemplate_wv, Wtemplate, Wtemplate_ivar = getTempSpec(wNm)\n",
    "Wtemplate_wv_full, Wtemplate_full, Wtemplate_ivar_full = getTempSpec(wNm, lower = fullSpec_low, upper = fullSpec_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#graphs the limited-range carbon template spectrum created from the above function\n",
    "\n",
    "x = Ctemplate_wv.tolist()\n",
    "y = Ctemplate.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Carbon Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Others Template Spectrum\n",
    "Otemplate_wv, Otemplate,Otemplate_ivar = getTempSpec(others)\n",
    "Otemplate_wv_full, Otemplate_full, Otemplate_ivar_full = getTempSpec(others, lower = fullSpec_low, upper = fullSpec_high)\n",
    "\n",
    "x = Otemplate_wv.tolist()\n",
    "y = Otemplate.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Others Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ivar Analysis (Plotting & Trimming)\n",
    "Focuses on analyzing ivars of different stars in order to further process and analyze spectral data. First, creates plots of ivar vs brightness to look for correlation between high ivar and high brightness (as a measure of affirmation that high ivar values are not unfounded). Then, trims the PHAT keckPhotoOthers sample set to match weak CN and carbon in terms of normalized distribution of ivars.\n",
    "End result is two samples of others stars, others1 and others2, which match the weak CN and carbon ivar distributions, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Ivar v. Brightness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a histogram of the F814W data, to get a general sense of the distribution\n",
    "defaultHist([data['F814W'][~np.isnan(data[\"F814W\"])]], np.arange(1, 25), [\"b\"], [\"F814W data\"], (\"F814W Data\", \"Magnitude\", \"Counts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creates the data needed to make a scatter plot of IVAR v MAGNITUDE \n",
    "#goal: check if extremely high ivar is really correct\n",
    "#implementation note: can't use the ivarMeds lists because need to know the star itself (to determine the brightness)\n",
    "x, y, wNm_x, wNm_y, carb_x, carb_y, kphO_x, kphO_y = [], [], [], [], [], [], [], [] #creating lists that will be filled with the coordinates for each star\n",
    "highIvarNaN = wNmIvarNaN = carbIvarNaN = kphOIvarNaN  = 0 #defining counters that will be used to keep track of how many stars have NaN values in the F814W dataset\n",
    "SAMPLE_OTHERS = False #this boolean represents a flag of whether to plot the full photo others (False), or only a 10% sample (True)\n",
    "REMOVE_OVERLAP = True #this boolean represents a flag of whether to remove the high star data from the control data (since that is where they originate from, really)\n",
    "                      #if REMOVE_OVERLAP is true, then the stars in the wNm, carbon, and kphOthers control groups will NOT have the highIvarStars data in them\n",
    "\n",
    "print(\"Flag states:\", \"SAMPLE_OTHERS =\", SAMPLE_OTHERS, 'and', \"REMOVE_OVERLAP =\", REMOVE_OVERLAP)\n",
    "#create the x and y data for the high ivar stars: x = median of ivars, y = F814W magnitude\n",
    "for star in highIvarStars:\n",
    "    x.append(np.nanmedian(splashIvars_dict[star])) #these stars MUST have non-0, non-NaN ivars, due to their construction as \"high ivar stars\"\n",
    "    y.append(data[\"F814W\"][star])\n",
    "    if np.isnan(data[\"F814W\"][star]): #gathering metadata on cardinality of brightness-NaN-subset of highIvar\n",
    "        highIvarNaN += 1\n",
    "        \n",
    "print('The following stars overlap in wNm and highIvarStars.') \n",
    "wNmOverlap = 0\n",
    "for star in wNm: #control group 1: weak CN stars\n",
    "    if star not in wNm_ivarMeds_dict: #ensures that stars whose spectra could not be normalized are skipped over\n",
    "        continue\n",
    "    if not REMOVE_OVERLAP or (REMOVE_OVERLAP and star not in highIvarStars):\n",
    "        med = wNm_ivarMeds_dict[star]\n",
    "        wNm_x.append(med) #if REMOVE_OVERLAP is False, this will be the same as wNm_ivarMeds; otherwise, it is no-highIvarStar clipped version\n",
    "        wNm_y.append(data[\"F814W\"][star])\n",
    "    if star in highIvarStars: #gathering metadata on the stats of high-IVAR stars and their distribution in SPLASH\n",
    "        print(star, \"median ivar =\", med)\n",
    "        wNmOverlap += 1\n",
    "    if np.isnan(data[\"F814W\"][star]): #gathering metadata on cardinality of brightness-NaN-subset of wNm\n",
    "        wNmIvarNaN += 1\n",
    "if wNmOverlap == 0:\n",
    "    print(\"NONE\")\n",
    "        \n",
    "\n",
    "print('The following stars overlap in carbon and highIvarStars.')\n",
    "cOverlap = 0\n",
    "for star in allcarbon: #control group 2: carbon stars\n",
    "    if star not in carbon_ivarMeds_dict: #ensures that stars whose spectra could not be normalized are skipped over\n",
    "        continue\n",
    "    if not REMOVE_OVERLAP or (REMOVE_OVERLAP and star not in highIvarStars):\n",
    "        med = carbon_ivarMeds_dict[star]\n",
    "        carb_x.append(med) #if REMOVE_OVERLAP is False, this will be the same as carbon_ivarMeds; otherwise, it is no-highIvarStar clipped version\n",
    "        carb_y.append(data[\"F814W\"][star])\n",
    "    if star in highIvarStars: #gathering metadata on the stats of high-IVAR stars and their distribution in SPLASH\n",
    "        cOverlap += 1\n",
    "        print(star, \"median ivar =\", med)\n",
    "    if np.isnan(data[\"F814W\"][star]): #gathering metadata on cardinality of brightness-NaN-subset of carbon\n",
    "        carbIvarNaN += 1\n",
    "if cOverlap == 0:\n",
    "    print(\"NONE\")\n",
    "\n",
    "print('The following stars overlap in the control group of PHAT-others and highIvarStars.')\n",
    "oOverlap = 0\n",
    "if SAMPLE_OTHERS:\n",
    "    picker = 0\n",
    "    print('SAMPLE_OTHERS = TRUE, so this is not ALL of the stars in highIvarStars from keckPhotoOthers; since this is a 10% sample, it is likely 10% the actual, larger number.')\n",
    "for star in keckPhotoOthers: #control group 3: keckPhotoOthers (with possibility of randomized 10% subset)\n",
    "    if SAMPLE_OTHERS:\n",
    "        picker += 1\n",
    "        if not picker % 10 == randrange(0, 9, 1): #generates a random number to use, will pick ~1/10 the subset\n",
    "            continue\n",
    "    if star not in kphOthers_ivarMeds_dict: #ensures that stars whose spectra could not be normalized are skipped over\n",
    "        continue\n",
    "    currentMed = kphOthers_ivarMeds_dict[star]\n",
    "    if not REMOVE_OVERLAP or (REMOVE_OVERLAP and star not in highIvarStars):\n",
    "        kphO_x.append(currentMed)\n",
    "        kphO_y.append(data[\"F814W\"][star])\n",
    "    if star in highIvarStars: #gathering metadata on the stats of high-IVAR stars and their distribution in SPLASH\n",
    "        print(star, \"median ivar =\", currentMed)\n",
    "        oOverlap += 1\n",
    "    if np.isnan(data[\"F814W\"][star]):\n",
    "        kphOIvarNaN += 1 #this will likely be 0 (although not certain, due to \"OR\" condition in keckPhotoOthers construction)\n",
    "if oOverlap == 0:\n",
    "    print(\"NONE\")\n",
    "    \n",
    "#printing out metadata for debugging/testing uses        \n",
    "print(\"Brightness NaN counts (highIvar, wNm, carbon, kphO):\", highIvarNaN, wNmIvarNaN, carbIvarNaN, kphOIvarNaN) #check to see how many of each type don't have data in F814W \n",
    "print(\"Total Stars (highIvar, wNm, carbon, kphO):\", len(x), len(wNm_y), len(carb_y), len(kphO_y))\n",
    "print(\"Overlaps (wNm, carbon, kphO):\", wNmOverlap, cOverlap, oOverlap)\n",
    "print(\"Maximum Ivar Found:\", np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the scatter plots of the star ivars vs brightness\n",
    "#note that the dataset is split into the highIvarStars, and wNm and carbon as controls\n",
    "plt.scatter(np.log(x), y, color = 'b', label = \"High-IVAR Stars (varying types)\")\n",
    "plt.scatter(np.log(wNm_x), wNm_y, color = 'orange', alpha = 0.7, label = \"wNm Control Group\")\n",
    "plt.scatter(np.log(carb_x), carb_y, color = 'g', alpha = 0.7, label = \"Carbon Control Group\")\n",
    "plt.scatter(np.log(kphO_x), kphO_y, color = 'r', alpha = 0.3, label = \"PHAT Others Control Group\")\n",
    "\n",
    "#formatting the graph to make it easier to read\n",
    "plt.xlim(-5, 12) #after 17000, just a few outliers (some ~20000, 2 ~ 50000, 1 ~ 180000, 1 ~ 225000), with magnitudes ~16, 15, 13\n",
    "#only 2 kPH stars with ivars < natlog -7\n",
    "plt.ylim(25, 14)\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"Brightness vs Ivar\", size = 30) \n",
    "plt.ylabel(\"Brightness (Magnitude)\", size = 20)\n",
    "plt.xlabel(\"Natural Log (Median Ivar)\", size = 20)\n",
    "plt.legend(fontsize = 20)\n",
    "#plt.savefig('brightVivar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Ivar Histograms (observing distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a histogram of ivars for different types of stars to provide insight into distribution of uncertainty for wNm, carbon, and other stars\n",
    "binList = np.arange(0, 500, 5)\n",
    "defaultHist([wNm_ivarMeds, kphOthers_ivarMeds, carbon_ivarMeds], binList, \n",
    "            ('b', 'g', 'r'), (\"Weak CN Ivars\", \"keck-PHAT Other Ivars\", \"Carbon Ivars\"), (\"Ivar Distribution\", \"Ivar\", \"Counts\"),\n",
    "            yLim = (0,10), alphas = (0.5,0.5,0.5))\n",
    "\n",
    "#note: yLim is optional, remove for full version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a density histogram of the ivars for different types of stars\n",
    "binList = np.arange(0, 500, 10)\n",
    "defaultHist([wNm_ivarMeds, kphOthers_ivarMeds, carbon_ivarMeds], binList, \n",
    "            ('b', 'g', 'r'), (\"Weak CN Ivars\", \"keck-PHAT Other Ivars\", \"Carbon Ivars\"), (\"Ivar Density Distribution\", \"Ivar\", \"Frequency/Density\"),\n",
    "            dens=True, alphas = (0.5,0.5,0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Trimming Based on Ivars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method of ivar trimming: take a ratio based on high-ivar ratio\n",
    "#step 1: create histogram based on log (ivar), step sizes of 1.5\n",
    "binList = np.arange(-6, 6, 0.25) #largest value ~160000\n",
    "\n",
    "wNm_logHighData = plt.hist(np.log(wNm_ivarMeds)/np.log(10), bins = binList, color = \"b\", alpha = 0.5, label = \"Weak CN Ivars\")\n",
    "kphO_logHighData = plt.hist(np.log(kphOthers_ivarMeds)/np.log(10), bins = binList, color = \"g\", alpha = 0.5, label = \"PHAT Other Ivars\")\n",
    "carb_logHighData = plt.hist(np.log(carbon_ivarMeds)/np.log(10), bins = binList, color = \"r\", alpha = 0.5, label = \"Carbon Ivars\")\n",
    "plt.legend(fontsize = 20)\n",
    "plt.title(\"Log(Inverse Variance) Histogram\", fontsize = 40)\n",
    "plt.xlabel(\"Log(Inverse Variance)\", fontsize = 30)\n",
    "plt.ylabel(\"Counts\", fontsize = 30)\n",
    "plt.ylim(0, 200)\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.rcParams['figure.figsize'] = 30, 11\n",
    "#plt.savefig('logivar_histbase.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2: find ratios of other stars to wNm and carbon stars at high ivars, which will be applied to lower ivars to clip the sample\n",
    "#finding ratio for others1 (high kphOthers:high wNm)\n",
    "#note: bucket with high-ivar values (log IVAR_LIMIT = log 1000 = 3) is index 36\n",
    "highKphOSum = highwNmSum = 0\n",
    "for i in range(36, len(kphO_logHighData[0])):\n",
    "    highKphOSum += kphO_logHighData[0][i]\n",
    "    highwNmSum += wNm_logHighData[0][i]\n",
    "others1R = highKphOSum/highwNmSum\n",
    "\n",
    "#finding ratio for others2 (kphOthers:carbon) after 10^2.5 (~316)\n",
    "#note: bucket with high-ivar values (log IVAR_LIMIT = log 10^2.5 = 2.5) is index 34\n",
    "highKphOSum = highCarbSum = 0\n",
    "for i in range(34, len(kphO_logHighData[0])):\n",
    "    if not carb_logHighData[0][i] == 0: #stops the ratio from going beyond 700-ish, as the carbon stars are limited by that value but the other stars are not\n",
    "        highKphOSum += kphO_logHighData[0][i]\n",
    "        highCarbSum += carb_logHighData[0][i]\n",
    "others2R = highKphOSum/highCarbSum\n",
    "\n",
    "print('others1:', others1R, '|', 'others2:', others2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for trimStars\n",
    "#defines a function which will give a fraction (probability) to run through trimStars, based on bin-based-ratio\n",
    "def ratioLim(sampleData, medIvar, ratio, modelData):   \n",
    "    '''\n",
    "    algorithm\n",
    "    a. find bin which this ivar falls under\n",
    "    b. multiply the count of weakCN/carbon (model population) by the constant ratio previously created for that bin\n",
    "    c. divide the result of (b) by the total number of stars in the current bin from the kphOthers population (the one to trim)\n",
    "    \n",
    "    sampleData: the dataset that you wish to clip/modify based on ivar\n",
    "    medIvar: the ivar to operate with\n",
    "    ratio: a numerical value representing the ratio of other stars population to model carbon/weak CN population previously found \n",
    "    modelData: the dataset that you are trying to match the sampleData to through ivar clipping\n",
    "    buckets: the buckets with which to operate - if the log-ivar histogram bins are changed, then this must be changed as well\n",
    "    \n",
    "    Note that buckets will default to an array from 0 to 6 with a step size of 0.25 unless otherwise assigned\n",
    "    \n",
    "    Returns a numerical value representing a probability that will be used to choose a certain number of stars from the sample population\n",
    "    '''\n",
    "    buckets = sampleData[1]\n",
    "    logIv = np.log(medIvar)/np.log(10)\n",
    "    step = buckets[1] - buckets[0]\n",
    "    index = int((logIv - buckets[0])/step)\n",
    "    goalCount = ratio*modelData[0][index]\n",
    "    return goalCount/sampleData[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that takes in a sample of stars and trims that sample according to the ivars of those stars\n",
    "def trimStars(starSample, medIvDict, modelData, ratio, sampleData):\n",
    "    '''\n",
    "    starSample: the sample of stars that you wish to trim based on ivar\n",
    "    medIvDict: a dictionary of the median ivars for the stars in starSample; keys are the indices of the stars and values are the median ivars\n",
    "    modelData: the model histogram data for bin-based ratio calculation (wNm_logHighData or carb_logHighData)\n",
    "    ratio: the ratio of other:model to use for trimming the starSample dataset\n",
    "    sampleData: the sample histogram data for bin-based ratio calculation (kphO_logHighData); a 2D array representing the histogram frequencies/bins that were used to find the ratio\n",
    "    \n",
    "    Returns pickStar, an array of Boolean values corresponding to the stars in starSample. True indicates that the star should be selected and False indicates that it should not be selected\n",
    "    Also returns trimmed_ivarMeds, an array containing the median ivar values for each of the stars in the new trimmed sample. In other words, these median ivars correspond to the \"True\"s in the pickStar array\n",
    "    '''\n",
    "    pickStar = np.zeros(len(starSample), dtype = bool)\n",
    "    trimmed_ivarMeds = []\n",
    "    index = 0\n",
    "    for star in starSample: #set to choose from is keckPhotoOthers (not the entire others set)\n",
    "        if star not in medIvDict:\n",
    "            index += 1 #must actually skip this index in pickStar, on top of just moving to next star\n",
    "            continue\n",
    "        starMedIvar = medIvDict[star]\n",
    "        \n",
    "        #find the fraction to pick, and thus probability of picking, based on the function: limFunc(starMedIvar)\n",
    "        pickFraction = ratioLim(sampleData, starMedIvar, ratio, modelData)\n",
    "        if random.random() < pickFraction: #random.random() generates a floating point number from [0.0, 1.0)\n",
    "            pickStar[index] = True #this star will be picked for the new sample\n",
    "            trimmed_ivarMeds.append(starMedIvar) #add this star's median ivar to a list, to plot in the new normalized histogram\n",
    "        index += 1\n",
    "    return pickStar, trimmed_ivarMeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating trimmed others1 and others2 samples based on the ivar-trimming functions above\n",
    "chosenStars1, kphTrimmedOthers1_ivarMeds = trimStars(keckPhotoOthers, kphOthers_ivarMeds_dict, wNm_logHighData, others1R, kphO_logHighData)\n",
    "kphTrimmedOthers1 = np.array(keckPhotoOthers)[chosenStars1]\n",
    "chosenStars2, kphTrimmedOthers2_ivarMeds = trimStars(keckPhotoOthers, kphOthers_ivarMeds_dict, carb_logHighData, others2R, kphO_logHighData)\n",
    "kphTrimmedOthers2 = np.array(keckPhotoOthers)[chosenStars2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: New Ivar Histograms & Analysis of Trimmed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wNm-based trimming - histogram/data analysis\n",
    "#goal: make the two ivar distributions (others1 and weak CN) as similar as possible\n",
    "print(\"Post-Clipping Size in wNm-Based Trimming:\", len(kphTrimmedOthers1))\n",
    "print(\"Original Size:\", len(keckPhotoOthers))\n",
    "\n",
    "#creating + formatting the histogram\n",
    "binList = np.arange(0, 1000, 10)\n",
    "defaultHist([wNm_ivarMeds, kphTrimmedOthers1_ivarMeds, carbon_ivarMeds], binList, \n",
    "            ('b', 'g', 'r'), (\"Weak CN Ivars\", \"keckPHAT, Trimmed Normal Ivars- 1\", \"Carbon Ivars\"), \n",
    "            (\"Ivar Density Distribution, with Ivar-Trimmed Sample 1 of keckPHAT-Other Stars\", \"Ivar\", \"Frequency/Density\"),\n",
    "             dens=True,alphas = (0.5,0.5,0.5), fileName=\"ivarDensity_hist_others1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carbon-based trimming - histogram/data analysis\n",
    "#goal: make the two ivar distributions (others2 and carbon) as similar as possible\n",
    "print(\"Post-Clipping Size in Carbon-Based Trimming:\", len(kphTrimmedOthers2))\n",
    "print(\"Original Size:\", len(keckPhotoOthers))\n",
    "\n",
    "#creating and formatting the histogram\n",
    "binList = np.arange(0, 1000, 10)\n",
    "defaultHist([wNm_ivarMeds, kphTrimmedOthers2_ivarMeds, carbon_ivarMeds], binList, \n",
    "            ('b', 'g', 'r'), (\"Weak CN Ivars\", \"keckPHAT, Trimmed Normal Ivars- 2\", \"Carbon Ivars\"), \n",
    "            (\"Ivar Density Distribution, with Ivar-Trimmed Sample 2 of keckPHAT-Other Stars\", \"Ivar\", \"Frequency/Density\"),\n",
    "             dens=True,alphas = (0.5,0.5,0.5), fileName=\"ivarDensity_hist_others2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making unbinned cumulative distribution plots, based on a step of 1/N for each data point\n",
    "#step 1: sorting the data\n",
    "wNm_sortedMeds = np.sort(wNm_ivarMeds)\n",
    "carb_sortedMeds = np.sort(carbon_ivarMeds)\n",
    "kphO1_sortedMeds = np.sort(kphTrimmedOthers1_ivarMeds)\n",
    "kphO2_sortedMeds = np.sort(kphTrimmedOthers2_ivarMeds)\n",
    "\n",
    "#step 2: make the cumulative sum as a step function with a step size of 1 / N (where N is set size), so all samples' y's end at 1\n",
    "plt.step(wNm_sortedMeds, np.linspace(0, 1, len(wNm_sortedMeds)), color = 'blue', label = \"weak CN ivars\")\n",
    "plt.step(carb_sortedMeds, np.linspace(0, 1, len(carb_sortedMeds)),  color = 'red', label = \"carbon ivars\")\n",
    "plt.step(kphO1_sortedMeds, np.linspace(0, 1, len(kphO1_sortedMeds)), color = 'green', label = \"others1 trimmed ivars\")\n",
    "plt.step(kphO2_sortedMeds, np.linspace(0, 1, len(kphO2_sortedMeds)), color = 'orange', label = \"others2 trimmed ivars\")\n",
    "\n",
    "#formatting the chart so that it is easy to read\n",
    "plt.title(\"Ivar Cumulative Sum Distribution\", size = 30) \n",
    "plt.xlabel(\"Ivars\", size = 30)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.xlim(0, 1000)\n",
    "#plt.savefig('ivarDistr_cumulativeSum_others1+2_raw.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Further Cleaning of Others2 Data\n",
    "Goal: to make the others2 sample better match the carbon star sample in terms of ivar distribution. Current methods: don't keep any stars with ivar > 700, from 0 - 100 keep only 30% of stars (evenly distributed in range after sorting; i.e. 1, 5, 9 in every interval of 10), and from 450 - 700 keep only 10% of stars (after sorting, only star 4 in every interval of 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performs the clean-up of the others2 sample based on the methods described above\n",
    "keep = []\n",
    "keepIvars = []\n",
    "UPPER_LIM = 700 #no carbon stars have median ivars beyond 700\n",
    "\n",
    "kphTrimmed2_dict = {}\n",
    "for star in kphTrimmedOthers2:\n",
    "    kphTrimmed2_dict[star] = kphOthers_ivarMeds_dict[star] #all stars in kphTrimmedOthers2 are in ivarMeds dictionary, but not vice versa\n",
    "\n",
    "ctr = 1\n",
    "for star in sorted(kphTrimmed2_dict, key = kphTrimmed2_dict.get):\n",
    "    ctr = ctr % 10\n",
    "    keepStar = True\n",
    "    if star not in kphOthers_ivarMeds_dict:\n",
    "        continue\n",
    "    med = kphOthers_ivarMeds_dict[star]\n",
    "    if med > UPPER_LIM: \n",
    "        keepStar = False\n",
    "    if 0 < med < 100: \n",
    "        if ctr % 2 == 0 or ctr == 3 or ctr == 7: #a way of picking 1, 5, 9 values\n",
    "            keepStar = False\n",
    "    if 450 <= med < 700:\n",
    "        if not ctr == 4:\n",
    "            keepStar = False\n",
    "    ctr += 1\n",
    "    if keepStar:\n",
    "        keep.append(star)\n",
    "        keepIvars.append(kphTrimmed2_dict[star])\n",
    "\n",
    "#creates the final trimmed-by-ivar others2 sample, with separate but corresponding median ivars\n",
    "kphTrimmedOthers2, kphTrimmedOthers2_ivarMeds = keep, keepIvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making unbinned cumulative distribution plots, based on a step of 1/N for each data point\n",
    "#step 1: sorting the data\n",
    "wNm_sortedMeds = np.sort(wNm_ivarMeds)\n",
    "carb_sortedMeds = np.sort(carbon_ivarMeds)\n",
    "kphO1_sortedMeds = np.sort(kphTrimmedOthers1_ivarMeds)\n",
    "kphO2select_sortedMeds = np.sort(np.array(kphTrimmedOthers2_ivarMeds))\n",
    "\n",
    "\n",
    "#step 2: make the cumulative sum as a step function with a step size of 1 / N (where N is set size), so all samples' y's end at 1\n",
    "plt.step(wNm_sortedMeds, np.linspace(0, 1, len(wNm_sortedMeds)), color = 'blue', label = \"weak CN ivars\")\n",
    "plt.step(carb_sortedMeds, np.linspace(0, 1, len(carb_sortedMeds)),  color = 'red', label = \"carbon ivars\")\n",
    "plt.step(kphO1_sortedMeds,np.linspace(0, 1, len(kphO1_sortedMeds)), color = 'green', label = \"others1 trimmed ivars\")\n",
    "plt.step(kphO2select_sortedMeds,np.linspace(0, 1, len(kphO2select_sortedMeds)), color = 'orange', label = \"others2 trimmed ivars\")\n",
    "\n",
    "#formatting the chart so that it is easy to read\n",
    "plt.title(\"Inverse Variance Cumulative Sum Distribution (2)\", size = 50) \n",
    "plt.xlabel(\"Inverse Variance\", size = 40)\n",
    "plt.ylabel(\"Cumulative Fraction\", size = 40)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.xlim(0, 1000)\n",
    "plt.rcParams['figure.figsize'] = 30, 11\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "#plt.savefig('ivarDistr_cumulativeSum_others1+2_shaped_final.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Rachel and Antara's Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1 - Unmodified Template\n",
    "Calculates the \"score\" of a star's normalized spectrum by comparing that to a normalized template spectrum and applying a formula that adds up and weights the differences between the two spectra. Note that in method 1, the template spectrum is unmodified.\n",
    "\n",
    "Note: This code was adapted from 2.5.3 and 2.6.1 and edited to calculated scores for a Weak CN template instead of Carbon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a function that calculates the score (a measure of the difference between two spectra) for a certain star's spectrum compared to a certain template spectrum\n",
    "#note that the input spectra and ivars must be already sliced and normalized\n",
    "def getScore(templateSpec, scienceSpec, ivars):\n",
    "    '''\n",
    "    templateSpec: a Numpy array containing the flux values of the coadded template spectrum\n",
    "    scienceSpec: a Numpy array containing the flux values at each wavelength of the normalized spectrum for a specific star\n",
    "    ivars: a Numpy array containing the normalized ivar values at each wavelength of the spectrum for a specific star\n",
    "    \n",
    "    Returns finalScore, a float representing the similarity between the two spectra. A lower score indicates greater similarity and a higher score indicates lower similarity\n",
    "    Note that spectra that cannot be normalized will not have a score associated with them. The function returns a NaN as the score for these spectra\n",
    "    '''\n",
    "    templateSpec_list = templateSpec.tolist()\n",
    "    scienceSpec_list = scienceSpec[~np.isnan(scienceSpec)].tolist()\n",
    "    if scienceSpec_list == []:\n",
    "        print(\"ScoreError: Because this spectrum cannot be normalized, its score cannot be found.\")\n",
    "        return np.nan\n",
    "    else:\n",
    "        summedScore = 0\n",
    "        for wv in range(len(templateSpec_list)):\n",
    "            score = ((scienceSpec[wv] - templateSpec[wv])**2) * ivars[wv]\n",
    "            if not np.isnan(score):\n",
    "                summedScore += score\n",
    "        summedIvars = 0\n",
    "        for ivar in ivars:\n",
    "            if not np.isnan(ivar):\n",
    "                summedIvars += ivar\n",
    "        finalScore = (summedScore/summedIvars)**0.5\n",
    "        return finalScore\n",
    "\n",
    "#test execution of function\n",
    "specStar, ivarStar = splashSpecs_dict[19534],splashIvars_dict[19534]\n",
    "print(\"Score: \" + str(getScore(Wtemplate, specStar, ivarStar)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Analysis Based on the Full-Range 'W'\n",
    "\n",
    "Uses a template spectrum based on the wNm (all weak CN) data set. Compares stars to this template with the aim of being able to sort stars into three distinct populations: weak CN, carbon, and normal/other. Main method of analysis is histograms.\n",
    "\n",
    "Includes Carbon and weak CN template. \n",
    "\n",
    "Scores are divided for weak CN stars based on their scores to both templates. The stars were then divided into two templates: strong-weak CN template and weak-weak template. \n",
    "\n",
    "Strong-weak CN template - scores < median score to template\n",
    "\n",
    "Weak-weak CN template - scores > median score to template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Carbon template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#graphs the limited-range carbon template spectrum \n",
    "\n",
    "x = Ctemplate_wv.tolist()\n",
    "y = Ctemplate.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Carbon Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionaries- Unmodified C Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates dictionaries consisting of every star for which a normalized spectrum can be obtained and a score can be calculated\n",
    "#in these dictionaries, the keys are star indices and the values are the scores associated with those particular stars\n",
    "\n",
    "#Antara - I think this was deleted, I've rewritten it for now, ignoring kphOthers and weak/marginal\n",
    "#kphOthers_Cscore_dict, kphTrO1_Cscore_dict, kphTrO2_Cscore_dict  = {}, {}, {},\n",
    "others_Cscore_dict = {}\n",
    "flaggedStars_Cscore_dict, wNm_Cscore_dict, carbon_Cscore_dict = {}, {}, {} \n",
    "#weak_Cscore_dict, marginal_Cscore_dict = {}, {}\n",
    "\n",
    "#generating the dictionaries and lists simultaneously\n",
    "for star in wNm:\n",
    "    if splashSuccess_dict[star]:\n",
    "        score1 = getScore(Ctemplate, splashSpecs_dict[star], splashIvars_dict[star])\n",
    "        wNm_Cscore_dict[star] = score1\n",
    "        if star in flaggedStars_list:\n",
    "            flaggedStars_Cscore_dict[star] = score1\n",
    "        #if star in weaks:\n",
    "            #weak_Cscore_dict[star] = score1\n",
    "        #else: #the star is a marginal CN star\n",
    "            #marginal_Cscore_dict[star] = score1\n",
    "for star in others: \n",
    "    if splashSuccess_dict[star]:\n",
    "        score2 = getScore(Ctemplate, splashSpecs_dict[star], splashIvars_dict[star])\n",
    "        others_Cscore_dict[star] = score2\n",
    "        if star in flaggedStars_list:\n",
    "            flaggedStars_Cscore_dict[star] = score2\n",
    "        #if star in keckPhotoOthers_set:    \n",
    "         #   kphOthers_Cscore_dict[star] = score2\n",
    "          #  if star in kphTrimmedOthers1: #based on others1\n",
    "           #     kphTrO1_Cscore_dict[star] = score2\n",
    "            #if star in kphTrimmedOthers2: #based on others1\n",
    "             #   kphTrO2_Cscore_dict[star] = score2\n",
    "for star in allcarbon:\n",
    "    if splashSuccess_dict[star]:\n",
    "        score3 = getScore(Ctemplate, splashSpecs_dict[star], splashIvars_dict[star])\n",
    "        carbon_Cscore_dict[star] = score3\n",
    "        if star in flaggedStars_list:\n",
    "            flaggedStars_Cscore_dict[star] = score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (st.mean(carbon_Cscore_dict.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata: stats used to see how the data fits \n",
    "#Rach-changed to Cscore_\n",
    "print(st.mean(carbon_Cscore_dict.values()), st.mean(wNm_Cscore_dict.values()))\n",
    "print(st.median(carbon_Cscore_dict.values()), st.median(wNm_Cscore_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing score - Carbon template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that divides the weak CN stars into two templates based on score to C template\n",
    "# Strong weak CN stars are stars with low scores (score < median)(closest to the science template)\n",
    "# Weak weak CN stars are stars with high scores (score >= median)(furthest to the science template)\n",
    "\n",
    "strong_wCN_Cscore_dict= {} #Antara - name changed to _Cscore_dict to avoid confusion with the weak CN score dictionary\n",
    "weak_wCN_Cscore_dict= {}\n",
    "wCN_Cscore_dict = {}\n",
    "\n",
    "for star,score1 in wNm_Cscore_dict.items():\n",
    "    \n",
    "    if score1 >= st.median(wNm_Cscore_dict.values()):\n",
    "        weak_wCN_Cscore_dict[star] = score1\n",
    "            \n",
    "    else:\n",
    "        strong_wCN_Cscore_dict[star] = score1\n",
    "        \n",
    "    if score1:\n",
    "        wCN_Cscore_dict[star] = score1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double checking the data\n",
    "\n",
    "print ('length of strong_wCN_Cscore_dict = ' + str( len(strong_wCN_Cscore_dict)))\n",
    "print ('length of weak_wCN_Cscore_dict = ' + str( len(weak_wCN_Cscore_dict)))\n",
    "\n",
    "print('min of strong_wCN_Cscore_dict = ' + str( min(strong_wCN_Cscore_dict.values())))\n",
    "print('max of strong_wCN_Cscore_dict = '+ str( max(strong_wCN_Cscore_dict.values())))\n",
    "\n",
    "print('min of weak_wCN_Cscore_dict = ' + str(min(weak_wCN_Cscore_dict.values())))\n",
    "print('min of weak_wCN_Cscore_dict = ' + str( max(weak_wCN_Cscore_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the strong wCN and weak wCN templates using getTempSpec\n",
    "\n",
    "#Rach -changed everything to _Ctemplate\n",
    "strong_wCN_Ctemplate_wv, strong_wCN_Ctemplate, strong_wCN_Ctemplate_ivar = getTempSpec(strong_wCN_Cscore_dict)\n",
    "weak_wCN_Ctemplate_wv, weak_wCN_Ctemplate, weak_wCN_Ctemplate_ivar = getTempSpec(weak_wCN_Cscore_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak WCN Ctemplate (stars > median score)\n",
    "\n",
    "Graphs the weak-weak CN template that was created based on the scores of stars compared to the carbon template. \n",
    "Where scores > median score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphs the limited-range weak weak CN template calculated from scores to C template\n",
    "\n",
    "x = weak_wCN_Ctemplate_wv.tolist()\n",
    "y = weak_wCN_Ctemplate.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Weak Weak CN Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong WCN Ctemplate (stars <median score)\n",
    "\n",
    "Graphs the strong-weak CN template that was created based on the scores of stars compared to the carbon template.\n",
    "Where scores > median score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphs the limited-range weak weak CN template calculated from scores to C template\n",
    "\n",
    "x = strong_wCN_Ctemplate_wv.tolist()\n",
    "y = strong_wCN_Ctemplate.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Strong Weak CN Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double checking the data\n",
    "\n",
    "print ('length of strong_wCN_Cscore_dict = ' + str( len(strong_wCN_Cscore_dict)))\n",
    "print ('length of weak_wCN_Cscore_dict = ' + str( len(weak_wCN_Cscore_dict)))\n",
    "\n",
    "print('min of strong_wCN_Cscore_dict = ' + str( min(strong_wCN_Cscore_dict.values())))\n",
    "print('max of strong_wCN_Cscore_dict = '+ str( max(strong_wCN_Cscore_dict.values())))\n",
    "\n",
    "print('min of weak_wCN_Cscore_dict = ' + str(min(weak_wCN_Cscore_dict.values())))\n",
    "print('min of weak_wCN_Cscore_dict = ' + str( max(weak_wCN_Cscore_dict.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Weak CN template "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionaries - Unmodified W Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphs the limited-range weak CN template spectrum \n",
    "\n",
    "x = Wtemplate_wv.tolist()\n",
    "y = Wtemplate.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Weak CN Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates dictionaries consisting of every star for which a normalized spectrum can be obtained and a score can be calculated\n",
    "#in these dictionaries, the keys are star indices and the values are the scores associated with those particular stars\n",
    "kphOthers_score_dict, kphTrO1_score_dict, kphTrO2_score_dict, others_score_dict = {}, {}, {}, {}\n",
    "flaggedStars_score_dict, wNm_score_dict, carbon_score_dict = {}, {}, {} \n",
    "weak_score_dict, marginal_score_dict = {}, {}\n",
    "\n",
    "#generating the dictionaries and lists simultaneously\n",
    "for star in wNm:\n",
    "    if splashSuccess_dict[star]:\n",
    "        score1 = getScore(Wtemplate, splashSpecs_dict[star], splashIvars_dict[star])\n",
    "        wNm_score_dict[star] = score1\n",
    "        if star in flaggedStars_list:\n",
    "            flaggedStars_score_dict[star] = score1\n",
    "        if star in weaks:\n",
    "            weak_score_dict[star] = score1\n",
    "        else: #the star is a marginal CN star\n",
    "            marginal_score_dict[star] = score1\n",
    "for star in others: \n",
    "    if splashSuccess_dict[star]:\n",
    "        score2 = getScore(Wtemplate, splashSpecs_dict[star], splashIvars_dict[star])\n",
    "        others_score_dict[star] = score2\n",
    "        if star in flaggedStars_list:\n",
    "            flaggedStars_score_dict[star] = score2\n",
    "        if star in keckPhotoOthers_set:    \n",
    "            kphOthers_score_dict[star] = score2\n",
    "            if star in kphTrimmedOthers1: #based on others1\n",
    "                kphTrO1_score_dict[star] = score2\n",
    "            if star in kphTrimmedOthers2: #based on others1\n",
    "                kphTrO2_score_dict[star] = score2\n",
    "for star in allcarbon:\n",
    "    if splashSuccess_dict[star]:\n",
    "        score3 = getScore(Wtemplate, splashSpecs_dict[star], splashIvars_dict[star])\n",
    "        carbon_score_dict[star] = score3\n",
    "        if star in flaggedStars_list:\n",
    "            flaggedStars_score_dict[star] = score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata: stats used to see how the data fits the weak CN hypothesis\n",
    "print(st.mean(carbon_score_dict.values()), st.mean(wNm_score_dict.values()), st.mean(kphOthers_score_dict.values()))\n",
    "print(st.median(carbon_score_dict.values()), st.median(wNm_score_dict.values()), st.median(kphOthers_score_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing Score - weak CN template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#Create a function that divides the weak CN stars into two templates based on score to Weak CN template\n",
    "# Strong weak CN stars are stars with low scores (score < median)(closest to the science template)\n",
    "# Weak weak CN stars are stars with high scores (score >= median)(furthest to the science template)\n",
    "\n",
    "strong_wCN_score_dict = {}\n",
    "weak_wCN_score_dict = {}\n",
    "wCN_score_dict = {}\n",
    "\n",
    "for star,score1 in wNm_score_dict.items():\n",
    "    \n",
    "    if score1 >= st.median(wNm_score_dict.values()):\n",
    "        weak_wCN_score_dict[star] = score1\n",
    "            \n",
    "    else:\n",
    "        strong_wCN_score_dict[star] = score1\n",
    "    \n",
    "    if score1:\n",
    "        wCN_score_dict[star]=score1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#double checking the data\n",
    "#lengths, mins, maxes of the two dictionaries -\n",
    "print(\"lengthof the strong_wCN_score_dict = \" + str(len(strong_wCN_score_dict)))\n",
    "print(\"length of the weak_wCN_score_dict = \"+ str(len(weak_wCN_score_dict)))\n",
    "print(\"min of strong_wCN_score_dict = \" + str(min(strong_wCN_score_dict.values())))\n",
    "print(\"max of strong_wCN_score_dict = \" + str(max(strong_wCN_score_dict.values())))\n",
    "print(\"min of weak_wCN_score_dict = \" + str(min(weak_wCN_score_dict.values())))\n",
    "print(\"min of weak_wCN_score_dict = \" + str(max(weak_wCN_score_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create the strong wcn and weak wcn templates using getTempSpec\n",
    "strong_wCN_template_wv, strong_wCN_template, strong_wCN_template_ivar = getTempSpec(strong_wCN_score_dict)\n",
    "weak_wCN_template_wv, weak_wCN_template, weak_wCN_template_ivar = getTempSpec(weak_wCN_score_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak WCN template (stars > median score)\n",
    "\n",
    "Graphs the weak-weak CN template that was created based on the scores of stars compared to the weak CN template. Where scores > median score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#graphs the Weak-Weak CN template \n",
    "#High score Weak CN stars when compared to Weak CN template\n",
    "\n",
    "x = weak_wCN_template_wv.tolist()\n",
    "y = weak_wCN_template.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Weak Weak CN Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong WCN template (stars <median score)\n",
    "\n",
    "Graphs the strong-weak CN template that was created based on the scores of stars compared to the weak CN template. Where scores < median score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#graphs the Strong-Weak CN template \n",
    "#low score Weak CN stars when compared to Weak CN template\n",
    "\n",
    "x = strong_wCN_template_wv.tolist() \n",
    "y = strong_wCN_template.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Strong Weak CN Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Others Template Spectrum\n",
    "Otemplate_wv, Otemplate,Otemplate_ivar = getTempSpec(others)\n",
    "print('reached')\n",
    "Otemplate_wv_full, Otemplate_full, Otemplate_ivar_full = getTempSpec(others, lower = fullSpec_low, upper = fullSpec_high)\n",
    "print('reached1')\n",
    "x = Otemplate_wv.tolist()\n",
    "y = Otemplate.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Coadded Others Template Spectrum\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Score Histograms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Score histograms to weak CN Template\n",
    "\n",
    "Graphs the scores of all stars when compared to the Weak CN template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plots scores of all stars to the Weak CN template\n",
    "\n",
    "#creates a histogram of the score distributions of valid, able-to-be-normalized stars in SPLASH\n",
    "binList = np.arange(0, 10, 0.02)\n",
    "\n",
    "defaultHist([kphOthers_score_dict.values(),kphTrO1_score_dict.values(),kphTrO2_score_dict.values(),carbon_score_dict.values(),wNm_score_dict.values()],\n",
    "           binList, ['gray','g','orange','r','b'], [\"Entire PHAT Others Sample\", \"Others1 Stars\", \"Others2 Stars\", \"Carbon Stars\", \"Weak CN Stars\"],\n",
    "           [\"Score Distribution\", \"Score\", \"Counts\"], xLim=(0,1),yLim=(0,600), step=3)\n",
    "#entire PHAT others sample is \"ghost\" sample to show differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plots scores of all stars to the Weak CN template\n",
    "#same histogram as above, just zoomed in on the bottom corner so trends in the weak CN and carbon stars can be observed\n",
    "#creates a histogram of the score distributions of valid, able-to-be-normalized stars in SPLASH\n",
    "\n",
    "binList = np.arange(0, 10, 0.02)\n",
    "defaultHist([kphOthers_score_dict.values(),kphTrO1_score_dict.values(),kphTrO2_score_dict.values(),carbon_score_dict.values(),wNm_score_dict.values()],\n",
    "           binList, ['gray','g','orange','r','b'], [\"Entire PHAT Others Sample\", \"Others1 Stars\", \"Others2 Stars\", \"Carbon Stars\", \"Weak CN Stars\"],\n",
    "           [\"Score Distribution - Zoomed\", \"Score\", \"Counts\"], xLim=(0,1),yLim=(0,100), alphas=(0.2,0.5,0.5,0.5,0.5), step = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score histogram for strong-weak CN\n",
    "\n",
    "Graphs the scores of all stars when compared to the Weak CN template. Emphasizes the strong-weak CN scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#Plots scores of all stars to the Weak CN template\n",
    "#emphasizes the scores of strong weak CN stars from Weak CN template\n",
    "binList = np.arange(0, 10, 0.02)\n",
    "defaultHist([wNm_score_dict.values(), carbon_score_dict.values(), strong_wCN_score_dict.values()], binList, [\"blue\", \"red\", \"black\"],[\"Weak CN\",\"Carbon\",\"Strong-Weak CN\"],[\"Score Distribution - Zoomed\", \"Score\", \"Counts\"], xLim=(0,1),yLim=(0,50), alphas=(0.2,0.5,0.5), step = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score histogram of weak-weak CN \n",
    "\n",
    "Graphs the scores of all stars when compared to the Weak CN template. Emphasizes the weak-weak CN scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ALLISON PRACTICE\n",
    "#Plots scores of all stars to the Weak CN template\n",
    "#emphasizes the scores of weak weak CN stars from Weak CN template\n",
    "defaultHist([wNm_score_dict.values(), carbon_score_dict.values(), \n",
    "             weak_wCN_score_dict.values()], binList, [\"blue\", \"red\", \"black\"],\n",
    "            [\"Weak CN\",\"Carbon\",\"Weak-Weak CN\"],[\"Score Distribution - Zoomed\", \"Score\", \"Counts\"], \n",
    "            xLim=(0,1),yLim=(0,50), alphas=(0.2,0.5,0.5), step = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Score histograms to carbon template\n",
    "\n",
    "Graphs the scores of all stars when compared to the carbon template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#Plots scores of all stars to the Carbon template\n",
    "defaultHist([wNm_Cscore_dict.values(), carbon_Cscore_dict.values()], binList, [\"blue\", \"red\"], \n",
    "            [\"Weak CN\", \"Carbon\"],[\"Score Distribution - Zoomed\", \"Score\", \"Counts\"],\n",
    "            xLim=(0,1),yLim=(0,70), alphas=(0.2,0.5,0.5,0.5,0.5), step = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score histogram for strong-weak CN\n",
    "\n",
    "Graphs the scores of all stars when compared to the carbon template. Emphasizes the strong-weak CN scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLSION PRACTICE\n",
    "#Plots scores of all stars to the Carbon template\n",
    "#emphasizes the scores of strong weak CN stars calculated from carbon template\n",
    "defaultHist([wNm_Cscore_dict.values(), carbon_Cscore_dict.values(),weak_wCN_Cscore_dict.values()], binList, [\"blue\", \"red\",\"black\"], \n",
    "            [\"Weak CN\", \"Carbon\",\"Weak-Weak CN\"],[\"Score Distribution - Zoomed\", \"Score\", \"Counts\"],\n",
    "            xLim=(0,1),yLim=(0,70), alphas=(0.5,0.5,1), step = 3)\n",
    "print(weak_wCN_Cscore_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score histogram of weak-weak CN\n",
    "\n",
    "Graphs the scores of all stars when compared to the carbon template. Emphasizes the weak-weak CN scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#Plots scores of all stars to the Carbon template\n",
    "#emphasizes the scores of weak weak CN stars calculated from carbon template\n",
    "\n",
    "\n",
    "defaultHist([wNm_Cscore_dict.values(), carbon_Cscore_dict.values(), \n",
    "             weak_wCN_Cscore_dict.values()], binList, [\"blue\", \"red\", \"black\"],\n",
    "            [\"Weak CN\",\"Carbon\",\"Weak-Weak CN\"],[\"Score Distribution - Zoomed\", \"Score\", \"Counts\"], \n",
    "            xLim=(0,1),yLim=(0,100), alphas=(0.2,0.5,0.5,0.5,0.5), step = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Comparing Strong and Weak WCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Weak wCN  from C and W templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#plotted the Weak Weak CN templates that were calculated from the scores to the Carbon vs Weak CN template\n",
    "#HINT- you have to plot two templates so there will be x1,x2,y1,y2\n",
    "#add labels, titles, and legend\n",
    "\n",
    "x1 = weak_wCN_template_wv.tolist()\n",
    "y1 = weak_wCN_template.tolist()\n",
    "\n",
    "x2 = weak_wCN_Ctemplate_wv.tolist()\n",
    "y2 = weak_wCN_Ctemplate.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x1, y1, label= \"CN Template\")\n",
    "plt.plot(x2,y2, label= \"Carbon Template\")\n",
    "plt.legend(loc=\"upper right\", fontsize=20)\n",
    "plt.title(\"Coadded Weak wCN Templates\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Strong wCN  from C and W templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#plotted the Strong Weak CN templates that were calculated from the scores to the Carbon vs Weak CN template\n",
    "\n",
    "x1 = strong_wCN_template_wv.tolist()\n",
    "y1 = strong_wCN_template.tolist()\n",
    "x2 = strong_wCN_Ctemplate_wv.tolist()\n",
    "y1 = strong_wCN_Ctemplate.tolist()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x1, y1, label= \"CN Template\")\n",
    "plt.plot(x2,y2, label= \"Carbon Template\")\n",
    "plt.legend(loc=\"upper right\", fontsize=20)\n",
    "plt.title(\"Coadded Strong wCN Templates\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Strong vs Weak from W template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#Comparing the Strong weak CN template vs the Weak Weak CN template\n",
    "#Both calculated from scores to the Weak CN template\n",
    "\n",
    "x1 = weak_wCN_template_wv.tolist()\n",
    "y1 = weak_wCN_template.tolist()\n",
    "x2 = strong_wCN_template_wv.tolist()\n",
    "y1 = strong_wCN_template.tolist()\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x1, y1, label= \"Weak wCN Template\")\n",
    "plt.plot(x2,y2, label= \"Strong wCN Template\")\n",
    "plt.legend(loc=\"upper right\", fontsize=20)\n",
    "plt.title(\"Coadded Strong wCN Templates\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Strong vs Weak from C template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLISON PRACTICE\n",
    "#Comparing the Strong weak CN template vs the Weak Weak CN template\n",
    "#Both calculated from scores to the Carbon template\n",
    "\n",
    "x1= weak_wCN_Ctemplate_wv.tolist()\n",
    "y1= weak_wCN_Ctemplate.tolist()\n",
    "x2= strong_wCN_Ctemplate_wv.tolist()\n",
    "y2= strong_wCN_Ctemplate.tolist()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "plt.plot(x1, y1, label= \"Weak wCN Template\")\n",
    "plt.plot(x2,y2, label= \"Strong wCN Template\")\n",
    "plt.legend(loc=\"upper right\", fontsize=20)\n",
    "plt.title(\"Coadded Strong wCN Templates\", size = 30)\n",
    "plt.ylabel(\"Flux (normalized & weighted with ivar)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2 - Modified Diluted Template\n",
    "Calculates the \"score\" of a star's normalized spectrum by comparing that to a normalized template spectrum and applying a formula that adds up and weights the differences between the two spectra. Note that in method 2, the template is tilted and diluted to match the science spectrum. This makes slope and dilution factor (scale) important factors in addition to score.\n",
    "\n",
    "Note: The code was adapted from 2.5.3 and 2.6.1 and edited for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of 2.5.3 and 2.6.1 is taken directly or adapted from Anika Kamath's \"Automation Version 1.4.1.ipynb\" and \"myAstroMods.py.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Modified Diluted C Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines an important variable that will be used for finding the slopes of spectra\n",
    "#the slope will not be calculated based on random points, but on the median point in a small \"window\" at either end of the spectrum\n",
    "slopeWindow = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that calculates the slope of a spectrum's wavelength vs flux graph on a certain interval\n",
    "def getSlope(spectrum, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    spectrum: a list containing the sliced, normalized flux values of the spectrum to be analyzed\n",
    "    lower: the lower boundary of the range the spectrum will be normalized on, in terms of wavelength index in data[\"LBIN\"]\n",
    "    upper: the upper boundary of the range the spectrum will be normalized on, in terms of wavelength index in data[\"LBIN\"]\n",
    "    \n",
    "    lower and upper will default to the previously defined lowerThresh and upperThresh values, respectively\n",
    "    \n",
    "    Returns slope, a numerical value representing the slope of the spectrum on the wavelength range lower to upper\n",
    "    '''\n",
    "    lowerInt, upperInt, = spectrum[:slopeWindow], spectrum[-slopeWindow:]\n",
    "    lowerMedian = np.nanmedian(lowerInt)\n",
    "    upperMedian = np.nanmedian(upperInt)\n",
    "    diff = (data['LBIN'][0][upper] - data['LBIN'][0][lower])\n",
    "    slope = (upperMedian - lowerMedian)/diff\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that modifies the slope of a spectrum by distorting the graph\n",
    "def getTiltedSpec(spectrum, slope, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    spectrum: a Numpy array containing the flux values of a (likely normalized) star spectrum to be modified\n",
    "    slope: a numerical value (most often a float) containing the slope to be applied to the spectrum\n",
    "    lower: the index of the lower boundary of spectrum in data[\"LBIN\"]\n",
    "    upper: the index of the upper boundary of spectrum in data[\"LBIN\"]\n",
    "    \n",
    "    Note that lower and upper will default to the predefined lowerThresh and upperThresh, respectively\n",
    "    \n",
    "    Returns titled, a Numpy array containing the flux values of the adjusted star spectrum\n",
    "    '''\n",
    "    deltaLam = data['LBIN'][0][lower:upper] - data['LBIN'][0][lower] #note that the used of data[\"LBIN\"][0] is arbitrary because all spectra have the same LBIN data values\n",
    "    tilted = slope*deltaLam + spectrum #creating a copy of the spectrum with the new slope\n",
    "    tilted = tilted/np.nanmedian(tilted) #normalizes the spectrum again\n",
    "    return tilted\n",
    "\n",
    "#defines a function that scales a spectrum by either enhancing or reducing spectral features\n",
    "def getScaledSpec(spectrum, c):\n",
    "    '''\n",
    "    spectrum: a Numpy array containing the flux values of a (likely normalized) star spectrum to be scaled\n",
    "    c: a numerical value representing the scale factor by which the spectrum will be modified\n",
    "    \n",
    "    Returns scaledFlux, a Numpy array containing the flux values of the adjusted star spectrum\n",
    "    '''\n",
    "    if c == -1: #accounts for potential divide by zero errors in scaling function\n",
    "        raise ZeroDivisionError(\"c cannot be -1 due to the structure of the scaling formula.\")\n",
    "    scaledFlux = (spectrum + c)/(1+c)\n",
    "    return scaledFlux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a helper function for findOptimalC that produces a list of all the c-values to be tested\n",
    "def getRanger(start, stop, step, zoomStart = None, zoomStop = None, zoomStep = None):\n",
    "    '''\n",
    "    start: a numerical value representing the lowest value of c you want to test\n",
    "    stop: a numerical value representing the highest value of c you want to test\n",
    "    step: a numerical value representing the increment at which you want to create new values of c between start and stop\n",
    "    zoomStart: a numerical value representing the lowest value of c you want to test with a finer step size\n",
    "    zoomStop: a numerical value representing the highest value of c you want to test with a finer step size\n",
    "    zoomStep: a numerical value representing the finer step size to be applied between zoomStop and zoomStart\n",
    "    \n",
    "    Note that zoomStart, zoomStop, and zoomStep will all default to None.\n",
    "    \n",
    "    Returns rangeList, a list of the scale-factor (c) values to be iterated over for a star that is undergoing the template-matching process\n",
    "    '''\n",
    "    rangeList = []\n",
    "    i = start\n",
    "    if zoomStart == None:\n",
    "        zoomStart = start \n",
    "        zoomStop = stop\n",
    "        zoomStep = step\n",
    "    while i < stop:\n",
    "        rangeList.append(i)\n",
    "        if i >= zoomStart and i <= zoomStop: #'zooms in' on a part of the c-range to get smaller c increments just on that range\n",
    "            i += zoomStep \n",
    "        else:\n",
    "            i += step\n",
    "    return rangeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that sorts through the c-values produced by getRanger and returns the c-value and s-value that result in the lowest score\n",
    "def findOptimalC(star, template = Ctemplate_full, lower = lowerThresh, upper = upperThresh, lowC = -15, highC = 60, step = 0.5, zoomStart = None, zoomStop = None, zoomStep = None, trackC = False, gauss = False, nsigma = 10):\n",
    "    '''\n",
    "    Note that default argument values have been denoted with () in the descriptions below\n",
    "    \n",
    "    star: the index of the star for which the template is to be modified to fit and the score is to be calculated\n",
    "    template: (Ctemplate_full) the template spectrum that will be used to compare the spectrum of star to\n",
    "    lower: (lowerThresh) the lower boundary for the spectra of star and template to be normalized on/analyzed on\n",
    "    upper: (upperThresh) the upper boundary for the spectra of star and template to be normalized on/analyzed on\n",
    "    lowC: (-15) the lower boundary for the range of c-values to be tested\n",
    "    highC: (60) the upper boundary for the range of c-values to be tested\n",
    "    step: (0.5) the increment by which c-values between lowC and highC are tested\n",
    "    zoomStart: (None) the lower boundary for a range of c-values to be tested with a finer increment size\n",
    "    zoomStop: (None) the upper boundary for a range of c-values to be tested with a finer increment size\n",
    "    zoomStep: (None) the finer increment size by which c-values between zoomStart and zoomStop are tested\n",
    "    trackC: (False) a Boolean value that, if True, will produce a graph of c-values and their corresponding scores as the function steps through the c-range; if False, the graph will not be produced\n",
    "    gauss: (False) a Boolean value that, if True, will apply a Gaussian smoothing kernel to both the template and science spectra before optimal C is found\n",
    "    nsigma: (10) a numerical value representing the width of the Gaussian kernel that will be used if gauss is True\n",
    "    \n",
    "    Returns bestC, the scale factor that yielded the lowest score\n",
    "    Also returns bestS, the slope that yielded the lowest score (note that this is the version of the slope that has been changed according to the scaled spectrum)\n",
    "    Also returns bestScore, the \"lowest score\" referred to above\n",
    "    '''\n",
    "    if not normSpec(star = star, lower = lower, upper = upper)[3]:\n",
    "        print(\"ScoreError: Because this spectrum cannot be normalized, its score cannot be found.\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "    bestScore = None\n",
    "    bestC, bestS = 0, 0\n",
    "    c_coords, sc_coords = [], []\n",
    "    clipTemplate = template[lower:upper]\n",
    "    starFlux, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "    if gauss:\n",
    "        clipTemplate = applyGauss(clipTemplate, nsigma)\n",
    "        starFlux = applyGauss(starFlux, nsigma)\n",
    "    while all(np.isnan(starFlux[:slopeWindow])) or all(starFlux[:slopeWindow] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[slopeWindow:], starIvar[slopeWindow:], clipTemplate[slopeWindow:]\n",
    "        lower += slopeWindow\n",
    "    while all(np.isnan(starFlux[-slopeWindow:])) or all(starFlux[-slopeWindow:] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[:-slopeWindow], starIvar[:-slopeWindow], clipTemplate[:-slopeWindow]\n",
    "        upper -= slopeWindow\n",
    "    slope = getSlope(starFlux, lower, upper)\n",
    "    for c in getRanger(lowC, highC, step, zoomStart, zoomStop, zoomStep):\n",
    "        if c == -1:\n",
    "            continue\n",
    "        scaledFlux = getScaledSpec(clipTemplate, c)\n",
    "        s = slope - getSlope(scaledFlux, lower, upper)\n",
    "        tiltedFlux = getTiltedSpec(scaledFlux, s, lower, upper)\n",
    "        testScore = getScore(tiltedFlux, starFlux, starIvar)\n",
    "        if trackC:\n",
    "            c_coords.append(c)\n",
    "            sc_coords.append(testScore)\n",
    "        if bestScore == None or testScore < bestScore:\n",
    "            bestC, bestS = c, s\n",
    "            bestScore = testScore\n",
    "    if trackC:\n",
    "        plt.plot(c_coords, sc_coords)\n",
    "        plt.rcParams['figure.figsize'] = 30,11 \n",
    "        plt.title(\"C-Value vs. Score for Star \" + str(star), size = 30) \n",
    "        plt.ylabel(\"Score\", size = 20)\n",
    "        plt.xlabel(\"C (Scale) Value\", size = 20)\n",
    "        plt.legend(fontsize = 20)\n",
    "        plt.ylim(0,0.2)\n",
    "        plt.show()\n",
    "    return bestC, bestS, bestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#defines a function that allows a user to see the modified template \"findOptimalC\" chose as the best match for a star\n",
    "def seeModTemplate(star, c , template = Ctemplate_full, lower = lowerThresh, upper = upperThresh, starSpec = True, unmodified = False, gauss = False, nsigma = 10):\n",
    "    '''\n",
    "    star: the index number of the star that was analyzed with findOptimalC\n",
    "    c: the c (scale) value that was produced when findOptimalC was run on star\n",
    "    template: the template spectrum to be modified\n",
    "    lower: the lower boundary on which the template spectrum is to be modified\n",
    "    upper: the upper boundary on which the template spectrum is to be modified\n",
    "    starSpec: a Boolean value that, if True, will graph star's science spectrum along with the modified template; if False, only the modified template will be graphed\n",
    "    unmodified: a Boolean value that, if True, will graph the unmodified template along with the modified template; if False, only the modified template will be graphed\n",
    "    \n",
    "    Note that template, lower, upper, starSpec, and unmodified default to Ctemplate_full, lowerThresh, upperThresh, True, and False\n",
    "    \n",
    "    This function will return None while also producing a graph of the modified template spectrum along with any other auxilary graphs chosen by the user based on inputs\n",
    "    '''\n",
    "    if not normSpec(star = star, lower = lower, upper = upper)[3]:\n",
    "        print(\"NormalizationError: Because this spectrum cannot be normalized, this method cannot be applied to it.\")\n",
    "        return None\n",
    "    clipTemplate = template[lower:upper]\n",
    "    starFlux, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "   # if gauss:\n",
    "    #    clipTemplate = applyGauss(clipTemplate, nsigma)\n",
    "      #  starFlux = applyGauss(starFlux, nsigma)\n",
    "    while all(np.isnan(starFlux[:slopeWindow])) or all(starFlux[:slopeWindow] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[slopeWindow:], starIvar[slopeWindow:], clipTemplate[slopeWindow:]\n",
    "        lower += slopeWindow\n",
    "    while all(np.isnan(starFlux[-slopeWindow:])) or all(starFlux[-slopeWindow:] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[:-slopeWindow], starIvar[:-slopeWindow], clipTemplate[:-slopeWindow]\n",
    "        upper -= slopeWindow\n",
    "    slope = getSlope(starFlux, lower, upper)\n",
    "    scaledFlux = getScaledSpec(clipTemplate, c)\n",
    "    s = slope - getSlope(scaledFlux, lower, upper)\n",
    "    tiltedFlux = getTiltedSpec(scaledFlux, s, lower, upper)\n",
    "    plt.plot(data[\"LBIN\"][0][lower:upper], tiltedFlux, color = 'b', label = ('Modified Template (C = ' + str(c) +')'))\n",
    "    if starSpec:\n",
    "        plt.plot(data[\"LBIN\"][0][lower:upper], starFlux, color = 'orange', label = 'Science Spectrum')\n",
    "    if unmodified:\n",
    "        plt.plot(data[\"LBIN\"][0][lower:upper], clipTemplate, label = 'Unmodified Template')\n",
    "    plt.rcParams['figure.figsize'] = 30,11 \n",
    "    plt.title(\"Modified Template Comparison for Star \" + str(star), size = 30) \n",
    "    plt.ylabel(\"Flux\", size = 20)\n",
    "    plt.xlabel(\"Wavelength\", size = 20)\n",
    "    plt.legend(fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "seeModTemplate(22198, 0) #22198 allcarbon star\n",
    "#seeModTemplate (20352,0) #20252 wNm star\n",
    "#print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionaries - Modified Diluted C Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creates dictionaries of c, s, and score for each star population based on Method 2:modified diluted template\n",
    "wNm_c_dict, wNm_s_dict, wNm_score2_dict = {}, {}, {}\n",
    "#weak_c_dict, weak_s_dict, weak_score2_dict = {}, {}, {}\n",
    "#marginal_c_dict, marginal_s_dict, marginal_score2_dict = {}, {}, {}\n",
    "carbon_c_dict, carbon_s_dict, carbon_score2_dict = {}, {}, {}\n",
    "#kphTrO1_c_dict, kphTrO1_s_dict, kphTrO1_score2_dict = {}, {}, {}\n",
    "#kphTrO2_c_dict, kphTrO2_s_dict, kphTrO2_score2_dict = {}, {}, {}\n",
    "#kphOthers_c_dict, kphOthers_s_dict, kphOthers_score2_dict = {}, {}, {}\n",
    "others_c_dict, others_s_dict, others_score2_dict = {}, {}, {}\n",
    "#flaggedStars_c_dict, flaggedStars_s_dict, flaggedStars_score2_dict = {}, {}, {}\n",
    "\n",
    "#generates the sample of stars to be used in the dictionaries (excludes outsiders)\n",
    "useStars = []\n",
    "useStars.extend(wNm); useStars.extend(allcarbon); useStars.extend(others)\n",
    "#useStars.extend(kphTrimmedOthers1); useStars.extend(kphTrimmedOthers2)\n",
    "\n",
    "\n",
    "#generates the dictionaries and keeps track of progress with a counter\n",
    "ctr = 0\n",
    "for star in useStars:\n",
    "    if not splashSuccess_dict[star]:\n",
    "        ctr += 1\n",
    "        if ctr % 100 == 0:\n",
    "            print(ctr)\n",
    "        continue\n",
    "    c, s, sc = findOptimalC(star)\n",
    "    ctr += 1\n",
    "    #if star in flaggedStars_list:\n",
    "    #    flaggedStars_c_dict[star], flaggedStars_s_dict[star], flaggedStars_score2_dict[star] = c, s, sc\n",
    "    if star in wNm:\n",
    "        wNm_c_dict[star], wNm_s_dict[star], wNm_score2_dict[star] = c, s, sc\n",
    "        #if star in weaks:\n",
    "        #    weak_c_dict[star], weak_s_dict[star], weak_score2_dict[star] = c, s, sc\n",
    "        #if star in marginals:\n",
    "         #   marginal_c_dict[star], marginal_s_dict[star], marginal_score2_dict[star] = c, s, sc\n",
    "    if star in allcarbon:\n",
    "        carbon_c_dict[star], carbon_s_dict[star], carbon_score2_dict[star] = c, s, sc\n",
    "    if star in others:\n",
    "        others_c_dict[star], others_s_dict[star], others_score2_dict[star] = c, s, sc\n",
    "        \n",
    "    ''' #commented this section out for now-Rachel\n",
    "       if star in keckPhotoOthers:\n",
    "            kphOthers_c_dict[star], kphOthers_s_dict[star], kphOthers_score2_dict[star] = c, s, sc\n",
    "            if star in kphTrimmedOthers1:\n",
    "                kphTrO1_c_dict[star], kphTrO1_s_dict[star], kphTrO1_score2_dict[star] = c, s, sc\n",
    "            if star in kphTrimmedOthers2: #cannot use 'else' because kphTrimmedOthers1 and kphTrimmedOthers2 overlap\n",
    "                kphTrO2_c_dict[star], kphTrO2_s_dict[star], kphTrO2_score2_dict[star] = c, s, sc\n",
    "                '''\n",
    "    if ctr % 100 == 0:\n",
    "        print(ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Modified Diluted W Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that sorts through the c-values produced by getRanger and returns the c-value and s-value that result in the lowest score\n",
    "def findWOptimalC(star, template = Wtemplate_full, lower = lowerThresh, upper = upperThresh, lowC = -15, highC = 60, step = 0.5, zoomStart = None, zoomStop = None, zoomStep = None, trackC = False, gauss = False, nsigma = 10):\n",
    "    '''\n",
    "    Note that default argument values have been denoted with () in the descriptions below\n",
    "    \n",
    "    star: the index of the star for which the template is to be modified to fit and the score is to be calculated\n",
    "    template: (Ctemplate_full) the template spectrum that will be used to compare the spectrum of star to\n",
    "    lower: (lowerThresh) the lower boundary for the spectra of star and template to be normalized on/analyzed on\n",
    "    upper: (upperThresh) the upper boundary for the spectra of star and template to be normalized on/analyzed on\n",
    "    lowC: (-15) the lower boundary for the range of c-values to be tested\n",
    "    highC: (60) the upper boundary for the range of c-values to be tested\n",
    "    step: (0.5) the increment by which c-values between lowC and highC are tested\n",
    "    zoomStart: (None) the lower boundary for a range of c-values to be tested with a finer increment size\n",
    "    zoomStop: (None) the upper boundary for a range of c-values to be tested with a finer increment size\n",
    "    zoomStep: (None) the finer increment size by which c-values between zoomStart and zoomStop are tested\n",
    "    trackC: (False) a Boolean value that, if True, will produce a graph of c-values and their corresponding scores as the function steps through the c-range; if False, the graph will not be produced\n",
    "    gauss: (False) a Boolean value that, if True, will apply a Gaussian smoothing kernel to both the template and science spectra before optimal C is found\n",
    "    nsigma: (10) a numerical value representing the width of the Gaussian kernel that will be used if gauss is True\n",
    "    \n",
    "    Returns bestC, the scale factor that yielded the lowest score\n",
    "    Also returns bestS, the slope that yielded the lowest score (note that this is the version of the slope that has been changed according to the scaled spectrum)\n",
    "    Also returns bestScore, the \"lowest score\" referred to above\n",
    "    '''\n",
    "    if not normSpec(star = star, lower = lower, upper = upper)[3]:\n",
    "        print(\"ScoreError: Because this spectrum cannot be normalized, its score cannot be found.\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "    bestScore = None\n",
    "    bestC, bestS = 0, 0\n",
    "    c_coords, sc_coords = [], []\n",
    "    clipTemplate = template[lower:upper]\n",
    "    starFlux, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "    if gauss:\n",
    "        clipTemplate = applyGauss(clipTemplate, nsigma)\n",
    "        starFlux = applyGauss(starFlux, nsigma)\n",
    "    while all(np.isnan(starFlux[:slopeWindow])) or all(starFlux[:slopeWindow] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[slopeWindow:], starIvar[slopeWindow:], clipTemplate[slopeWindow:]\n",
    "        lower += slopeWindow\n",
    "    while all(np.isnan(starFlux[-slopeWindow:])) or all(starFlux[-slopeWindow:] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[:-slopeWindow], starIvar[:-slopeWindow], clipTemplate[:-slopeWindow]\n",
    "        upper -= slopeWindow\n",
    "    slope = getSlope(starFlux, lower, upper)\n",
    "    for c in getRanger(lowC, highC, step, zoomStart, zoomStop, zoomStep):\n",
    "        if c == -1:\n",
    "            continue\n",
    "        scaledFlux = getScaledSpec(clipTemplate, c)\n",
    "        s = slope - getSlope(scaledFlux, lower, upper)\n",
    "        tiltedFlux = getTiltedSpec(scaledFlux, s, lower, upper)\n",
    "        testScore = getScore(tiltedFlux, starFlux, starIvar)\n",
    "        if trackC:\n",
    "            c_coords.append(c)\n",
    "            sc_coords.append(testScore)\n",
    "        if bestScore == None or testScore < bestScore:\n",
    "            bestC, bestS = c, s\n",
    "            bestScore = testScore\n",
    "    if trackC:\n",
    "        plt.plot(c_coords, sc_coords)\n",
    "        plt.rcParams['figure.figsize'] = 30,11 \n",
    "        plt.title(\"C-Value vs. Score for Star \" + str(star), size = 30) \n",
    "        plt.ylabel(\"Score\", size = 20)\n",
    "        plt.xlabel(\"C (Scale) Value\", size = 20)\n",
    "        plt.legend(fontsize = 20)\n",
    "        plt.ylim(0,0.2)\n",
    "        plt.show()\n",
    "    return bestC, bestS, bestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that allows a user to see the modified template \"findOptimalC\" chose as the best match for a star\n",
    "def seeModWTemplate(star, c , template = Wtemplate_full, lower = lowerThresh, upper = upperThresh, starSpec = True, unmodified = False, gauss = False, nsigma = 10):\n",
    "    '''\n",
    "    star: the index number of the star that was analyzed with findOptimalC\n",
    "    c: the c (scale) value that was produced when findOptimalC was run on star\n",
    "    template: the template spectrum to be modified\n",
    "    lower: the lower boundary on which the template spectrum is to be modified\n",
    "    upper: the upper boundary on which the template spectrum is to be modified\n",
    "    starSpec: a Boolean value that, if True, will graph star's science spectrum along with the modified template; if False, only the modified template will be graphed\n",
    "    unmodified: a Boolean value that, if True, will graph the unmodified template along with the modified template; if False, only the modified template will be graphed\n",
    "    \n",
    "    Note that template, lower, upper, starSpec, and unmodified default to Ctemplate_full, lowerThresh, upperThresh, True, and False\n",
    "    \n",
    "    This function will return None while also producing a graph of the modified template spectrum along with any other auxilary graphs chosen by the user based on inputs\n",
    "    '''\n",
    "    if not normSpec(star = star, lower = lower, upper = upper)[3]:\n",
    "        print(\"NormalizationError: Because this spectrum cannot be normalized, this method cannot be applied to it.\")\n",
    "        return None\n",
    "    clipTemplate = template[lower:upper]\n",
    "    starFlux, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "   # if gauss:\n",
    "    #    clipTemplate = applyGauss(clipTemplate, nsigma)\n",
    "      #  starFlux = applyGauss(starFlux, nsigma)\n",
    "    while all(np.isnan(starFlux[:slopeWindow])) or all(starFlux[:slopeWindow] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[slopeWindow:], starIvar[slopeWindow:], clipTemplate[slopeWindow:]\n",
    "        lower += slopeWindow\n",
    "    while all(np.isnan(starFlux[-slopeWindow:])) or all(starFlux[-slopeWindow:] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[:-slopeWindow], starIvar[:-slopeWindow], clipTemplate[:-slopeWindow]\n",
    "        upper -= slopeWindow\n",
    "    slope = getSlope(starFlux, lower, upper)\n",
    "    scaledFlux = getScaledSpec(clipTemplate, c)\n",
    "    s = slope - getSlope(scaledFlux, lower, upper)\n",
    "    tiltedFlux = getTiltedSpec(scaledFlux, s, lower, upper)\n",
    "    plt.plot(data[\"LBIN\"][0][lower:upper], tiltedFlux, color = 'b', label = ('Modified Template (C = ' + str(c) +')'))\n",
    "    if starSpec:\n",
    "        plt.plot(data[\"LBIN\"][0][lower:upper], starFlux, color = 'orange', label = 'Science Spectrum')\n",
    "    if unmodified:\n",
    "        plt.plot(data[\"LBIN\"][0][lower:upper], clipTemplate, label = 'Unmodified Template')\n",
    "    plt.rcParams['figure.figsize'] = 30,11 \n",
    "    plt.title(\"Modified Template Comparison for Star \" + str(star), size = 30) \n",
    "    plt.ylabel(\"Flux\", size = 20)\n",
    "    plt.xlabel(\"Wavelength\", size = 20)\n",
    "    plt.legend(fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "seeModTemplate(20352, 0) #22198 allcarbon star\n",
    "#seeModTemplate (20352,0) #20252 wNm star\n",
    "#print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dictionaries - Modified Diluted W Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creates dictionaries of c, s, and score for each star population based on Method 2:modified diluted template\n",
    "wNm_c_wdict, wNm_s_wdict, wNm_score2_wdict = {}, {}, {}\n",
    "#weak_c_wdict, weak_s_wdict, weak_score2_wdict = {}, {}, {}\n",
    "#marginal_c_wdict, marginal_s_wdict, marginal_score2_wdict = {}, {}, {}\n",
    "carbon_c_wdict, carbon_s_wdict, carbon_score2_wdict = {}, {}, {}\n",
    "#kphTrO1_c_wdict, kphTrO1_s_wdict, kphTrO1_score2_wdict = {}, {}, {}\n",
    "#kphTrO2_c_wdict, kphTrO2_s_wdict, kphTrO2_score2_wdict = {}, {}, {}\n",
    "#kphOthers_c_wdict, kphOthers_s_wdict, kphOthers_score2_wdict = {}, {}, {}\n",
    "others_c_wdict, others_s_wdict, others_score2_wdict = {}, {}, {}\n",
    "#flaggedStars_c_wdict, flaggedStars_s_wdict, flaggedStars_score2_wdict = {}, {}, {}\n",
    "\n",
    "#generates the sample of stars to be used in the dictionaries (excludes outsiders)\n",
    "useStars_w = []\n",
    "useStars_w.extend(wNm); useStars_w.extend(allcarbon); useStars_w.extend(others)\n",
    "#useStars.extend(kphTrimmedOthers1); useStars.extend(kphTrimmedOthers2)\n",
    "\n",
    "\n",
    "#generates the dictionaries and keeps track of progress with a counter\n",
    "ctr = 0\n",
    "for star in useStars_w:\n",
    "    if not splashSuccess_dict[star]:\n",
    "        ctr += 1\n",
    "        if ctr % 100 == 0:\n",
    "            print(ctr)\n",
    "        continue\n",
    "    c, s, sc = findWOptimalC(star)\n",
    "    ctr += 1\n",
    "    #if star in flaggedStars_list:\n",
    "    #    flaggedStars_c_wdict[star], flaggedStars_s_wdict[star], flaggedStars_score2_wdict[star] = c, s, sc\n",
    "    if star in wNm:\n",
    "        wNm_c_wdict[star], wNm_s_wdict[star], wNm_score2_wdict[star] = c, s, sc\n",
    "        #if star in weaks:\n",
    "        #    weak_c_wdict[star], weak_s_wdict[star], weak_score2_wdict[star] = c, s, sc\n",
    "        #if star in marginals:\n",
    "         #   marginal_c_wdict[star], marginal_s_wdict[star], marginal_score2_wdict[star] = c, s, sc\n",
    "    if star in allcarbon:\n",
    "        carbon_c_wdict[star], carbon_s_wdict[star], carbon_score2_wdict[star] = c, s, sc\n",
    "    if star in others:\n",
    "        others_c_wdict[star], others_s_wdict[star], others_score2_wdict[star] = c, s, sc\n",
    "        \n",
    "    ''' #commented this section out for now-Rachel\n",
    "       if star in keckPhotoOthers:\n",
    "            kphOthers_c_wdict[star], kphOthers_s_wdict[star], kphOthers_score2_wdict[star] = c, s, sc\n",
    "            if star in kphTrimmedOthers1:\n",
    "                kphTrO1_c_wdict[star], kphTrO1_s_wdict[star], kphTrO1_score2_wdict[star] = c, s, sc\n",
    "            if star in kphTrimmedOthers2: #cannot use 'else' because kphTrimmedOthers1 and kphTrimmedOthers2 overlap\n",
    "                kphTrO2_c_wdict[star], kphTrO2_s_wdict[star], kphTrO2_score2_wdict[star] = c, s, sc\n",
    "                '''\n",
    "    if ctr % 100 == 0:\n",
    "        print(ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Analysis Based on the Full-Range 'W' - Diluted C Template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allison practice\n",
    "#creating a histogram that displays the score2's for weak CN, carbon,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allison practice\n",
    "#creating a DENSITY histogram that displays the score2's for weak CN, carbon\n",
    "\n",
    "#formatting the graph so that it is easier to read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allison practice\n",
    "\n",
    "#creating a histogram that displays the c-values for weak CN, carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allison practice\n",
    "#creating a histogram that displays the s-values for weak CN, carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allison practice\n",
    "#creates a scatter plot of score vs. scale for weak CN, carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allison practice\n",
    "#creates a scatter plot of score1 vs. score2 for weak CN, carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allison practice\n",
    "#creates a scatter plot of score1 vs. scale for weak CN, carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allison practice\n",
    "#plot optimal dilution factor vs score against diluted C template (carbon and weak cn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allison practice\n",
    "#plot optimal dilution factor vs score against diluted W template (carbon and weak cn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3 - Undiluted Weak CN template \n",
    "\n",
    "Score calculations with slope adjustment with no dilution factor (c=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Undiluted W Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rachel- renamed seeModTemplate2 to seeModWtemplate2\n",
    "\n",
    "#Antara - rewrote this section for spectra that are only tilted and not scaled\n",
    "#made c=0 everywhere so that spectrum+c/1+c makes no change in spectrum scaling\n",
    "#also entirely rewrote getRanger, and made some other less extreme changes to the other functions\n",
    "\n",
    "\n",
    "#defines an important variable that will be used for finding the slopes of spectra\n",
    "#the slope will not be calculated based on random points, but on the median point in a small \"window\" at either end of the spectrum\n",
    "slopeWindow = 25\n",
    "\n",
    "#defines a function that calculates the slope of a spectrum's wavelength vs flux graph on a certain interval\n",
    "def getSlope2(spectrum, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    spectrum: a list containing the sliced, normalized flux values of the spectrum to be analyzed\n",
    "    lower: the lower boundary of the range the spectrum will be normalized on, in terms of wavelength index in data[\"LBIN\"]\n",
    "    upper: the upper boundary of the range the spectrum will be normalized on, in terms of wavelength index in data[\"LBIN\"]\n",
    "    \n",
    "    lower and upper will default to the previously defined lowerThresh and upperThresh values, respectively\n",
    "    \n",
    "    Returns slope, a numerical value representing the slope of the spectrum on the wavelength range lower to upper\n",
    "    '''\n",
    "    lowerInt, upperInt, = spectrum[:slopeWindow], spectrum[-slopeWindow:]\n",
    "    lowerMedian = np.nanmedian(lowerInt)\n",
    "    upperMedian = np.nanmedian(upperInt)\n",
    "    diff = (data['LBIN'][0][upper] - data['LBIN'][0][lower])\n",
    "    slope = (upperMedian - lowerMedian)/diff\n",
    "    return slope\n",
    "\n",
    "#defines a function that modifies the slope of a spectrum by distorting the graph\n",
    "def getTiltedSpec2(spectrum, slope, lower = lowerThresh, upper = upperThresh):\n",
    "    '''\n",
    "    spectrum: a Numpy array containing the flux values of a (likely normalized) star spectrum to be modified\n",
    "    slope: a numerical value (most often a float) containing the slope to be applied to the spectrum\n",
    "    lower: the index of the lower boundary of spectrum in data[\"LBIN\"]\n",
    "    upper: the index of the upper boundary of spectrum in data[\"LBIN\"]\n",
    "    \n",
    "    Note that lower and upper will default to the predefined lowerThresh and upperThresh, respectively\n",
    "    \n",
    "    Returns titled, a Numpy array containing the flux values of the adjusted star spectrum\n",
    "    '''\n",
    "    deltaLam = data['LBIN'][0][lower:upper] - data['LBIN'][0][lower] #note that the used of data[\"LBIN\"][0] is arbitrary because all spectra have the same LBIN data values\n",
    "    tilted = slope*deltaLam + spectrum #creating a copy of the spectrum with the new slope\n",
    "    tilted = tilted/np.nanmedian(tilted) #normalizes the spectrum again\n",
    "    return tilted\n",
    "\n",
    "#defines a function that scales a spectrum by either enhancing or reducing spectral features\n",
    "def getScaledSpec2(spectrum, c):\n",
    "    '''\n",
    "    spectrum: a Numpy array containing the flux values of a (likely normalized) star spectrum to be scaled\n",
    "    c: a numerical value representing the scale factor by which the spectrum will be modified\n",
    "    \n",
    "    Returns scaledFlux, a Numpy array containing the flux values of the adjusted star spectrum\n",
    "    '''\n",
    "    if c == -1: #accounts for potential divide by zero errors in scaling function\n",
    "        raise ZeroDivisionError(\"c cannot be -1 due to the structure of the scaling formula.\")\n",
    "    scaledFlux = (spectrum + c)/(1+c)\n",
    "    return scaledFlux\n",
    "\n",
    "\n",
    "#defines a helper function for findOptimalC that produces a list of all the c-values to be tested\n",
    "def getRanger2(start, stop, step, zoomStart = None, zoomStop = None, zoomStep = None):\n",
    "    '''\n",
    "    start: a numerical value representing the lowest value of c you want to test\n",
    "    stop: a numerical value representing the highest value of c you want to test\n",
    "    step: a numerical value representing the increment at which you want to create new values of c between start and stop\n",
    "    zoomStart: a numerical value representing the lowest value of c you want to test with a finer step size\n",
    "    zoomStop: a numerical value representing the highest value of c you want to test with a finer step size\n",
    "    zoomStep: a numerical value representing the finer step size to be applied between zoomStop and zoomStart\n",
    "    \n",
    "    Note that zoomStart, zoomStop, and zoomStep will all default to None.\n",
    "    \n",
    "    Returns rangeList, a list of the scale-factor (c) values to be iterated over for a star that is undergoing the template-matching process\n",
    "    '''\n",
    "    rangeList = []\n",
    "    c = 0\n",
    "    rangeList.append(c)\n",
    "    return rangeList\n",
    "    \n",
    "    #Previous code from 2.6\n",
    "    ''' \n",
    "    if zoomStart == None:\n",
    "        zoomStart = start \n",
    "        zoomStop = stop\n",
    "        zoomStep = step\n",
    "    while i < stop:\n",
    "        rangeList.append(i)\n",
    "        if i >= zoomStart and i <= zoomStop: #'zooms in' on a part of the c-range to get smaller c increments just on that range\n",
    "            i += zoomStep \n",
    "        else:\n",
    "            i += step\n",
    "    return rangeList\n",
    "    '''\n",
    "\n",
    "#defines a function that sorts through the c-values produced by getRanger and returns the c-value and s-value that result in the lowest score\n",
    "def findWOptimalC2(star, template = Wtemplate_full, lower = lowerThresh, upper = upperThresh, lowC = -15, highC = 60, step = 0.5, zoomStart = None, zoomStop = None, zoomStep = None, trackC = False, gauss = False, nsigma = 10):\n",
    "    '''\n",
    "    Note that default argument values have been denoted with () in the descriptions below\n",
    "    \n",
    "    star: the index of the star for which the template is to be modified to fit and the score is to be calculated\n",
    "    template: (Ctemplate_full) the template spectrum that will be used to compare the spectrum of star to\n",
    "    lower: (lowerThresh) the lower boundary for the spectra of star and template to be normalized on/analyzed on\n",
    "    upper: (upperThresh) the upper boundary for the spectra of star and template to be normalized on/analyzed on\n",
    "    lowC: (-15) the lower boundary for the range of c-values to be tested\n",
    "    highC: (60) the upper boundary for the range of c-values to be tested\n",
    "    step: (0.5) the increment by which c-values between lowC and highC are tested\n",
    "    zoomStart: (None) the lower boundary for a range of c-values to be tested with a finer increment size\n",
    "    zoomStop: (None) the upper boundary for a range of c-values to be tested with a finer increment size\n",
    "    zoomStep: (None) the finer increment size by which c-values between zoomStart and zoomStop are tested\n",
    "    trackC: (False) a Boolean value that, if True, will produce a graph of c-values and their corresponding scores as the function steps through the c-range; if False, the graph will not be produced\n",
    "    gauss: (False) a Boolean value that, if True, will apply a Gaussian smoothing kernel to both the template and science spectra before optimal C is found\n",
    "    nsigma: (10) a numerical value representing the width of the Gaussian kernel that will be used if gauss is True\n",
    "    \n",
    "    Returns bestC, the scale factor that yielded the lowest score\n",
    "    Also returns bestS, the slope that yielded the lowest score (note that this is the version of the slope that has been changed according to the scaled spectrum)\n",
    "    Also returns bestScore, the \"lowest score\" referred to above\n",
    "    '''\n",
    "    if not normSpec(star = star, lower = lower, upper = upper)[3]:\n",
    "        print(\"ScoreError: Because this spectrum cannot be normalized, its score cannot be found.\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "    bestScore = None\n",
    "    bestC, bestS = 0, 0\n",
    "    c_coords, sc_coords = [], []\n",
    "    clipTemplate = template[lower:upper]\n",
    "    starFlux, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "    if gauss:\n",
    "        clipTemplate = applyGauss(clipTemplate, nsigma)\n",
    "        starFlux = applyGauss(starFlux, nsigma)\n",
    "    while all(np.isnan(starFlux[:slopeWindow])) or all(starFlux[:slopeWindow] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[slopeWindow:], starIvar[slopeWindow:], clipTemplate[slopeWindow:]\n",
    "        lower += slopeWindow\n",
    "    while all(np.isnan(starFlux[-slopeWindow:])) or all(starFlux[-slopeWindow:] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[:-slopeWindow], starIvar[:-slopeWindow], clipTemplate[:-slopeWindow]\n",
    "        upper -= slopeWindow\n",
    "    slope = getSlope2(starFlux, lower, upper)\n",
    "    for c in getRanger2(lowC, highC, step, zoomStart, zoomStop, zoomStep):\n",
    "        if c == -1:\n",
    "            continue\n",
    "        scaledFlux = getScaledSpec2(clipTemplate, c)\n",
    "        s = slope - getSlope2(scaledFlux, lower, upper)\n",
    "        tiltedFlux = getTiltedSpec2(scaledFlux, s, lower, upper)\n",
    "        testScore = getScore(tiltedFlux, starFlux, starIvar)\n",
    "        if trackC:\n",
    "            c_coords.append(c)\n",
    "            sc_coords.append(testScore)\n",
    "        if bestScore == None or testScore < bestScore:\n",
    "            bestC, bestS = c, s\n",
    "            bestScore = testScore\n",
    "    if trackC:\n",
    "        plt.plot(c_coords, sc_coords)\n",
    "        plt.rcParams['figure.figsize'] = 30,11 \n",
    "        plt.title(\"C-Value vs. Score for Star \" + str(star), size = 30) \n",
    "        plt.ylabel(\"Score\", size = 20)\n",
    "        plt.xlabel(\"C (Scale) Value\", size = 20)\n",
    "        plt.legend(fontsize = 20)\n",
    "        plt.ylim(0,0.2)\n",
    "        plt.show()\n",
    "    return bestC, bestS, bestScore\n",
    "\n",
    "#defines a function that allows a user to see the modified template \"findOptimalC\" chose as the best match for a star\n",
    "def seeModWTemplate2(star, c=0, template = Wtemplate_full, lower = lowerThresh, upper = upperThresh, starSpec = True, unmodified = False, gauss = False, nsigma = 10):\n",
    "    '''\n",
    "    star: the index number of the star that was analyzed with findOptimalC\n",
    "    c: the c (scale) value that was produced when findOptimalC was run on star\n",
    "    template: the template spectrum to be modified\n",
    "    lower: the lower boundary on which the template spectrum is to be modified\n",
    "    upper: the upper boundary on which the template spectrum is to be modified\n",
    "    starSpec: a Boolean value that, if True, will graph star's science spectrum along with the modified template; if False, only the modified template will be graphed\n",
    "    unmodified: a Boolean value that, if True, will graph the unmodified template along with the modified template; if False, only the modified template will be graphed\n",
    "    \n",
    "    Note that template, lower, upper, starSpec, and unmodified default to Ctemplate_full, lowerThresh, upperThresh, True, and False\n",
    "    \n",
    "    This function will return None while also producing a graph of the modified template spectrum along with any other auxilary graphs chosen by the user based on inputs\n",
    "    '''\n",
    "    if not normSpec(star = star, lower = lower, upper = upper)[3]:\n",
    "        print(\"NormalizationError: Because this spectrum cannot be normalized, this method cannot be applied to it.\")\n",
    "        return None\n",
    "    clipTemplate = template[lower:upper]\n",
    "    starFlux, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "    if gauss:\n",
    "        clipTemplate = applyGauss(clipTemplate, nsigma)\n",
    "        starFlux = applyGauss(starFlux, nsigma)\n",
    "    while all(np.isnan(starFlux[:slopeWindow])) or all(starFlux[:slopeWindow] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[slopeWindow:], starIvar[slopeWindow:], clipTemplate[slopeWindow:]\n",
    "        lower += slopeWindow\n",
    "    while all(np.isnan(starFlux[-slopeWindow:])) or all(starFlux[-slopeWindow:] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[:-slopeWindow], starIvar[:-slopeWindow], clipTemplate[:-slopeWindow]\n",
    "        upper -= slopeWindow\n",
    "    slope = getSlope2(starFlux, lower, upper)\n",
    "    scaledFlux = getScaledSpec2(clipTemplate, c)\n",
    "    s = slope - getSlope2(scaledFlux, lower, upper)\n",
    "    tiltedFlux = getTiltedSpec2(scaledFlux, s, lower, upper)\n",
    "    plt.plot(data[\"LBIN\"][0][lower:upper], tiltedFlux, color = 'b', label = ('Modified Template (C = ' + str(c) +')'))\n",
    "    if starSpec:\n",
    "        plt.plot(data[\"LBIN\"][0][lower:upper], starFlux, color = 'orange', label = 'Science Spectrum')\n",
    "    if unmodified:\n",
    "        plt.plot(data[\"LBIN\"][0][lower:upper], clipTemplate, label = 'Unmodified Template')\n",
    "    plt.rcParams['figure.figsize'] = 30,11 \n",
    "    plt.title(\"Modified Template Comparison for Star \" + str(star), size = 30) \n",
    "    plt.ylabel(\"Flux\", size = 20)\n",
    "    plt.xlabel(\"Wavelength\", size = 20)\n",
    "    plt.legend(fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "#seeModTemplate2(20352, 0) #inputting manually to make sure this works\n",
    "#seeModTemplate2(20352, c) - doesn't work now (because I've declared c=0 default?)\n",
    "seeModWTemplate2(20352) #star 20352 is a weak CN star from wNm\n",
    "\n",
    "#Set scale factor to 0 and adjusted slope to make modified template for Weak CN stars vs science spectrum of wNms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionaries - Undiluted W Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#labeled as uwdict for undiluted w template scores\n",
    "#creates dictionaries of c, s, and score for each star population based on Method 2\n",
    "wNm_c_uwdict, wNm_s_uwdict, wNm_score2_uwdict = {}, {}, {}\n",
    "#weak_c_uwdict, weak_s_uwdict, weak_score2_uwdict = {}, {}, {}\n",
    "#marginal_c_uwdict, marginal_s_uwdict, marginal_score2_uwdict = {}, {}, {}\n",
    "carbon_c_uwdict, carbon_s_uwdict, carbon_score2_uwdict = {}, {}, {}\n",
    "#kphTrO1_c_uwdict, kphTrO1_s_uwdict, kphTrO1_score2_uwdict = {}, {}, {}\n",
    "#kphTrO2_c_uwdict, kphTrO2_s_uwdict, kphTrO2_score2_uwdict = {}, {}, {}\n",
    "#kphOthers_c_uwdict, kphOthers_s_uwdict, kphOthers_score2_uwdict = {}, {}, {}\n",
    "others_c_uwdict, others_s_uwdict, others_score2_uwdict = {}, {}, {}\n",
    "#flaggedStars_c_uwdict, flaggedStars_s_uwdict, flaggedStars_score2_uwdict = {}, {}, {}\n",
    "\n",
    "#generates the sample of stars to be used in the dictionaries (excludes outsiders)\n",
    "useStars_uw = []\n",
    "useStars_uw.extend(wNm); useStars_uw.extend(allcarbon); useStars_uw.extend(others)\n",
    "#useStars.extend(kphTrimmedOthers1); useStars.extend(kphTrimmedOthers2)\n",
    "\n",
    "\n",
    "#generates the dictionaries and keeps track of progress with a counter\n",
    "ctr = 0\n",
    "for star in useStars_uw:\n",
    "    if not splashSuccess_dict[star]:\n",
    "        ctr += 1\n",
    "        if ctr % 100 == 0:\n",
    "            print(ctr)\n",
    "        continue\n",
    "    c, s, sc = findWOptimalC2(star)\n",
    "    ctr += 1\n",
    "   # if star in flaggedStars_list:\n",
    "    #    flaggedStars_c_uwdict[star], flaggedStars_s_uwdict[star], flaggedStars_score2_uwdict[star] = c, s, sc\n",
    "    if star in wNm:\n",
    "        wNm_c_uwdict[star], wNm_s_uwdict[star], wNm_score2_uwdict[star] = c, s, sc\n",
    "       # if star in weaks:\n",
    "       #     weak_c_uwdict[star], weak_s_uwdict[star], weak_score2_uwdict[star] = c, s, sc\n",
    "       # if star in marginals:\n",
    "       #     marginal_c_uwdict[star], marginal_s_uwdict[star], marginal_score2_uwdict[star] = c, s, sc\n",
    "    if star in allcarbon:\n",
    "        carbon_c_uwdict[star], carbon_s_uwdict[star], carbon_score2_uwdict[star] = c, s, sc\n",
    "\n",
    "    if star in others:\n",
    "        others_c_uwdict[star], others_s_uwdict[star], others_score2_uwdict[star] = c, s, sc\n",
    "       \n",
    "    '''\n",
    "    if star in keckPhotoOthers:\n",
    "       kphOthers_c_uwdict[star], kphOthers_s_uwdict[star], kphOthers_score2_uwdict[star] = c, s, sc \n",
    "        \n",
    "            \n",
    "    if star in kphTrimmedOthers1:\n",
    "        kphTrO1_c_uwdict[star], kphTrO1_s_uwdict[star], kphTrO1_score2_uwdict[star] = c, s, sc\n",
    "    if star in kphTrimmedOthers2: #cannot use 'else' because kphTrimmedOthers1 and kphTrimmedOthers2 overlap\n",
    "        kphTrO2_c_uwdict[star], kphTrO2_s_uwdict[star], kphTrO2_score2_uwdict[star] = c, s, sc\n",
    "        '''\n",
    "    if ctr % 100 == 0:\n",
    "        print(ctr)\n",
    "        \n",
    "#runs 21400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Undiluted C Template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rachel- copied  findOptimalC2, seeModWtemplate2 and renamed it findCOptimalC2 and seeModCtemplate\n",
    "        #and rewrote for template = C_template_full\n",
    "\n",
    "#defines a function that sorts through the c-values produced by getRanger and returns the c-value and s-value that result in the lowest score\n",
    "def findCOptimalC2(star, template = Ctemplate_full, lower = lowerThresh, upper = upperThresh, lowC = -15, highC = 60, step = 0.5, zoomStart = None, zoomStop = None, zoomStep = None, trackC = False, gauss = False, nsigma = 10):\n",
    "    '''\n",
    "    Note that default argument values have been denoted with () in the descriptions below\n",
    "    \n",
    "    star: the index of the star for which the template is to be modified to fit and the score is to be calculated\n",
    "    template: (Ctemplate_full) the template spectrum that will be used to compare the spectrum of star to\n",
    "    lower: (lowerThresh) the lower boundary for the spectra of star and template to be normalized on/analyzed on\n",
    "    upper: (upperThresh) the upper boundary for the spectra of star and template to be normalized on/analyzed on\n",
    "    lowC: (-15) the lower boundary for the range of c-values to be tested\n",
    "    highC: (60) the upper boundary for the range of c-values to be tested\n",
    "    step: (0.5) the increment by which c-values between lowC and highC are tested\n",
    "    zoomStart: (None) the lower boundary for a range of c-values to be tested with a finer increment size\n",
    "    zoomStop: (None) the upper boundary for a range of c-values to be tested with a finer increment size\n",
    "    zoomStep: (None) the finer increment size by which c-values between zoomStart and zoomStop are tested\n",
    "    trackC: (False) a Boolean value that, if True, will produce a graph of c-values and their corresponding scores as the function steps through the c-range; if False, the graph will not be produced\n",
    "    gauss: (False) a Boolean value that, if True, will apply a Gaussian smoothing kernel to both the template and science spectra before optimal C is found\n",
    "    nsigma: (10) a numerical value representing the width of the Gaussian kernel that will be used if gauss is True\n",
    "    \n",
    "    Returns bestC, the scale factor that yielded the lowest score\n",
    "    Also returns bestS, the slope that yielded the lowest score (note that this is the version of the slope that has been changed according to the scaled spectrum)\n",
    "    Also returns bestScore, the \"lowest score\" referred to above\n",
    "    '''\n",
    "    if not normSpec(star = star, lower = lower, upper = upper)[3]:\n",
    "        print(\"ScoreError: Because this spectrum cannot be normalized, its score cannot be found.\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "    bestScore = None\n",
    "    bestC, bestS = 0, 0\n",
    "    c_coords, sc_coords = [], []\n",
    "    clipTemplate = template[lower:upper]\n",
    "    starFlux, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "    if gauss:\n",
    "        clipTemplate = applyGauss(clipTemplate, nsigma)\n",
    "        starFlux = applyGauss(starFlux, nsigma)\n",
    "    while all(np.isnan(starFlux[:slopeWindow])) or all(starFlux[:slopeWindow] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[slopeWindow:], starIvar[slopeWindow:], clipTemplate[slopeWindow:]\n",
    "        lower += slopeWindow\n",
    "    while all(np.isnan(starFlux[-slopeWindow:])) or all(starFlux[-slopeWindow:] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[:-slopeWindow], starIvar[:-slopeWindow], clipTemplate[:-slopeWindow]\n",
    "        upper -= slopeWindow\n",
    "    slope = getSlope2(starFlux, lower, upper)\n",
    "    for c in getRanger2(lowC, highC, step, zoomStart, zoomStop, zoomStep):\n",
    "        if c == -1:\n",
    "            continue\n",
    "        scaledFlux = getScaledSpec2(clipTemplate, c)\n",
    "        s = slope - getSlope2(scaledFlux, lower, upper)\n",
    "        tiltedFlux = getTiltedSpec2(scaledFlux, s, lower, upper)\n",
    "        testScore = getScore(tiltedFlux, starFlux, starIvar)\n",
    "        if trackC:\n",
    "            c_coords.append(c)\n",
    "            sc_coords.append(testScore)\n",
    "        if bestScore == None or testScore < bestScore:\n",
    "            bestC, bestS = c, s\n",
    "            bestScore = testScore\n",
    "    if trackC:\n",
    "        plt.plot(c_coords, sc_coords)\n",
    "        plt.rcParams['figure.figsize'] = 30,11 \n",
    "        plt.title(\"C-Value vs. Score for Star \" + str(star), size = 30) \n",
    "        plt.ylabel(\"Score\", size = 20)\n",
    "        plt.xlabel(\"C (Scale) Value\", size = 20)\n",
    "        plt.legend(fontsize = 20)\n",
    "        plt.ylim(0,0.2)\n",
    "        plt.show()\n",
    "    return bestC, bestS, bestScore\n",
    "\n",
    "#defines a function that allows a user to see the modified template \"findOptimalC\" chose as the best match for a star\n",
    "def seeModCTemplate2(star, c=0, template = Ctemplate_full, lower = lowerThresh, upper = upperThresh, starSpec = True, unmodified = False, gauss = False, nsigma = 10):\n",
    "    '''\n",
    "    star: the index number of the star that was analyzed with findOptimalC\n",
    "    c: the c (scale) value that was produced when findOptimalC was run on star\n",
    "    template: the template spectrum to be modified\n",
    "    lower: the lower boundary on which the template spectrum is to be modified\n",
    "    upper: the upper boundary on which the template spectrum is to be modified\n",
    "    starSpec: a Boolean value that, if True, will graph star's science spectrum along with the modified template; if False, only the modified template will be graphed\n",
    "    unmodified: a Boolean value that, if True, will graph the unmodified template along with the modified template; if False, only the modified template will be graphed\n",
    "    \n",
    "    Note that template, lower, upper, starSpec, and unmodified default to Ctemplate_full, lowerThresh, upperThresh, True, and False\n",
    "    \n",
    "    This function will return None while also producing a graph of the modified template spectrum along with any other auxilary graphs chosen by the user based on inputs\n",
    "    '''\n",
    "    if not normSpec(star = star, lower = lower, upper = upper)[3]:\n",
    "        print(\"NormalizationError: Because this spectrum cannot be normalized, this method cannot be applied to it.\")\n",
    "        return None\n",
    "    clipTemplate = template[lower:upper]\n",
    "    starFlux, starIvar = normSpec(star = star, lower = lower, upper = upper)[1:3]\n",
    "    if gauss:\n",
    "        clipTemplate = applyGauss(clipTemplate, nsigma)\n",
    "        starFlux = applyGauss(starFlux, nsigma)\n",
    "    while all(np.isnan(starFlux[:slopeWindow])) or all(starFlux[:slopeWindow] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[slopeWindow:], starIvar[slopeWindow:], clipTemplate[slopeWindow:]\n",
    "        lower += slopeWindow\n",
    "    while all(np.isnan(starFlux[-slopeWindow:])) or all(starFlux[-slopeWindow:] == 0):\n",
    "        starFlux, starIvar, clipTemplate = starFlux[:-slopeWindow], starIvar[:-slopeWindow], clipTemplate[:-slopeWindow]\n",
    "        upper -= slopeWindow\n",
    "    slope = getSlope2(starFlux, lower, upper)\n",
    "    scaledFlux = getScaledSpec2(clipTemplate, c)\n",
    "    s = slope - getSlope2(scaledFlux, lower, upper)\n",
    "    tiltedFlux = getTiltedSpec2(scaledFlux, s, lower, upper)\n",
    "    plt.plot(data[\"LBIN\"][0][lower:upper], tiltedFlux, color = 'b', label = ('Modified Template (C = ' + str(c) +')'))\n",
    "    if starSpec:\n",
    "        plt.plot(data[\"LBIN\"][0][lower:upper], starFlux, color = 'orange', label = 'Science Spectrum')\n",
    "    if unmodified:\n",
    "        plt.plot(data[\"LBIN\"][0][lower:upper], clipTemplate, label = 'Unmodified Template')\n",
    "    plt.rcParams['figure.figsize'] = 30,11 \n",
    "    plt.title(\"Modified Template Comparison for Star \" + str(star), size = 30) \n",
    "    plt.ylabel(\"Flux\", size = 20)\n",
    "    plt.xlabel(\"Wavelength\", size = 20)\n",
    "    plt.legend(fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "seeModCTemplate2(22198) #22198 is a carbon star from allcarbon\n",
    "\n",
    "#Set scale factor to 0 and adjusted slope to make modified template for Weak CN stars vs science spectrum of wNms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionaries - Undiluted C Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#labeled as ucdict for undiluted C template scores\n",
    "#creates dictionaries of c, s, and score for each star population based on Method 2\n",
    "wNm_c_ucdict, wNm_s_ucdict, wNm_score2_ucdict = {}, {}, {}\n",
    "#weak_c_ucdict, weak_s_ucdict, weak_score2_ucdict = {}, {}, {}\n",
    "#marginal_c_ucdict, marginal_s_ucdict, marginal_score2_ucdict = {}, {}, {}\n",
    "carbon_c_ucdict, carbon_s_ucdict, carbon_score2_ucdict = {}, {}, {}\n",
    "#kphTrO1_c_ucdict, kphTrO1_s_ucdict, kphTrO1_score2_ucdict = {}, {}, {}\n",
    "#kphTrO2_c_ucdict, kphTrO2_s_ucdict, kphTrO2_score2_ucdict = {}, {}, {}\n",
    "#kphOthers_c_ucdict, kphOthers_s_ucdict, kphOthers_score2_ucdict = {}, {}, {}\n",
    "others_c_ucdict, others_s_ucdict, others_score2_ucdict = {}, {}, {}\n",
    "#flaggedStars_c_ucdict, flaggedStars_s_ucdict, flaggedStars_score2_ucdict = {}, {}, {}\n",
    "\n",
    "#generates the sample of stars to be used in the dictionaries (excludes outsiders)\n",
    "useStars_uc = []\n",
    "useStars_uc.extend(wNm); useStars_uc.extend(allcarbon); useStars_uc.extend(others)\n",
    "#useStars.extend(kphTrimmedOthers1); useStars.extend(kphTrimmedOthers2)\n",
    "\n",
    "\n",
    "#generates the dictionaries and keeps track of progress with a counter\n",
    "ctr = 0\n",
    "for star in useStars_uc:\n",
    "    if not splashSuccess_dict[star]:\n",
    "        ctr += 1\n",
    "        if ctr % 100 == 0:\n",
    "            print(ctr)\n",
    "        continue\n",
    "    c, s, sc = findCOptimalC2(star)\n",
    "    ctr += 1\n",
    "   # if star in flaggedStars_list:\n",
    "    #    flaggedStars_c_ucdict[star], flaggedStars_s_ucdict[star], flaggedStars_score2_ucdict[star] = c, s, sc\n",
    "    if star in wNm:\n",
    "        wNm_c_ucdict[star], wNm_s_ucdict[star], wNm_score2_ucdict[star] = c, s, sc\n",
    "       # if star in weaks:\n",
    "       #     weak_c_ucdict[star], weak_s_ucdict[star], weak_score2_ucdict[star] = c, s, sc\n",
    "       # if star in marginals:\n",
    "       #     marginal_c_ucdict[star], marginal_s_ucdict[star], marginal_score2_ucdict[star] = c, s, sc\n",
    "    if star in allcarbon:\n",
    "        carbon_c_ucdict[star], carbon_s_ucdict[star], carbon_score2_ucdict[star] = c, s, sc\n",
    "\n",
    "    if star in others:\n",
    "        others_c_ucdict[star], others_s_ucdict[star], others_score2_ucdict[star] = c, s, sc\n",
    "       \n",
    "    '''\n",
    "    if star in keckPhotoOthers:\n",
    "       kphOthers_c_ucdict[star], kphOthers_s_ucdict[star], kphOthers_score2_ucdict[star] = c, s, sc \n",
    "        \n",
    "            \n",
    "    if star in kphTrimmedOthers1:\n",
    "        kphTrO1_c_ucdict[star], kphTrO1_s_ucdict[star], kphTrO1_score2_ucdict[star] = c, s, sc\n",
    "    if star in kphTrimmedOthers2: #cannot use 'else' because kphTrimmedOthers1 and kphTrimmedOthers2 overlap\n",
    "        kphTrO2_c_ucdict[star], kphTrO2_s_ucdict[star], kphTrO2_score2_ucdict[star] = c, s, sc\n",
    "        '''\n",
    "    if ctr % 100 == 0:\n",
    "        print(ctr)\n",
    "        \n",
    "#runs 21400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis of Method 2 & 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undiluted W Template vs. C Template scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(others_score2_uwdict.values(),others_score2_ucdict.values(), color ='orange', alpha =0.2, s= 10, label = 'Others')\n",
    "plt.scatter(wNm_score2_uwdict.values(),wNm_score2_ucdict.values(), color='blue',s=35, label = 'Weak CN Stars')\n",
    "plt.scatter(carbon_score2_uwdict.values(),carbon_score2_ucdict.values(), color ='red', label = 'Carbon')\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.xlim([-0.5,2])\n",
    "plt.ylim([-0.5,2])\n",
    "plt.xlabel(\"Score against Weak CN Template\", size = 25)\n",
    "plt.ylabel(\"Score against C Template\", size = 25)\n",
    "plt.title(\"Score Against Undiluted W vs C Template\", size = 30) \n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(others_score2_uwdict.values(),others_score2_ucdict.values(), color ='orange', alpha =0.2, s= 10, label = 'Others')\n",
    "plt.scatter(wNm_score2_uwdict.values(),wNm_score2_ucdict.values(), color='blue',s=35, label = 'Weak CN Stars')\n",
    "plt.scatter(carbon_score2_uwdict.values(),carbon_score2_ucdict.values(), color ='red', label = 'Carbon')\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.xlim([-0.1,1.3])\n",
    "plt.ylim([-0.1,1.3])\n",
    "#plot lines for star to correspond to axes\n",
    "#plt.plot([carbon_score2_uwdict[20867],0,carbon_score2_uwdict[20867],carbon_score2_ucdict[20867]])\n",
    "\n",
    "#Carbon Stars identificaion by vertical and horizontal line \n",
    "plt.axhline(y = carbon_score2_ucdict[21469], color='red', linewidth = 0.6)\n",
    "plt.axvline(x = carbon_score2_uwdict[21469], color='red', linewidth = 0.6)\n",
    "# print(carbon_score2_ucdict[21469])\n",
    "# print(carbon_score2_uwdict[21469])\n",
    "\n",
    "#Weak CN Stars identificaion by vertical and horizontal line \n",
    "plt.axhline(y = wNm_score2_ucdict[19971], color='blue', linewidth = 0.6)\n",
    "plt.axvline(x = wNm_score2_uwdict[19971], color='blue', linewidth = 0.6)\n",
    "# print(wNm_score2_uwdict[19971])\n",
    "# print(wNm_score2_ucdict[19971])\n",
    "\n",
    "#Other Stars identificaion by vertical and horizontal line\n",
    "plt.axhline(y = others_score2_ucdict[3445],color='orange', linewidth = 0.6)\n",
    "plt.axvline(x = others_score2_uwdict[3445],color='orange', linewidth = 0.6)\n",
    "# print(\"Score Against C Template for Other Star: \",others_score2_ucdict[3445])\n",
    "# print(\"Score Against Weak CN Template for Other Star: \",others_score2_uwdict[3445])\n",
    "\n",
    "\n",
    "#Ploy y=x for comparison\n",
    "plt.plot(np.linspace(0,2,1000),np.linspace(0,2,1000))\n",
    "\n",
    "# Computes what percent of other stars are closer to carbon than Weak CN\n",
    "closerToCarbonCount = 0\n",
    "for starID in others_score2_uwdict:\n",
    "  if others_score2_uwdict[starID]>others_score2_ucdict[starID]:\n",
    "      closerToCarbonCount+=1\n",
    "\n",
    "print(\"Percent of 'other' stars closer to carbon than Weak CN: %\",100*closerToCarbonCount/len(others_score2_uwdict))\n",
    "\n",
    "plt.xlabel(\"Score against Weak CN Template\", size = 25)\n",
    "plt.ylabel(\"Score against C Template\", size = 25)\n",
    "plt.title(\"Score Against Undiluted W vs C Template\", size = 30) \n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(others_score2_uwdict.values(),others_score2_ucdict.values(), color ='orange', alpha =0.2, s= 10, label = 'Others')\n",
    "plt.scatter(wNm_score2_uwdict.values(),wNm_score2_ucdict.values(), color='blue',s=35, label = 'Weak CN Stars')\n",
    "plt.scatter(carbon_score2_uwdict.values(),carbon_score2_ucdict.values(), color ='red', label = 'Carbon')\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.xlim([0,0.4])\n",
    "plt.ylim([0.1,0.4])\n",
    "plt.xlabel(\"Score against Weak CN Template\", size = 25)\n",
    "plt.ylabel(\"Score against C Template\", size = 25)\n",
    "plt.title(\"Score Against Undiluted W vs C Template\", size = 30) \n",
    "plt.legend(fontsize = 20)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diluted C Template Scores vs. Optimal Dilution Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 4 - Slope\n",
    "\n",
    "Calculating the four slopes of the W range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding W slopes for the weak CN template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines important variables that will be used to find the slopes of the graph within specific windows\n",
    "wv_range = data[\"LBIN\"][0][lowerThresh:upperThresh]\n",
    "windows = [[0, 227], [227, 342], [342, 473], [473, 709]] #these bin limits correspond to values 7796, 7943.5, 8018.5, 8103.5, and 8257.5 in data[\"LBIN\"]\n",
    "windows2 = [[0, 227], [0, 115], [0, 131], [0, 236]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a helper function for the getWSlopes function that determines what the slope of the line of best fit is for a certain graph\n",
    "def findOptimalM(spectrum, lower, upper, lowM = -0.1, highM = 0.1, step = 0.001, zoomStart = -0.05, zoomStop = 0.05, zoomStep = 0.0001):\n",
    "    '''\n",
    "    spectrum: a Numpy array representing the flux values of a normalized, clipped (to the 'W' range) spectrum whose slopes are to be found\n",
    "    lower: the lower boundary of the range that the slope is to be calculated over (represented by an index of the CLIPPED spectrum; 0 will be lowerThresh and so on)\n",
    "    upper: the upper boundary of the range that the slope is to be calculated over (represented by an index of the CLIPPED spectrum; 0 will be lowerThresh and so on)\n",
    "    lowM: the lower boundary of the range of m-values (slope values) to be tested when searching for the line of best fit\n",
    "    highM: the upper boundary of the range of m-values (slope values) to be tested when searching for the line of best fit\n",
    "    step: the increment value to use when creating new values of m to test between lowM and highM\n",
    "    zoomStart: the lower boundary of the range of m-values that you want to test with a finer step size\n",
    "    zoomStop: the upper boundary of the range of m-values that you want to test with a finer step size\n",
    "    zoomStep: the finer increment value to be applied between zoomStart and zoomStop\n",
    "    \n",
    "    Note that lowM, highM, step, zoomStart, zoomStop, and zoomStep will default to -0.1, 0.1, 0.05, -0.05, 0.05, and 0.001, respectively\n",
    "    \n",
    "    Returns bestM, a numerical value representing the slope of the line of best fit for the spectrum on the range lower:upper\n",
    "    Also returns bestB, the y-intercept value that corresponds to the bestM, to be used for graphing the chosen lines of best fit\n",
    "    '''\n",
    "    bestDiff, bestM, bestB = 1000000000000, None, None\n",
    "    lbin = data[\"LBIN\"][0][lowerThresh:upperThresh][lower:upper]\n",
    "    mRanger = getRanger(lowM, highM, step, zoomStart, zoomStop, zoomStep) #note that this is the same function earlier defined in score calculation method 2\n",
    "    for m in mRanger:\n",
    "        b = ((np.nansum(spectrum)) - (m*(np.nansum(lbin))))/(len(lbin))\n",
    "        testDiff = np.nansum(np.power((spectrum - m*lbin - b), 2))\n",
    "        if testDiff < bestDiff:\n",
    "            bestDiff = testDiff\n",
    "            bestM, bestB = m, b\n",
    "    return bestM, bestB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that will check to see if the range covered by non-NaN values in a spectrum slice is greater than/equal to 75% of the length of the spectrum\n",
    "#if the above condition is not met, the slope of the slice cannot be calculated\n",
    "def isValidWindow(spectrum, windowLower, windowUpper):\n",
    "    '''\n",
    "    spectrum: a Numpy array containing the flux values of a normalized, trimmed (clipped to the 'W' range) spectrum whose slope is to be calculated\n",
    "    windowLower: the lower boundary of the window of spectrum whose validity is to be tested\n",
    "    windowUpper: the upper boundary of the window of spectrum whose validity is to be tested\n",
    "    \n",
    "    Returns False if the window specified has too many NaN values to be used for slope calculation, True otherwise\n",
    "    '''\n",
    "    testSpec = spectrum[windowLower:windowUpper]\n",
    "    count1, count2 = windowLower, windowUpper\n",
    "    for index in range(len(testSpec)): #finding the index of the first non-NaN value\n",
    "        if np.isnan(testSpec[index]):\n",
    "            count1 = index\n",
    "        else:\n",
    "            break\n",
    "    for index in range(len(testSpec), 0, -1): #finding the index of the last non-NaN value\n",
    "        if np.isnan(testSpec[index - 1]):\n",
    "            count2 = index\n",
    "        else:\n",
    "            break\n",
    "    if len(testSpec[count1:count2]) < 0.75*len(testSpec): #the range covered by the two indices found above must be greater than or equal to the length of the spectrum to be usable\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that calculates four slopes of a spectral graph\n",
    "def getWSlopes(spectrum, lowM = -0.1, highM = 0.1, step = 0.001, zoomStart = -0.05, zoomStop = 0.05, zoomStep = 0.0001, getB = False):\n",
    "    '''\n",
    "    spectrum: a Numpy array or list containing the flux values for a spectrum whose slopes will be calculated; must already be normalized/clipped to the lowerThresh:upperThresh wavelength range\n",
    "    lowM: the lower boundary of the range of m-values (slope values) to be tested when searching for the line of best fit\n",
    "    highM: the upper boundary of the range of m-values (slope values) to be tested when searching for the line of best fit\n",
    "    step: the increment value to use when creating new values of m to test between lowM and highM\n",
    "    zoomStart: the lower boundary of the range of m-values that you want to test with a finer step size\n",
    "    zoomStop: the upper boundary of the range of m-values that you want to test with a finer step size\n",
    "    zoomStep: the finer increment value to be applied between zoomStart and zoomStop\n",
    "    getB: a Boolean value that, if set to True, will cause the function to return both slope and y-intercept values for the lines of best fit created (if False, only slopes will be returned)\n",
    "    \n",
    "    Note that lowM, highM, step, zoomStart, zoomStop, zoomStep, and getB will default to -0.1, 0.1, 0.05, -0.05, 0.05, 0.001, and False, respectively\n",
    "    \n",
    "    Returns slope1, slope2, slope3, and slope4, the slopes of the spectral graph over the window ranges described above; these slopes are intended to represent the four slopes of the 'W' feature in carbon/weak CN spectra\n",
    "    If getB is set to True, also returns the y-intercept values for the lines of best fit corresponding to slope1, slope2, slope3, and slope4\n",
    "    '''\n",
    "    #first, a preliminary check to see if the entire spectrum is NaN; if True, all returned slopes are NaN as well\n",
    "    if all(np.isnan(spectrum)):\n",
    "        print(\"SlopeError: This spectrum is all NaNs. No slopes can be found.\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    #if the above test is passed, the spectrum is divided into four windows\n",
    "    window1, window2 = spectrum[windows[0][0]:windows[0][1]], spectrum[windows[1][0]:windows[1][1]]\n",
    "    window3, window4 = spectrum[windows[2][0]:windows[2][1]], spectrum[windows[3][0]:windows[3][1]]\n",
    "    calc1, calc2, calc3, calc4 = True, True, True, True\n",
    "    \n",
    "    #tests are done on each window to make sure that the presence of NaNs will not ruin the slope calculation\n",
    "    #if the calculation cannot be performed, the calcX variables are set to False (meaning those slopes will not be calculated later) and the slopes to be returned are set to NaN\n",
    "    if all(np.isnan(window1)) or not isValidWindow(spectrum, windows2[0][0], windows2[0][1]):\n",
    "        print(\"SlopeError: This spectrum is dominated by NaNs in window 1. Slope1 could not be found.\")\n",
    "        slope1, calc1 = np.nan, False\n",
    "    if all(np.isnan(window2)) or not isValidWindow(spectrum, windows2[1][0], windows2[1][1]):\n",
    "        print(\"SlopeError: This spectrum is dominated by NaNs in window 2. Slope2 could not be found.\")\n",
    "        slope2, calc2 = np.nan, False\n",
    "    if all(np.isnan(window3)) or not isValidWindow(spectrum, windows2[2][0], windows2[2][1]):\n",
    "        print(\"SlopeError: This spectrum is dominated by NaNs in window 3. Slope3 could not be found.\")\n",
    "        slope3, calc3 = np.nan, False\n",
    "    if all(np.isnan(window4)) or not isValidWindow(spectrum, windows2[3][0], windows2[3][1]):\n",
    "        print(\"SlopeError: This spectrum is dominated by NaNs in window 4. Slope4 could not be found.\")\n",
    "        slope4, calc4 = np.nan, False\n",
    "    \n",
    "    #finally, slopes are calculated in each of the valid windows that were not previously weeded out above\n",
    "    if calc1:\n",
    "        slope1, b1 = findOptimalM(window1, windows[0][0], windows[0][1], lowM, highM, step, zoomStart, zoomStop, zoomStep)\n",
    "    if calc2:\n",
    "        slope2, b2 = findOptimalM(window2, windows[1][0], windows[1][1], lowM, highM, step, zoomStart, zoomStop, zoomStep)\n",
    "    if calc3:\n",
    "        slope3, b3 = findOptimalM(window3, windows[2][0], windows[2][1], lowM, highM, step, zoomStart, zoomStop, zoomStep)\n",
    "    if calc4:\n",
    "        slope4, b4 = findOptimalM(window4, windows[3][0], windows[3][1], lowM, highM, step, zoomStart, zoomStop, zoomStep)\n",
    "        \n",
    "    #the valid slopes and the NaN slopes (if any) are returned together in a tuple, along with the b-values (if specified)\n",
    "    if getB:\n",
    "        return slope1, slope2, slope3, slope4, b1, b2, b3, b4\n",
    "    if not getB:\n",
    "        return slope1, slope2, slope3, slope4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test executions of the above function\n",
    "print(getWSlopes(Ctemplate))\n",
    "print(getWSlopes(Wtemplate))\n",
    "print(getWSlopes(normSpec(star = others[2])[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a test graph of the carbon coadd to see if the lines of best fit match the data well\n",
    "s1, s2, s3, s4, b1, b2, b3, b4 = getWSlopes(Ctemplate, getB = True)\n",
    "lbin = data[\"LBIN\"][0][lowerThresh:upperThresh]\n",
    "plt.plot(lbin[windows[0][0]:windows[0][1]], lbin[windows[0][0]:windows[0][1]]*s1 + b1, color = 'orange')\n",
    "plt.plot(lbin[windows[1][0]:windows[1][1]], lbin[windows[1][0]:windows[1][1]]*s2 + b2, color = 'r')\n",
    "plt.plot(lbin[windows[2][0]:windows[2][1]], lbin[windows[2][0]:windows[2][1]]*s3 + b3, color = 'b')\n",
    "plt.plot(lbin[windows[3][0]:windows[3][1]], lbin[windows[3][0]:windows[3][1]]*s4 + b4, color = 'g')\n",
    "plt.plot(Ctemplate_wv, Ctemplate, color = 'purple')\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"Slope Testing Graph for the Carbon Template\", size = 30) \n",
    "plt.ylabel(\"Flux (normalized)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antara - creating a test graph of the Weak CN coadd to see if the lines of best fit match the data well\n",
    "s1, s2, s3, s4, b1, b2, b3, b4 = getWSlopes(Wtemplate, getB = True)\n",
    "lbin = data[\"LBIN\"][0][lowerThresh:upperThresh]\n",
    "plt.plot(lbin[windows[0][0]:windows[0][1]], lbin[windows[0][0]:windows[0][1]]*s1 + b1, color = 'orange')\n",
    "plt.plot(lbin[windows[1][0]:windows[1][1]], lbin[windows[1][0]:windows[1][1]]*s2 + b2, color = 'r')\n",
    "plt.plot(lbin[windows[2][0]:windows[2][1]], lbin[windows[2][0]:windows[2][1]]*s3 + b3, color = 'b')\n",
    "plt.plot(lbin[windows[3][0]:windows[3][1]], lbin[windows[3][0]:windows[3][1]]*s4 + b4, color = 'g')\n",
    "plt.plot(Wtemplate_wv, Wtemplate, color = 'purple')\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"Slope Testing Graph for the Weak CN Template\", size = 30) \n",
    "plt.ylabel(\"Flux (normalized)\", size = 20)\n",
    "plt.xlabel(\"Wavelength\", size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dictionaries of slopes for all stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creates dictionaries of all four slopes for every star, as found in method 3\n",
    "#Antara - commented out all unnecessary stuff\n",
    "wNm_s1_dict, wNm_s2_dict, wNm_s3_dict, wNm_s4_dict = {}, {}, {}, {}\n",
    "weak_s1_dict, weak_s2_dict, weak_s3_dict, weak_s4_dict = {}, {}, {}, {}\n",
    "marginal_s1_dict, marginal_s2_dict, marginal_s3_dict, marginal_s4_dict = {}, {}, {}, {}\n",
    "carbon_s1_dict, carbon_s2_dict, carbon_s3_dict, carbon_s4_dict = {}, {}, {}, {}\n",
    "kphTrO1_s1_dict, kphTrO1_s2_dict, kphTrO1_s3_dict, kphTrO1_s4_dict = {}, {}, {}, {}\n",
    "kphTrO2_s1_dict, kphTrO2_s2_dict, kphTrO2_s3_dict, kphTrO2_s4_dict = {}, {}, {}, {}\n",
    "kphOthers_s1_dict, kphOthers_s2_dict, kphOthers_s3_dict, kphOthers_s4_dict = {}, {}, {}, {}\n",
    "others_s1_dict, others_s2_dict, others_s3_dict, others_s4_dict = {}, {}, {}, {}\n",
    "flaggedStars_s1_dict, flaggedStars_s2_dict, flaggedStars_s3_dict, flaggedStars_s4_dict = {}, {}, {}, {}\n",
    "allstars_s1_dict, allstars_s2_dict, allstars_s3_dict, allstars_s4_dict = {}, {}, {}, {}\n",
    "wNmNc_s1_dict, wNmNc_s2_dict, wNmNc_s3_dict, wNmNc_s4_dict = {}, {}, {}, {}\n",
    "\n",
    "#creates lists that star indices will be appended to so that stars with NaN slopes can be picked out\n",
    "validSlopeStars = []\n",
    "invalidW1, invalidW2, invalidW3, invalidW4 = [], [], [], []\n",
    "\n",
    "#creates a list of star classifications (corresponding to useStars) that is used exclusively for the below pandas plot\n",
    "starTypes, wNmNcTypes = [], []\n",
    "\n",
    "\n",
    "\n",
    "#generates the sample of stars to be used in the dictionaries (excludes outsiders)\n",
    "useStars = []\n",
    "useStars.extend(wNm); useStars.extend(allcarbon); useStars.extend(others)\n",
    "\n",
    "#generates the dictionaries and keeps track of progress with a counter\n",
    "ctr = 0\n",
    "for star in useStars:\n",
    "    if not splashSuccess_dict[star]:\n",
    "        ctr += 1\n",
    "        if ctr % 100 == 0:\n",
    "            print(ctr)\n",
    "        continue\n",
    "    starSpectrum = normSpec(star = star)[1]\n",
    "    s1, s2, s3, s4 = getWSlopes(starSpectrum)\n",
    "    allstars_s1_dict[star], allstars_s2_dict[star], allstars_s3_dict[star], allstars_s4_dict[star] = s1, s2, s3, s4\n",
    "    ctr += 1\n",
    "    if np.isnan(s1):\n",
    "        invalidW1.append(star)\n",
    "    if np.isnan(s2):\n",
    "        invalidW2.append(star)\n",
    "    if np.isnan(s3):\n",
    "        invalidW3.append(star)\n",
    "    if np.isnan(s4):\n",
    "        invalidW4.append(star)\n",
    "    if not any(np.isnan([s1, s2, s3, s4])):\n",
    "        validSlopeStars.append(star)\n",
    "    if star in flaggedStars_list:\n",
    "        flaggedStars_s1_dict[star], flaggedStars_s2_dict[star], flaggedStars_s3_dict[star], flaggedStars_s4_dict[star] = s1, s2, s3, s4\n",
    "    if star in wNm:\n",
    "        starTypes.append(\"Weak CN\")\n",
    "        wNm_s1_dict[star], wNm_s2_dict[star], wNm_s3_dict[star], wNm_s4_dict[star] = s1, s2, s3, s4\n",
    "        wNmNc_s1_dict[star], wNmNc_s2_dict[star], wNmNc_s3_dict[star], wNmNc_s4_dict[star] = s1, s2, s3, s4\n",
    "        wNmNcTypes.append(\"Weak CN\")\n",
    "        if star in weaks:\n",
    "            weak_s1_dict[star], weak_s2_dict[star], weak_s3_dict[star], weak_s4_dict[star] = s1, s2, s3, s4\n",
    "        if star in marginals:\n",
    "            marginal_s1_dict[star], marginal_s2_dict[star], marginal_s3_dict[star], marginal_s4_dict[star] = s1, s2, s3, s4\n",
    "    if star in allcarbon:\n",
    "        starTypes.append(\"Carbon\"); wNmNcTypes.append(\"Carbon\")\n",
    "        carbon_s1_dict[star], carbon_s2_dict[star], carbon_s3_dict[star], carbon_s4_dict[star] = s1, s2, s3, s4\n",
    "        wNmNc_s1_dict[star], wNmNc_s2_dict[star], wNmNc_s3_dict[star], wNmNc_s4_dict[star] = s1, s2, s3, s4\n",
    "    if star in others:\n",
    "        starTypes.append(\"Other\")\n",
    "        others_s1_dict[star], others_s2_dict[star], others_s3_dict[star], others_s4_dict[star] = s1, s2, s3, s4\n",
    "    if star in keckPhotoOthers:\n",
    "        kphOthers_s1_dict[star], kphOthers_s2_dict[star], kphOthers_s3_dict[star], kphOthers_s4_dict[star] = s1, s2, s3, s4\n",
    "    if star in kphTrimmedOthers1:\n",
    "        kphTrO1_s1_dict[star], kphTrO1_s2_dict[star], kphTrO1_s3_dict[star], kphTrO1_s4_dict[star] = s1, s2, s3, s4\n",
    "    if star in kphTrimmedOthers2: #cannot use 'else' because kphTrimmedOthers1 and kphTrimmedOthers2 overlap\n",
    "        kphTrO2_s1_dict[star], kphTrO2_s2_dict[star], kphTrO2_s3_dict[star], kphTrO2_s4_dict[star] = s1, s2, s3, s4\n",
    "        \n",
    "    if ctr % 100 == 0:\n",
    "        print(ctr)\n",
    "\n",
    "#runs around 19800 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata: seeing how many stars would be invalidated if the requirement \"no NaN slopes\" was imposed\n",
    "print(str(len(useStars)) + \" valid stars in SPLASH (w/o outsiders) become \" + str(len(validSlopeStars)) + \" stars if all NaN slopes are ignored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating the pandas data frame that will be used below in making the parallel coordinates graph\n",
    "#slopes_dict = {\"s1\":list(wNmNc_s1_dict.values()), \"s2\":list(wNmNc_s2_dict.values()), \"s3\":list(wNmNc_s3_dict.values()), \"s4\":list(wNmNc_s4_dict.values()), \"type\":wNmNcTypes}\n",
    "#slopes = pd.DataFrame(slopes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#slicing the 254-256 stars\n",
    "\n",
    "sliced1=  {k: v for k, v in wNmNc_s1_dict.items() if s1 != None }\n",
    "sliced2=  {k: v for k, v in wNmNc_s2_dict.items() if s1 != None }\n",
    "sliced3=  {k: v for k, v in wNmNc_s3_dict.items() if s1 != None }\n",
    "sliced4=  {k: v for k, v in wNmNc_s4_dict.items() if s1 != None }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#creating the pandas data frame that will be used below in making the parallel coordinates graph\n",
    "#Antara - edited so that this runs \n",
    "slopes_dict = {\"s1\": list(sliced1.values()), \"s2\": list(sliced2.values()), \"s3\": list(sliced3.values()), \"s4\": list(sliced4.values()), \"type\":wNmNcTypes}\n",
    "\n",
    "slopes = pd.DataFrame.from_dict(slopes_dict, orient='index')\n",
    "slopes.transpose()\n",
    "\n",
    "#used slopes.transpose to get an output and see where the problem is\n",
    "#comment it out for data analysis because it flips rows and columns \n",
    "#there are some carbon stars that have None for all slopes but are somehow still in this list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I remove the None values? I've tried a couple of times but it isn't working. -Antara\n",
    "(tried to define a function too but it didn't work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slopes_dict = {\"s1\": list(wNmNc_s1_dict.values()), \"s2\": list(wNmNc_s2_dict.values()), \"s3\": list(wNmNc_s3_dict.values()), \"s4\": list(wNmNc_s4_dict.values()), \"type\":wNmNcTypes}\n",
    "\n",
    "#checking that all lengths are the same\n",
    "\n",
    "print(len(wNmNc_s1_dict.values()))  \n",
    "print(len(wNmNc_s2_dict.values())) \n",
    "print(len(wNmNc_s3_dict.values()))  \n",
    "print(len(wNmNc_s4_dict.values()))     \n",
    "\n",
    "\n",
    "slopes = pd.DataFrame(slopes_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#creating a parallel coordinates graph in an attempt to do four-dimensional data analysis of the slopes\n",
    "pd.plotting.parallel_coordinates(slopes, 'type', color = (\"r\", \"g\", \"b\"))\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"Slopes of Stars\", size = 30)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a scatter plot of slope1 vs. slope2 for weak CN, carbon, and identified, ivar-trimmed other stars\n",
    "plt.scatter(carbon_s1_dict.values(), carbon_s2_dict.values(), color = 'r', alpha = 0.5, label = 'Carbon Stars')\n",
    "plt.scatter(kphTrO1_s1_dict.values(), kphTrO1_s2_dict.values(), alpha = 0.5, color = 'g', label = 'Others1 Stars')\n",
    "plt.scatter(kphTrO2_s1_dict.values(), kphTrO2_s2_dict.values(), alpha = 0.5, color = 'orange', label = 'Others2 Stars')\n",
    "plt.scatter(weak_s1_dict.values(), weak_s2_dict.values(), color = 'b', alpha = 0.5, s = 100, label = 'Weak CN Stars')\n",
    "plt.scatter(marginal_s1_dict.values(), marginal_s2_dict.values(), color = 'b', alpha = 0.5, s = 10, label = 'Marginal CN Stars')\n",
    "#plt.scatter(wNm_s1_dict.values(), wNm_s2_dict.values(), color = 'b', alpha = 0.5, label = 'Weak CN Stars')\n",
    "\n",
    "#formatting the graph so that it is easier to read\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"Slope1 vs. Slope2\", size = 30) \n",
    "plt.ylabel(\"Slope2\", size = 20)\n",
    "plt.xlabel(\"Slope1\", size = 20)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a scatter plot of slope1 vs. slope2 for weak CN, carbon, and identified, ivar-trimmed other stars\n",
    "plt.scatter(carbon_s3_dict.values(), carbon_s4_dict.values(), color = 'r', alpha = 0.5, label = 'Carbon Stars')\n",
    "plt.scatter(kphTrO1_s3_dict.values(), kphTrO1_s4_dict.values(), alpha = 0.5, color = 'g', label = 'Others1 Stars')\n",
    "plt.scatter(kphTrO2_s3_dict.values(), kphTrO2_s4_dict.values(), alpha = 0.5, color = 'orange', label = 'Others2 Stars')\n",
    "plt.scatter(weak_s3_dict.values(), weak_s4_dict.values(), color = 'b', alpha = 0.5, s = 100, label = 'Weak CN Stars')\n",
    "plt.scatter(marginal_s3_dict.values(), marginal_s4_dict.values(), color = 'b', alpha = 0.5, s = 10, label = 'Marginal CN Stars')\n",
    "#plt.scatter(wNm_s3_dict.values(), wNm_s4_dict.values(), color = 'b', alpha = 0.5, label = 'Weak CN Stars')\n",
    "\n",
    "#formatting the graph so that it is easier to read\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"Slope3 vs. Slope4\", size = 30) \n",
    "plt.ylabel(\"Slope4\", size = 20)\n",
    "plt.xlabel(\"Slope3\", size = 20)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot s4-s3 vs s2-s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create slope arrays from dictionary values for weak CN\n",
    "s4_wNm = np.array(list(wNm_s4_dict.values()))\n",
    "s3_wNm = np.array(list(wNm_s3_dict.values()))\n",
    "s2_wNm = np.array(list(wNm_s2_dict.values()))\n",
    "s1_wNm = np.array(list(wNm_s1_dict.values()))\n",
    "\n",
    "#create slope arrays from dictionary values for Carbon\n",
    "s4_C = np.array(list(carbon_s4_dict.values()))\n",
    "s3_C = np.array(list(carbon_s3_dict.values()))\n",
    "s2_C = np.array(list(carbon_s2_dict.values()))\n",
    "s1_C = np.array(list(carbon_s1_dict.values()))\n",
    "\n",
    "#create slope arrays from dictionary values for Others\n",
    "s4_O = np.array(list(others_s4_dict.values()))\n",
    "s3_O = np.array(list(others_s3_dict.values()))\n",
    "s2_O = np.array(list(others_s2_dict.values()))\n",
    "s1_O = np.array(list(others_s1_dict.values()))\n",
    "\n",
    "#Perform s4-s3 and s2-s1 operation for each group\n",
    "s4_s3_wNm = s4_wNm - s3_wNm\n",
    "s2_s1_wNm = s2_wNm - s1_wNm\n",
    "\n",
    "s4_s3_C = s4_C - s3_C\n",
    "s2_s1_C = s2_C - s1_C\n",
    "\n",
    "s4_s3_O = s4_O - s3_O\n",
    "s2_s1_O = s2_O - s1_O\n",
    "\n",
    "#Normalize s4-s3 and s2-s1 to template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(s4_s3_O, s2_s1_O, color ='orange', alpha =0.2, s= 10, label = 'Others')\n",
    "plt.scatter(s4_s3_wNm, s2_s1_wNm, color='blue',s=35, label = 'Weak CN Stars')\n",
    "plt.scatter(s4_s3_C, s2_s1_C, color ='red', label = 'Carbon')\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"S4-S3 vs S2-S1\", size = 30) \n",
    "plt.ylabel(\"Slope 2 - Slope 1\", size = 25)\n",
    "plt.xlim([-.01,.01])\n",
    "plt.ylim([-.025,.03])\n",
    "plt.xlabel(\"Slope 4 - Slope 3\", size = 25)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#finding s4 - s3 and s2 - s1 for the templates of carbon\n",
    "s1c_template,s2c_template,s3c_template,s4c_template = getWSlopes(Ctemplate)\n",
    "s4_s3_c_template = s4c_template-s3c_template\n",
    "s2_s1_c_template = s2c_template-s1c_template\n",
    "\n",
    "#plotting standardized histogram for s2 - s1 for carbon vs. wNm\n",
    "plt.hist(s2_s1_C - s2_s1_c_template, color='red',histtype=u'step', linewidth = 2.0, label = 'Carbon')\n",
    "plt.hist(s2_s1_wNm - s2_s1_c_template, color='blue',histtype=u'step', linewidth = 2.0, label = 'Weak CN')\n",
    "plt.hist(s2_s1_O - s2_s1_c_template, color='orange',histtype=u'step', linewidth = 2.0, label = 'Weak CN')\n",
    "plt.ylabel('count', size = 25)\n",
    "plt.xlabel('standardized slope difference', size = 25)\n",
    "plt.xlim([-.02,.02])\n",
    "plt.title(\"S2-S1 standardized to carbon template\", size = 30) \n",
    "\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#plotting standardized histogram for s4 - s3 for carbon vs. wNm\n",
    "plt.hist(s4_s3_C - s4_s3_c_template, color='red',histtype=u'step', linewidth = 2.0, label = 'Carbon')\n",
    "plt.hist(s4_s3_wNm - s4_s3_c_template, color='blue',histtype=u'step', linewidth = 2.0, label = 'Weak CN')\n",
    "plt.hist(s4_s3_O - s4_s3_c_template, color='orange',histtype=u'step', linewidth = 2.0, label = 'Weak CN')\n",
    "plt.ylabel('count', size = 25)\n",
    "plt.xlabel('standardized slope difference', size = 25)\n",
    "plt.xlim([-.02,.02])\n",
    "plt.title(\"S4-S3 standardized to carbon template\", size = 30) \n",
    "\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding s4 - s3 and s2 - s1 for the templates of carbon and weak CN\n",
    "s1c_template,s2c_template,s3c_template,s4c_template = getWSlopes(Ctemplate)\n",
    "s4_s3_c_template = s4c_template-s3c_template\n",
    "s2_s1_c_template = s2c_template-s1c_template\n",
    "\n",
    "s1w_template,s2w_template,s3w_template,s4w_template = getWSlopes(Wtemplate)\n",
    "s4_s3_w_template = s4w_template-s3w_template\n",
    "s2_s1_w_template = s2w_template-s1w_template\n",
    "\n",
    "#plotting standardized histogram for s2 - s1 for carbon vs. wNm\n",
    "plt.hist(s2_s1_C - s2_s1_c_template, color='red',histtype=u'step', linewidth = 2.0, label = 'Carbon')\n",
    "plt.hist(s2_s1_wNm - s2_s1_w_template, color='blue',histtype=u'step', linewidth = 2.0, label = 'Weak CN')\n",
    "plt.ylabel('count', size = 25)\n",
    "plt.xlabel('standardized slope difference', size = 25)\n",
    "plt.xlim([-.02,.02])\n",
    "plt.title(\"S2-S1 standardized to respective template\", size = 30) \n",
    "\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#plotting standardized histogram for s4 - s3 for carbon vs. wNm\n",
    "plt.hist(s4_s3_C - s4_s3_c_template, color='red',histtype=u'step', linewidth = 2.0, label = 'Carbon')\n",
    "plt.hist(s4_s3_wNm - s4_s3_w_template, color='blue',histtype=u'step', linewidth = 2.0, label = 'Weak CN')\n",
    "plt.ylabel('count', size = 25)\n",
    "plt.xlabel('standardized slope difference', size = 25)\n",
    "plt.xlim([-.02,.02])\n",
    "plt.title(\"S4-S3 standardized to respective template\", size = 30) \n",
    "\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding s4 - s3 and s2 - s1 for the templates of carbon and weak CN\n",
    "s1c_template,s2c_template,s3c_template,s4c_template = getWSlopes(Ctemplate)\n",
    "s4_s3_c_template = s4c_template-s3c_template\n",
    "s2_s1_c_template = s2c_template-s1c_template\n",
    "\n",
    "s1w_template,s2w_template,s3w_template,s4w_template = getWSlopes(Wtemplate)\n",
    "s4_s3_w_template = s4w_template-s3w_template\n",
    "s2_s1_w_template = s2w_template-s1w_template\n",
    "\n",
    "#plotting standardized histogram for s2 - s1 for carbon vs. wNm\n",
    "plt.hist(s2_s1_C, color='red',histtype=u'step', linewidth = 2.0, label = 'Carbon')\n",
    "plt.hist(s2_s1_wNm, color='blue',histtype=u'step', linewidth = 2.0, label = 'Weak CN')\n",
    "plt.ylabel('count', size = 25)\n",
    "plt.xlabel('standardized slope difference', size = 25)\n",
    "plt.xlim([-.01,.04])\n",
    "plt.title(\"S2-S1\", size = 30) \n",
    "\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#plotting standardized histogram for s4 - s3 for carbon vs. wNm\n",
    "plt.hist(s4_s3_C, color='red',histtype=u'step', linewidth = 2.0, label = 'Carbon')\n",
    "plt.hist(s4_s3_wNm, color='blue',histtype=u'step', linewidth = 2.0, label = 'Weak CN')\n",
    "plt.ylabel('count', size = 25)\n",
    "plt.xlabel('standardized slope difference', size = 25)\n",
    "plt.xlim([-.01,.04])\n",
    "plt.title(\"S4-S3\", size = 30) \n",
    "\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CMDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes functions for creating CMDs based on the F814W and F160W filter data from the PHAT survey. In these CMDs, the x-axis is F814W - F160W and the y-axis is F160W (this can be changed by editing the graphCMD function). Also includes functions that draw bins on the CMD for grouping stars, and functions that determine whether or not certain stars lie within those bins. These processes are used to create new datasets for coadditions, as well as analyze the placement of unidentified stars relative to identified carbon and weak CN stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines a function that plots any set of star indices on a CMD\n",
    "#note that the CMD is defined as followed: the x-axis is visible - infrared and the y-axis is infrared\n",
    "def graphCMD(data, indices, markersize = 20, color = 'b', marker = 'o', label = None, facecolor = True, alpha = None):\n",
    "    '''\n",
    "    data: a Numpy array that consists of the dataset your color-magnitude information is contained in\n",
    "    indices: a Numpy array or list of the star indices to be graphed on the CMD\n",
    "    markersize: an integer representing the size of the dots to be plotted on the CMD\n",
    "    color: a string representing the color of the dots to be plotted on the CMD\n",
    "    marker: a string representing the shape of the dots to be plotted on the CMD\n",
    "    label: a string representing the label that will be assigned in the legend of the CMD to the dots plotted here\n",
    "    facecolor: a Boolean value that, if True, will fill in the dots plotted on the CMD and, if False, will plot open circles\n",
    "    alpha: a numerical value representing the opacity of the markers to be graphed\n",
    "    \n",
    "    markersize, color, marker, label, facecolor, and alpha will default to 20, 'b' (blue), 'o', None, True, and None respectively\n",
    "    \n",
    "    Note that there is no return value, as well as no plt.show() statement. The plt.show() statement must be included in your code where this function is called\n",
    "    '''\n",
    "    if facecolor:\n",
    "        plt.scatter((data.F814W[indices] - data.F160W[indices]), data.F160W[indices], s = markersize, color = color, marker = marker, label = label, alpha = alpha)\n",
    "    else:\n",
    "        plt.scatter((data.F814W[indices] - data.F160W[indices]), data.F160W[indices], s = markersize, color = color, marker = marker, label = label, facecolors = 'none', alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines variables that will be used for graphing Rosenfield's line\n",
    "m = (19 - -52.965)/(2.03045-10)\n",
    "xRos = np.arange(1, 3, .01)\n",
    "yRos = m*xRos - 2.0345*m + 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the CMD with our bins\n",
    "plt.rcParams['figure.figsize'] = 13,11\n",
    "\n",
    "graphCMD(data, others, 1, 'black', label = 'Other', alpha = .6, facecolor = False)\n",
    "graphCMD(data, wNm, 13, 'blue', label = 'Visually Classified Weak CN')\n",
    "graphCMD(data, allcarbon, 13, 'red', label = 'Visually Classified Carbon')\n",
    "#graphCMD(data, possTruewNm, 13, 'purple', label = 'Machine-Classified Weak CN')\n",
    "#graphCMD(data, possTruewNm_multiD, 13, 'green', label = 'Multi-D Classified Weak CN')\n",
    "#graphCMD(data, possTruewNm_multiD2, 13, 'green', label = 'Multi-D Classified Weak CN')\n",
    "#graphCMD(data, possTruewNm_multiD3, 13, 'green', label = 'Multi-D Classified Weak CN')\n",
    "\n",
    "# polygon(Cbin1_points, 'blue', 'Carbon 1 (C1)')\n",
    "# polygon(Cbin2_points, 'violet', 'Carbon 2 (C2)')\n",
    "# polygon(Wbin1_points, 'orange', 'Weak CN 1 (W1)')\n",
    "# polygon(Wbin2_points, 'indigo', 'Weak CN 2 (W2)')\n",
    "\n",
    "plt.plot(xRos, yRos, color = 'black', linewidth = 3, linestyle = '--', label = 'Rosenfield line')\n",
    "\n",
    "plt.title(\"Color-Magnitude Diagram\", size = 20) \n",
    "plt.ylabel(\"F160W\", size = 20)\n",
    "plt.xlabel(\"F814W - F160W\", size = 20)\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(25, 14)\n",
    "# plt.xlim(1,4)\n",
    "# plt.ylim(21,16)\n",
    "plt.legend(loc = \"right\", bbox_to_anchor = (1.3,.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unmodified Templates - Full Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify as either carbon or wNm using scores to carbon template\n",
    "#returns probability it is a WeakCN Star\n",
    "\n",
    "def probWCN_CTemp(star):\n",
    "    #retrieve star's score\n",
    "    starCscore=getScore(Ctemplate, splashSpecs_dict[star], splashIvars_dict[star])\n",
    "    #count the number of carbon above and weakCN below\n",
    "    numberCarbonAbove = 0\n",
    "    numberWeakCNBelow = 0\n",
    "    for value in carbon_Cscore_dict.values():\n",
    "        if(starCscore<value):\n",
    "            numberCarbonAbove+=1\n",
    "    for value in wNm_Cscore_dict.values():\n",
    "        if(starCscore>value):\n",
    "            numberWeakCNBelow+=1;\n",
    "    \n",
    "    #Calculates probability by taking propotion of stars on left and right\n",
    "    probCarbon = numberCarbonAbove/(numberCarbonAbove+numberWeakCNBelow)\n",
    "    probWeakCN = numberWeakCNBelow/(numberCarbonAbove+numberWeakCNBelow)\n",
    "\n",
    "#     print('Score of star versus C template: ',starCscore)\n",
    "#     print('Probability star is carbon: ', probCarbon)\n",
    "#     print('Probability Star is WeakCN: ', probWeakCN)\n",
    "    return probWeakCN\n",
    "    \n",
    "#probWCN_CTemp(19971)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify as either carbon or wNm using scores to WeakCN template\n",
    "#returns probability it is a WeakCN Star\n",
    "\n",
    "def probWCN_WTemp(star):\n",
    "    #retrieve star's score\n",
    "    starWscore=getScore(Wtemplate, splashSpecs_dict[star], splashIvars_dict[star])\n",
    "    #count the number of carbon below and weakCN above\n",
    "    numberCarbonBelow = 0\n",
    "    numberWeakCNAbove = 0\n",
    "    for value in carbon_score_dict.values():\n",
    "        if(starWscore>value):\n",
    "            numberCarbonBelow+=1\n",
    "    for value in wNm_score_dict.values():\n",
    "        if(starWscore<value):\n",
    "            numberWeakCNAbove+=1;\n",
    "    \n",
    "    #Calculates probability by taking propotion of stars on left and right\n",
    "    probCarbon = numberCarbonBelow/(numberCarbonBelow+numberWeakCNAbove)\n",
    "    probWeakCN = numberWeakCNAbove/(numberCarbonBelow+numberWeakCNAbove)\n",
    "\n",
    "#     print('Score of star versus W template: ',starWscore)\n",
    "#     print('Probability star is carbon: ', probCarbon)\n",
    "#     print('Probability Star is WeakCN: ', probWeakCN)\n",
    "    return probWeakCN\n",
    "\n",
    "#probWCN_WTemp(19971)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probThresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def carbonClassificationByTemplateScore(probThresh = 0.5):\n",
    "    #Test accuracy of using the C and W template on carbon stars\n",
    "countCorrectByC = 0\n",
    "countCorrectByW = 0\n",
    "countCorrectByProduct = 0\n",
    "probByC_C = []\n",
    "probByW_C = []\n",
    "probByProduct_C = []\n",
    "total = 0\n",
    "\n",
    "    #Iterate over all stars\n",
    "for star in allcarbon:\n",
    "        #Skip over if not valid\n",
    "    if(not(splashSuccess_dict[star])):\n",
    "        continue\n",
    "        #If the probability is less than 0.5, less likely to be Weak CN\n",
    "    if (probWCN_CTemp(star)<probThresh):\n",
    "        countCorrectByC+=1\n",
    "        probByC_C.append(probWCN_CTemp(star))\n",
    "    if (probWCN_WTemp(star)<probThresh):\n",
    "        countCorrectByW+=1 \n",
    "        probByW_C.append(probWCN_WTemp(star))\n",
    "    if (probWCN_CTemp(star)*probWCN_CTemp(star)<probThresh):\n",
    "        countCorrectByProduct+=1\n",
    "        probByProduct_C.append(probWCN_CTemp(star)*probWCN_CTemp(star))\n",
    "    total+=1\n",
    "\n",
    "    #Prints porprtion of stars for which a correct analysis was given\n",
    "print('Percent of carbon correctly identified by C template: ',countCorrectByC/total)\n",
    "print('Percent of carbon correctly identified by W template: ',countCorrectByW/total)\n",
    "print('Percent of carbon correctly identified by product: ',countCorrectByProduct/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def weakCNClassificationByTemplateScore(probThresh = 0.5):\n",
    "    #Test accuracy of using the C and W template on WeakCN stars\n",
    "countCorrectByC = 0\n",
    "countCorrectByW = 0\n",
    "countCorrectByProduct = 0\n",
    "probByC_W = []\n",
    "probByW_W = []\n",
    "probByProduct_W = []\n",
    "total = 0\n",
    "    #Iterate over all stars\n",
    "for star in wNm:\n",
    "        #Skip over if not valid\n",
    "    if(not(splashSuccess_dict[star])):\n",
    "        continue\n",
    "        #If the probability is less than 0.5, less likely to be Weak CN\n",
    "    if (probWCN_CTemp(star)>probThresh):\n",
    "        countCorrectByC+=1\n",
    "        probByC_W.append(probWCN_CTemp(star))\n",
    "    if (probWCN_WTemp(star)>probThresh):\n",
    "        countCorrectByW+=1  \n",
    "        probByW_W.append(probWCN_CTemp(star))\n",
    "    if (probWCN_CTemp(star)*probWCN_CTemp(star)>probThresh):\n",
    "        countCorrectByProduct+=1\n",
    "        probByProduct_W.append(probWCN_CTemp(star))\n",
    "    total+=1\n",
    "\n",
    "\n",
    "    #Prints porprtion of stars for which a correct analysis was given\n",
    "print(' ')\n",
    "print('Percent of wNm correctly identified by C template: ',countCorrectByC/total)\n",
    "print('Percent of wNm correctly identified by W template: ',countCorrectByW/total)\n",
    "print('Percent of wNm correctly identified by product: ',countCorrectByProduct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for probThresh in [0.65]:\n",
    "    print(probThresh)\n",
    "    carbonClassificationByTemplateScore(probThresh)\n",
    "    weakCNClassificationByTemplateScore(probThresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probByC_C, color ='red',histtype=u'step', linewidth = 2.0,label='Carbon')\n",
    "plt.hist(probByC_W, color = 'blue',histtype=u'step', linewidth = 2.0,label='Weak CN')\n",
    "\n",
    "plt.axvline(x = probThresh)\n",
    "plt.xlabel('Chance of being Weak CN')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Probabilities of Star being Weak CN')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probByW_C, color ='red',histtype=u'step', linewidth = 4.0,label='Carbon')\n",
    "plt.hist(probByW_W, color = 'blue',histtype=u'step', linewidth = 4.0,label='Weak CN')\n",
    "\n",
    "plt.axvline(x = probThresh)\n",
    "plt.xlabel('Chance of being Weak CN')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Probabilities of Star being Weak CN')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unmodified Templates - First 'U' Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#creates a function that calculates the score (a measure of the difference between two spectra) for a certain star's spectrum compared to a certain template spectrum\n",
    "#note that the input spectra and ivars must be already sliced and normalized\n",
    "def getScoreFirstU(templateSpec, scienceSpec, ivars, lowerThreshBound = 5840, upperThreshBound = 6550):\n",
    "    '''\n",
    "    templateSpec: a Numpy array containing the flux values of the coadded template spectrum\n",
    "    scienceSpec: a Numpy array containing the flux values at each wavelength of the normalized spectrum for a specific star\n",
    "    ivars: a Numpy array containing the normalized ivar values at each wavelength of the spectrum for a specific star\n",
    "    \n",
    "    Returns finalScore, a float representing the similarity between the two spectra. A lower score indicates greater similarity and a higher score indicates lower similarity\n",
    "    Note that spectra that cannot be normalized will not have a score associated with them. The function returns a NaN as the score for these spectra\n",
    "    '''\n",
    "    templateSpec_list = templateSpec.tolist()\n",
    "    scienceSpec_list = scienceSpec[~np.isnan(scienceSpec)].tolist()\n",
    "    if scienceSpec_list == []:\n",
    "        print(\"ScoreError: Because this spectrum cannot be normalized, its score cannot be found.\")\n",
    "        return np.nan\n",
    "    else:\n",
    "        summedScore = 0\n",
    "        for wv in range(len(templateSpec_list)):\n",
    "            score = ((scienceSpec[wv] - templateSpec[wv])**2) * ivars[wv]\n",
    "            if not np.isnan(score):\n",
    "                summedScore += score\n",
    "        summedIvars = 0\n",
    "        for ivar in ivars:\n",
    "            if not np.isnan(ivar):\n",
    "                summedIvars += ivar\n",
    "        finalScore = (summedScore/summedIvars)**0.5\n",
    "        return finalScore\n",
    "\n",
    "#test execution of function\n",
    "specStar, ivarStar = splashSpecs_dict[19534],splashIvars_dict[19534]\n",
    "print(\"Score: \" + str(getScore(Wtemplate, specStar, ivarStar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     7,
     16,
     25
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carbon_Cscore_dict_1U = {}\n",
    "carbon_score_dict_1U = {}\n",
    "wNm_Cscore_dict_1U = {}\n",
    "wNm_score_dict_1U = {}\n",
    "others_Cscore_dict_1U = {}\n",
    "others_score_dict_1U = {}\n",
    "\n",
    "for star in allcarbon:\n",
    "    if(splashSuccess_dict[star]):\n",
    "        carbon_Cscore_dict_1U[star] = getScore(Ctemplate[:355], \n",
    "                                               splashSpecs_dict[star][:355], \n",
    "                                               splashIvars_dict[star][:355])\n",
    "        carbon_score_dict_1U[star] = getScore(Wtemplate[:355], \n",
    "                                               splashSpecs_dict[star][:355], \n",
    "                                               splashIvars_dict[star][:355])\n",
    "    \n",
    "for star in wNm:\n",
    "    if(splashSuccess_dict[star]):\n",
    "        wNm_Cscore_dict_1U[star] = getScore(Ctemplate[:355], \n",
    "                                               splashSpecs_dict[star][:355], \n",
    "                                               splashIvars_dict[star][:355])\n",
    "        wNm_score_dict_1U[star] = getScore(Wtemplate[:355], \n",
    "                                               splashSpecs_dict[star][:355], \n",
    "                                               splashIvars_dict[star][:355])\n",
    "count = 0\n",
    "for star in others:\n",
    "    if(splashSuccess_dict[star]):\n",
    "        others_Cscore_dict_1U[star] = getScore(Ctemplate[:355], \n",
    "                                               splashSpecs_dict[star][:355], \n",
    "                                               splashIvars_dict[star][:355])\n",
    "        others_score_dict_1U[star] = getScore(Wtemplate[:355], \n",
    "                                               splashSpecs_dict[star][:355], \n",
    "                                               splashIvars_dict[star][:355])\n",
    "        if(count%100==0):\n",
    "            print(count)\n",
    "        count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(others_score_dict_1U.values(), others_Cscore_dict_1U.values(),color ='orange',s=10)\n",
    "plt.scatter(carbon_score_dict_1U.values(), carbon_Cscore_dict_1U.values(), color ='red')\n",
    "plt.scatter(wNm_score_dict_1U.values(), wNm_Cscore_dict_1U.values(),color ='blue',s=35)\n",
    "plt.xlim(0,2)\n",
    "plt.ylim(0.1,0.7)\n",
    "#print(wNm_Cscore_dict_1U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify as either carbon or wNm using scores to carbon template\n",
    "#returns probability it is a WeakCN Star\n",
    "\n",
    "def probWCN_CTemp_1U(star):\n",
    "    #retrieve star's score\n",
    "    starCscore=getScore(Ctemplate[lowerThresh:middleThresh], splashSpecs_dict[star][:355], splashIvars_dict[star][:355])\n",
    "    #count the number of carbon above and weakCN below\n",
    "    numberCarbonAbove = 0\n",
    "    numberWeakCNBelow = 0\n",
    "    for value in carbon_Cscore_dict_1U.values():\n",
    "        if(starCscore<value):\n",
    "            numberCarbonAbove+=1\n",
    "    for value in wNm_Cscore_dict_1U.values():\n",
    "        if(starCscore>value):\n",
    "            numberWeakCNBelow+=1;\n",
    "    try:\n",
    "        #Calculates probability by taking propotion of stars on left and right\n",
    "        probCarbon = numberCarbonAbove/(numberCarbonAbove+numberWeakCNBelow)\n",
    "        probWeakCN = numberWeakCNBelow/(numberCarbonAbove+numberWeakCNBelow)\n",
    "\n",
    "    #     print('Score of star versus C template: ',starCscore)\n",
    "    #     print('Probability star is carbon: ', probCarbon)\n",
    "    #     print('Probability Star is WeakCN: ', probWeakCN)\n",
    "        return probWeakCN\n",
    "    except:\n",
    "        return 1\n",
    "    \n",
    "#probWeakCNByCTemplate(19971)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify as either carbon or wNm using scores to WeakCN template\n",
    "#returns probability it is a WeakCN Star\n",
    "\n",
    "def probWCN_WTemp_1U(star):\n",
    "    #retrieve star's score\n",
    "    starWscore=getScore(Wtemplate[5840:6184], splashSpecs_dict[star][:355], splashIvars_dict[star][:355])\n",
    "    #count the number of carbon below and weakCN above\n",
    "    numberCarbonBelow = 0\n",
    "    numberWeakCNAbove = 0\n",
    "    for value in carbon_score_dict_1U.values():\n",
    "        if(starWscore>value):\n",
    "            numberCarbonBelow+=1\n",
    "    for value in wNm_score_dict_1U.values():\n",
    "        if(starWscore<value):\n",
    "            numberWeakCNAbove+=1;\n",
    "    try:\n",
    "        #Calculates probability by taking propotion of stars on left and right\n",
    "        probCarbon = numberCarbonBelow/(numberCarbonBelow+numberWeakCNAbove)\n",
    "        probWeakCN = numberWeakCNAbove/(numberCarbonBelow+numberWeakCNAbove)\n",
    "\n",
    "    #     print('Score of star versus W template: ',starWscore)\n",
    "    #     print('Probability star is carbon: ', probCarbon)\n",
    "    #     print('Probability Star is WeakCN: ', probWeakCN)\n",
    "        return probWeakCN\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "#probWeakCNByWTemplate(19971)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probByC_C_1U = []\n",
    "probByW_C_1U = []\n",
    "probByProduct_C_1U = []\n",
    "#Carbon Classification By Template Score First U\n",
    "def CClassifier_1U(probThresh = 0.5):\n",
    "    #Test accuracy of using the C and W template on carbon stars\n",
    "    countCorrectByC = 0\n",
    "    countCorrectByW = 0\n",
    "    countCorrectByProduct = 0\n",
    "    \n",
    "    total = 0\n",
    "\n",
    "    #Iterate over all stars\n",
    "    for star in allcarbon:\n",
    "        #Skip over if not valid\n",
    "        if(not(splashSuccess_dict[star])):\n",
    "            continue\n",
    "        #If the probability is less than 0.5, less likely to be Weak CN\n",
    "        if (probWCN_CTemp_1U(star)<probThresh):\n",
    "            countCorrectByC+=1\n",
    "            probByC_C.append(probWCN_CTemp_1U(star))\n",
    "        if (probWCN_WTemp_1U(star)<probThresh):\n",
    "            countCorrectByW+=1 \n",
    "            probByW_C.append(probWCN_WTemp_1U(star))\n",
    "        if (probWCN_CTemp_1U(star)*probWCN_CTemp_1U(star)<probThresh):\n",
    "            countCorrectByProduct+=1\n",
    "            probByProduct_C.append(probWCN_CTemp_1U(star)*probWCN_CTemp_1U(star))\n",
    "        total+=1\n",
    "\n",
    "    #Prints porprtion of stars for which a correct analysis was given\n",
    "    print('Percent of carbon correctly identified by C template: ',countCorrectByC/total)\n",
    "    print('Percent of carbon correctly identified by W template: ',countCorrectByW/total)\n",
    "    print('Percent of carbon correctly identified by product: ',countCorrectByProduct/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probByC_W_1U = []\n",
    "probByW_W_1U = []\n",
    "probByProduct_W_1U = []\n",
    "#WCNClassifier_1U\n",
    "def WCNClassifier_1U(probThresh = 0.5):\n",
    "    #Test accuracy of using the C and W template on WeakCN stars\n",
    "    countCorrectByC = 0\n",
    "    countCorrectByW = 0\n",
    "    countCorrectByProduct = 0\n",
    "    total = 0\n",
    "    #Iterate over all stars\n",
    "    for star in wNm:\n",
    "        #Skip over if not valid\n",
    "        if(not(splashSuccess_dict[star])):\n",
    "            continue\n",
    "        #If the probability is less than 0.5, less likely to be Weak CN\n",
    "        if (probWCN_CTemp_1U(star)>probThresh):\n",
    "            countCorrectByC+=1\n",
    "            probByC_W.append(probWCN_CTemp_1U(star))\n",
    "        if (probWCN_WTemp_1U(star)>probThresh):\n",
    "            countCorrectByW+=1  \n",
    "            probByW_W.append(probWCN_CTemp_1U(star))\n",
    "        if (probWCN_CTemp_1U(star)*probWCN_CTemp_1U(star)>probThresh):\n",
    "            countCorrectByProduct+=1\n",
    "            probByProduct_W.append(probWCN_CTemp_1U(star))\n",
    "        total+=1\n",
    "\n",
    "\n",
    "    #Prints porprtion of stars for which a correct analysis was given\n",
    "    print(total)\n",
    "    print('Percent of wNm correctly identified by C template: ',countCorrectByC/total)\n",
    "    print('Percent of wNm correctly identified by W template: ',countCorrectByW/total)\n",
    "    print('Percent of wNm correctly identified by product: ',countCorrectByProduct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for probThresh in [0.65]:\n",
    "    print(probThresh)\n",
    "    CClassifier_1U(probThresh)\n",
    "    WCNClassifier_1U(probThresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probByC_C_1U, color ='red',histtype=u'step', linewidth = 2.0)\n",
    "plt.hist(probByC_W_1U, color = 'blue',histtype=u'step', linewidth = 2.0)\n",
    "\n",
    "plt.axvline(x = probThresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probByW_C_1U, color ='red',histtype=u'step', linewidth = 4.0)\n",
    "plt.hist(probByW_W_1U, color = 'blue',histtype=u'step', linewidth = 4.0)\n",
    "\n",
    "plt.axvline(x = probThresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ellipse Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fivePointsToConic(points, f=1.0):\n",
    "    \"\"\"Solve for the coefficients of a conic given five points in Numpy array\n",
    "\n",
    "    `points` should have at least five rows.\n",
    "\n",
    "    `f` is the constant that you can specify. With the returned solution,\n",
    "    `(a, b, c, d, e, f)`, the full conic is specified as:\n",
    "\n",
    "    $a x^2 + b x y + c y^2 + d x + e y = -f$\n",
    "\n",
    "    If `points` has exactly five rows, the equation will be exact. If `points`\n",
    "    has *more* than five rows, the solution will be a least-squares one that\n",
    "    fits the data the best.\n",
    "    \"\"\"\n",
    "    from numpy.linalg import lstsq\n",
    "\n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    if max(x.shape) < 5:\n",
    "        raise ValueError('Need >= 5 points to solve for conic section')\n",
    "\n",
    "    A = np.vstack([x**2, x * y, y**2, x, y]).T\n",
    "    fullSolution = lstsq(A, f * np.ones(x.size))\n",
    "    (a, b, c, d, e) = fullSolution[0]\n",
    "    return (a, b, c, d, e, f)\n",
    "    #Ax^{2}+Bxy+Cy^{2}+Dx+Ey+F=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(others_score2_uwdict.values(),others_score2_ucdict.values(), color ='orange', alpha =0.2, s= 18, label = 'Others')\n",
    "plt.scatter(wNm_score2_uwdict.values(),wNm_score2_ucdict.values(), color='blue',s=35, label = 'Weak CN')\n",
    "plt.scatter(carbon_score2_uwdict.values(),carbon_score2_ucdict.values(), color ='red', label = 'Carbon')\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.xlim([0,1])\n",
    "plt.ylim(0.1,0.9)\n",
    "# plt.xlim([.08,0.12])\n",
    "# plt.ylim([0.15,0.2])\n",
    "# plt.xlim([0.25,0.35])\n",
    "# plt.ylim([0.28,0.36])\n",
    "plt.xlabel(\"Score against Weak CN Template\", size = 25)\n",
    "plt.ylabel(\"Score against C Template\", size = 25)\n",
    "plt.title(\"Score Against Undiluted W vs C Template\", size = 30) \n",
    "plt.legend(fontsize = 20)\n",
    "# Creating the COW Line\n",
    "divLineX= np.linspace(0,5,1000)\n",
    "divLineY = 0.649*divLineX+0.124\n",
    "plt.plot(divLineX,divLineY)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(others_score_dict_1U.values(), others_Cscore_dict_1U.values(),color ='orange',s=10,label='Others')\n",
    "plt.scatter(carbon_score_dict_1U.values(), carbon_Cscore_dict_1U.values(), color ='red',label='Carbon')\n",
    "plt.scatter(wNm_score_dict_1U.values(), wNm_Cscore_dict_1U.values(),color ='blue',s=35,label='Weak CN')\n",
    "plt.xlim(0,0.22)\n",
    "plt.ylim(0.2,0.6)\n",
    "plt.xlabel(\"Score against Weak CN Template 1U\", size = 25)\n",
    "plt.ylabel(\"Score against C Template 1U\", size = 25)\n",
    "plt.title(\"Score Against Undiluted W 1U vs C Template 1U\", size = 30) \n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "mean = [ 0.1 ,  0.435]\n",
    "width = 0.17\n",
    "height = 0.105\n",
    "angle = 18\n",
    "ell = mpl.patches.Ellipse(xy=mean, width=width, height=height, \n",
    "                          angle = 180+angle, lw=4, facecolor='None',edgecolor='b')\n",
    "\n",
    "\n",
    "ax.add_patch(ell)\n",
    "plt.show()\n",
    "\n",
    "#print(wNm_Cscore_dict_1U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(s4_s3_O, s2_s1_O, color ='orange', alpha =0.2, s= 10, label = 'Others')\n",
    "plt.scatter(s4_s3_wNm, s2_s1_wNm, color='blue',s=35, label = 'Weak CN Stars')\n",
    "plt.scatter(s4_s3_C, s2_s1_C, color ='red', label = 'Carbon')\n",
    "plt.rcParams['figure.figsize'] = 30,11 \n",
    "plt.title(\"S4-S3 vs S2-S1\", size = 30) \n",
    "plt.ylabel(\"Slope 2 - Slope 1\", size = 25)\n",
    "plt.xlim([-.002,.0035])\n",
    "plt.ylim([-.001,.015])\n",
    "plt.xlabel(\"Slope 4 - Slope 3\", size = 25)\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "mean = [ 0.0010 ,  0.0022]\n",
    "width = 0.0030\n",
    "height = 0.0054\n",
    "angle = 0\n",
    "ell = mpl.patches.Ellipse(xy=mean, width=width, height=height, \n",
    "                          angle = 180+angle, lw=4, facecolor='None',edgecolor='b')\n",
    "\n",
    "ax.add_patch(ell)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing to find coordinates of certain points for ellipse boundaries\n",
    "# for star in s4_s3_wNm:\n",
    "#     if(s4_s3_wNm[star] < -0.001):\n",
    "#         print(star,' s4_s3 = ',s4_s3_wNm[star])\n",
    "\n",
    "for i in range(0,len(s4_s3_wNm)):\n",
    "    if(s2_s1_wNm[i] > 0.0037):\n",
    "        print(i,' s4_s3 = ',s4_s3_wNm[i],', s2_s1 = ',s2_s1_wNm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(others_c_dict.values(),others_score2_dict.values(), color ='orange', alpha =0.2, s= 10, label = 'Others')\n",
    "plt.scatter(wNm_c_dict.values(),wNm_score2_dict.values(), color='blue',s=35, label = 'Weak CN Stars')\n",
    "plt.scatter(carbon_c_dict.values(),carbon_score2_dict.values(), color ='red', label = 'Carbon')\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "#plt.xlim([-.05,.06])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel(\"Optimal Dilution Factor\", size = 25)\n",
    "plt.ylabel(\"Score against C Template\", size = 25)\n",
    "plt.title(\"Score Against Diluted C Template vs Optimal Dilution Factor\", size = 30)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(others_c_wdict.values(),others_score2_wdict.values(), color ='orange', alpha =0.2, s= 10, label = 'Others')\n",
    "plt.scatter(wNm_c_wdict.values(),wNm_score2_wdict.values(), color='blue',s=35, label = 'Weak CN Stars')\n",
    "plt.scatter(carbon_c_wdict.values(),carbon_score2_wdict.values(), color ='red', label = 'Carbon')\n",
    "plt.rcParams['figure.figsize'] = 30,11\n",
    "#plt.xlim([-10,10])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel(\"Optimal Dilution Factor\", size = 25)\n",
    "plt.ylabel(\"Score against W Template\", size = 25)\n",
    "plt.title(\"Score Against Diluted W Template vs Optimal Dilution Factor\", size = 30)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "609px",
    "left": "24px",
    "top": "110px",
    "width": "357px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
